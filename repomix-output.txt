This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: lib/memory/upstash
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)

Additional Info:
----------------

================================================================
Directory Structure
================================================================
lib/memory/upstash/agent-state-store.ts
lib/memory/upstash/index.ts
lib/memory/upstash/memory-processor.ts
lib/memory/upstash/memoryStore.ts
lib/memory/upstash/README.md
lib/memory/upstash/redis-store.ts
lib/memory/upstash/stream-processor.ts
lib/memory/upstash/supabase-adapter-factory.ts
lib/memory/upstash/supabase-adapter.ts
lib/memory/upstash/upstash-logger.ts
lib/memory/upstash/upstash.json
lib/memory/upstash/upstashClients.ts
lib/memory/upstash/upstashTypes.ts
lib/memory/upstash/vector-store.ts

================================================================
Files
================================================================

================
File: lib/memory/upstash/memory-processor.ts
================
/**
 * Memory Processor for Upstash
 * 
 * This module provides utilities for processing and streaming memory data from Upstash Redis and Vector.
 * It includes optimized methods for handling personas, micro-personas, and agent states with efficient
 * streaming capabilities.
 * 
 * @module memory-processor
 */

import { getRedisClient, getVectorClient } from './upstashClients';
import { Redis } from '@upstash/redis';
import { Index } from '@upstash/vector';
import { PersonaDefinition, MicroPersonaDefinition } from '../../agents/personas/persona-library';
import { AgentState } from '../../agents/agent.types';
import { Readable } from 'stream';
import { generateEmbedding } from '../../ai-integration';
import { upstashLogger } from './upstash-logger';

/**
 * Error class for memory processor operations
 */
export class MemoryProcessorError extends Error {
  /**
   * Creates a new MemoryProcessorError
   * 
   * @param message - Error message
   * @param cause - Optional cause of the error
   */
  constructor(message: string, public cause?: unknown) {
    super(message);
    this.name = "MemoryProcessorError";
    Object.setPrototypeOf(this, MemoryProcessorError.prototype);
  }
}

/**
 * Type definition for stream state
 */
type StreamState = { cursor: number | string | null };

/**
 * Memory processor for optimized data operations
 */
export class MemoryProcessor {
  private redis: Redis;
  private vector: Index | null;
  private static instance: MemoryProcessor;

  /**
   * Creates a new MemoryProcessor instance
   * @private
   */
  private constructor() {
    this.redis = getRedisClient();
    try {
      const vectorClient = getVectorClient();
      if (vectorClient) {
        this.vector = vectorClient;
      } else {
        this.vector = null;
        upstashLogger.warn('memory-processor', 'Vector client not available, vector operations will be disabled');
      }
    } catch (error: unknown) {
      this.vector = null;
      upstashLogger.warn('memory-processor', 'Vector client not available, vector operations will be disabled', { error });
    }
  }

  /**
   * Gets the singleton instance of MemoryProcessor
   * 
   * @returns The MemoryProcessor instance
   */
  public static getInstance(): MemoryProcessor {
    if (!MemoryProcessor.instance) {
      MemoryProcessor.instance = new MemoryProcessor();
    }
    return MemoryProcessor.instance;
  }

  /**
   * Generates embeddings for the given text using the AI integration
   * 
   * @param text - The text to generate embeddings for
   * @returns A promise that resolves to the embeddings in the format expected by Upstash Vector
   */
  private async generateEmbeddings(text: string): Promise<number[]> {
    try {
      const embedding = await generateEmbedding(text);
      if (embedding instanceof Float32Array) {
        return Array.from(embedding);
      } else if (Array.isArray(embedding)) {
        return embedding;
      } else if (embedding && typeof embedding === 'object' && 'data' in embedding) {
        upstashLogger.warn('memory-processor', 'Unexpected embedding format, attempting to convert');
        // best effort conversion
        return Array.isArray(embedding.data) ? embedding.data : Array.from(embedding.data);
      } else {
        throw new MemoryProcessorError('Unknown embedding format');
      }
    } catch (error: unknown) {
      upstashLogger.error('memory-processor', 'Error generating embeddings', error instanceof Error ? error : { error });
      throw new MemoryProcessorError('Error generating embeddings', error);
    }
  }

  /**
   * Streams personas from Redis with efficient batching
   * 
   * @param options - Stream options
   * @param options.batchSize - Number of personas to fetch in each batch
   * @param options.filter - Optional filter function for personas
   * @returns A readable stream of personas
   */
  public streamPersonas(options: {
    batchSize?: number;
    filter?: (persona: PersonaDefinition) => boolean;
  } = {}): Readable {
    const { batchSize = 10, filter } = options;
    const redis = this.redis;
    return new Readable({
      objectMode: true,
      read() {
        const state: StreamState = { cursor: 0 };
        (async () => {
          try {
            const cursor = state.cursor ?? 0;
            const result = await redis.zscan('personas', cursor, { count: batchSize });
            const [nextCursor, items] = result;
            const personaIds = items.filter((_, index) => index % 2 === 0) as string[];
            if (personaIds.length === 0) {
              this.push(null);
              return;
            }
            const pipeline = redis.pipeline();
            for (const id of personaIds) {
              pipeline.get(`persona:${id}`);
            }
            const personaJsons = await pipeline.exec();
            for (const json of personaJsons) {
              if (json) {
                try {
                  const persona = JSON.parse(json as string) as PersonaDefinition;
                  if (!filter || filter(persona)) {
                    this.push(persona);
                  }
                } catch {
                  upstashLogger.error('memory-processor', 'Error parsing persona JSON');
                }
              }
            }
            state.cursor = nextCursor === '0' ? null : nextCursor;
            if (state.cursor === null) {
              this.push(null);
            }
          } catch (error: unknown) {
            this.destroy(new MemoryProcessorError('Error streaming personas', error));
          }
        })();
      }
    });
  }

  /**
   * Streams micro-personas for a specific parent persona
   * 
   * @param parentPersonaId - The parent persona ID
   * @param options - Stream options
   * @param options.batchSize - Number of micro-personas to fetch in each batch
   * @param options.filter - Optional filter function for micro-personas
   * @returns A readable stream of micro-personas
   */
  public streamMicroPersonas(
    parentPersonaId: string,
    options: {
      batchSize?: number;
      filter?: (microPersona: MicroPersonaDefinition) => boolean;
    } = {}
  ): Readable {
    const { batchSize = 10, filter } = options;
    const redis = this.redis;
    const parentKey = `persona:${parentPersonaId}:micro_personas`;
    return new Readable({
      objectMode: true,
      read() {
        const state: StreamState = { cursor: 0 };
        (async () => {
          try {
            const cursor = state.cursor ?? 0;
            const result = await redis.sscan(parentKey, cursor, { count: batchSize });
            const [nextCursor, microPersonaIds] = result;
            if (microPersonaIds.length === 0) {
              this.push(null);
              return;
            }
            const pipeline = redis.pipeline();
            for (const id of microPersonaIds) {
              pipeline.get(`micro_persona:${id}`);
            }
            const microPersonaJsons = await pipeline.exec();
            for (const json of microPersonaJsons) {
              if (json) {
                try {
                  const microPersona = JSON.parse(json as string) as MicroPersonaDefinition;
                  if (!filter || filter(microPersona)) {
                    this.push(microPersona);
                  }
                } catch {
                  upstashLogger.error('memory-processor', 'Error parsing micro-persona JSON');
                }
              }
            }
            state.cursor = nextCursor === '0' ? null : nextCursor;
            if (state.cursor === null) {
              this.push(null);
            }
          } catch (error: unknown) {
            this.destroy(new MemoryProcessorError('Error streaming micro-personas', error));
          }
        })();
      }
    });
  }

  /**
   * Streams agent states for a specific thread
   * 
   * @param threadId - The thread ID
   * @param options - Stream options
   * @param options.batchSize - Number of agent states to fetch in each batch
   * @param options.filter - Optional filter function for agent states
   * @returns A readable stream of agent states
   */
  public streamAgentStates(
    threadId: string,
    options: {
      batchSize?: number;
      filter?: (state: AgentState & { _agent_id: string }) => boolean;
    } = {}
  ): Readable {
    const { batchSize = 10, filter } = options;
    const redis = this.redis;
    const threadStatesKey = `thread:${threadId}:agent_states`;
    return new Readable({
      objectMode: true,
      read() {
        const state: StreamState = { cursor: 0 };
        (async () => {
          try {
            const cursor = state.cursor ?? 0;
            const result = await redis.sscan(threadStatesKey, cursor, { count: batchSize });
            const [nextCursor, agentIds] = result;
            if (agentIds.length === 0) {
              this.push(null);
              return;
            }
            const pipeline = redis.pipeline();
            for (const agentId of agentIds) {
              pipeline.get(`agent:state:${threadId}:${agentId}`);
            }
            const stateJsons = await pipeline.exec();
            for (const json of stateJsons) {
              if (json) {
                try {
                  const stateObj = JSON.parse(json as string) as AgentState & { _agent_id: string };
                  if (!filter || filter(stateObj)) {
                    this.push(stateObj);
                  }
                } catch {
                  upstashLogger.error('memory-processor', 'Error parsing agent state JSON');
                }
              }
            }
            state.cursor = nextCursor === '0' ? null : nextCursor;
            if (state.cursor === null) {
              this.push(null);
            }
          } catch (error: unknown) {
            this.destroy(new MemoryProcessorError('Error streaming agent states', error));
          }
        })();
      }
    });
  }

  /**
   * Performs a semantic search and streams the results
   * 
   * @param query - The search query
   * @param options - Search options
   * @param options.topK - Number of results to return
   * @param options.filter - Optional filter for vector search
   * @returns A readable stream of search results
   */
  public streamSemanticSearch(
    query: string,
    options: {
      topK?: number;
      filter?: Record<string, unknown>;
    } = {}
  ): Readable {
    const { topK = 10, filter } = options;
    const vector = this.vector;
    return new Readable({
      objectMode: true,
      read() {
        let searchStarted = false;
        let results: unknown[] = [];
        let currentIndex = 0;
        (async () => {
          try {
            if (!searchStarted) {
              searchStarted = true;
              results = await vector?.query({
                vector: await MemoryProcessor.getInstance().generateEmbeddings(query),
                topK,
                filter: filter ? JSON.stringify(filter) : undefined,
                includeMetadata: true,
                includeVectors: false
              }) ?? [];
              currentIndex = 0;
            }
            if (currentIndex >= results.length) {
              this.push(null);
              return;
            }
            this.push(results[currentIndex]);
            currentIndex++;
          } catch (error: unknown) {
            this.destroy(new MemoryProcessorError('Error streaming semantic search results', error));
          }
        })();
      }
    });
  }
}

================
File: lib/memory/upstash/stream-processor.ts
================
/**
 * Stream Processor for Upstash Memory
 *
 * This module provides utilities for processing and streaming data from Upstash Redis and Vector.
 * It includes optimized methods for handling streaming responses, batching, and error handling.
 *
 * @module stream-processor
 */

import { getRedisClient, getVectorClient } from './upstashClients';
import { upstashLogger } from './upstash-logger';
import { Readable, Transform, TransformCallback } from 'stream';
import { z } from 'zod';

// --- Zod Schemas ---

/**
 * Schema for stream processor options
 */
export const StreamProcessorOptionsSchema = z.object({
  batchSize: z.number().int().positive().default(10),
  maxRetries: z.number().int().min(0).default(3),
  retryDelay: z.number().int().min(0).default(1000),
  timeout: z.number().int().min(0).default(30000),
  filter: z.function().optional(),
  transform: z.function().optional(),
  errorHandler: z.function().optional(),
});

export type StreamProcessorOptions = z.infer<typeof StreamProcessorOptionsSchema>;

/**
 * Schema for Redis stream options
 */
export const RedisStreamOptionsSchema = z.object({
  key: z.string().min(1),
  scanType: z.enum(['zscan', 'sscan', 'hscan']).default('zscan'),
  count: z.number().int().positive().default(10),
  pattern: z.string().optional(),
  parseJson: z.boolean().default(true),
}).merge(StreamProcessorOptionsSchema.partial());

export type RedisStreamOptions = z.infer<typeof RedisStreamOptionsSchema>;

/**
 * Schema for Vector stream options
 */
export const VectorStreamOptionsSchema = z.object({
  query: z.array(z.number()), // Only allow number arrays for vector queries
  topK: z.number().int().positive().default(10),
  filter: z.record(z.unknown()).optional(),
  includeMetadata: z.boolean().default(true),
  includeVectors: z.boolean().default(false), // Changed from includeValues to includeVectors
}).merge(StreamProcessorOptionsSchema.partial());

export type VectorStreamOptions = z.infer<typeof VectorStreamOptionsSchema>;

// --- Error Handling ---

/**
 * Error class for stream processor operations
 */
export class StreamProcessorError extends Error {
  constructor(message: string, public cause?: unknown) {
    super(message);
    this.name = "StreamProcessorError";
    Object.setPrototypeOf(this, StreamProcessorError.prototype);
  }
}

/**
 * Stream processor for optimized data operations
 */
export class StreamProcessor {
  private redis = getRedisClient();
  private vector = (() => {
    try {
      return getVectorClient();
    } catch {
      upstashLogger.warn('stream-processor', 'Vector client not available, vector operations will be disabled');
      return null;
    }
  })();
  private static instance: StreamProcessor;

  private constructor() {}

  public static getInstance(): StreamProcessor {
    if (!StreamProcessor.instance) {
      StreamProcessor.instance = new StreamProcessor();
    }
    return StreamProcessor.instance;
  }

  public createRedisStream(options: RedisStreamOptions): Readable {
    const validatedOptions = RedisStreamOptionsSchema.parse(options);
    const {
      key,
      scanType,
      count,
      pattern,
      parseJson,
      batchSize = 10,
      maxRetries = 3,
      retryDelay = 1000,
      filter,
      transform,
      errorHandler
    } = validatedOptions;

    const redis = this.redis;

    return new Readable({
      objectMode: true,
      async read(this: Readable & { cursor?: string }) {
        try {
          const cursor = this.cursor || '0';
          let result: [string, (string | number)[]] | null = null;
          let scanMethod: (key: string, cursor: string | number, options: { count: number; match?: string }) => Promise<[string, (string | number)[]]>;

          switch (scanType) {
            case 'zscan':
              scanMethod = redis.zscan.bind(redis);
              break;
            case 'sscan':
              scanMethod = redis.sscan.bind(redis);
              break;
            case 'hscan':
              scanMethod = redis.hscan.bind(redis);
              break;
            default:
              scanMethod = redis.zscan.bind(redis);
          }

          let retries = 0;
          let success = false;

          while (!success && retries <= maxRetries) {
            try {
              result = await scanMethod(key, cursor, {
                count: count || batchSize,
                ...(pattern ? { match: pattern } : {})
              });
              success = true;
            } catch {
              retries++;
              if (retries > maxRetries) {
                throw new StreamProcessorError('Max retries exceeded');
              }
              await new Promise(resolve => setTimeout(resolve, retryDelay));
            }
          }

          if (!result) {
            this.push(null);
            return;
          }

          const [nextCursor, items] = result;

          if (items.length === 0) {
            this.push(null);
            return;
          }

          let processedItems: unknown[] = [];

          if (scanType === 'zscan' || scanType === 'sscan') {
            processedItems = scanType === 'zscan'
              ? items.filter((_, index) => index % 2 === 0)
              : items;
          } else {
            const fields: string[] = [];
            const values: unknown[] = [];

            for (let i = 0; i < items.length; i += 2) {
              fields.push(String(items[i]));
              values.push(items[i + 1]);
            }

            processedItems = fields.map((field, index) => ({
              field,
              value: values[index]
            }));
          }

          if (parseJson && processedItems.length > 0) {
            const pipeline = redis.pipeline();

            for (const item of processedItems) {
              const itemKey = typeof item === 'object' && item !== null && 'field' in item
                ? `${key}:${item.field}`
                : `${key}:${item}`;

              pipeline.get(itemKey);
            }

            const jsonResults = await pipeline.exec();

            for (const json of jsonResults) {
              if (json) {
                try {
                  const parsedItem = parseJson ? JSON.parse(json as string) : json;

                  if (!filter || filter(parsedItem)) {
                    const itemToEmit = transform ? transform(parsedItem) : parsedItem;
                    this.push(itemToEmit);
                  }
                } catch {
                  if (errorHandler) {
                    errorHandler(undefined, json);
                  } else {
                    upstashLogger.error('stream-processor', 'Error processing item in Redis stream', { item: json });
                  }
                }
              }
            }
          } else {
            for (const item of processedItems) {
              if (!filter || filter(item)) {
                const itemToEmit = transform ? transform(item) : item;
                this.push(itemToEmit);
              }
            }
          }

          this.cursor = nextCursor === '0' ? undefined : nextCursor;

          if (this.cursor === undefined) {
            this.push(null);
          }
        } catch (error) {
          if (errorHandler) {
            try {
              errorHandler(error);
            } catch (handlerError) {
              this.destroy(new StreamProcessorError('Error in stream error handler', handlerError));
            }
          } else {
            this.destroy(new StreamProcessorError('Error streaming from Redis', error));
          }
        }
      }
    });
  }

  public createVectorStream(options: VectorStreamOptions): Readable {
    const validatedOptions = VectorStreamOptionsSchema.parse(options);
    const {
      query,
      topK,
      filter: vectorFilter,
      includeMetadata,
      includeVectors,
      batchSize = 10,
      filter,
      transform,
      errorHandler
    } = validatedOptions;

    const vector = this.vector;

    if (!vector) {
      return new Readable({
        objectMode: true,
        read() {
          this.destroy(new StreamProcessorError('Vector client not available'));
        }
      });
    }

    return new Readable({
      objectMode: true,
      async read(this: Readable & { searchStarted?: boolean; results?: unknown[]; currentIndex?: number }) {
        try {
          if (!this.searchStarted) {
            this.searchStarted = true;

            const results = await vector.query({
              vector: query,
              topK,
              ...(vectorFilter ? { filter: JSON.stringify(vectorFilter) } : {}),
              includeMetadata,
              includeVectors
            });

            this.results = results;
            this.currentIndex = 0;
          }

          const results = this.results;
          const currentIndex = this.currentIndex;

          if (!results || currentIndex === undefined || currentIndex >= results.length) {
            this.push(null);
            return;
          }

          const endIndex = Math.min(currentIndex + batchSize, results.length);
          const batch = results.slice(currentIndex, endIndex);

          for (const result of batch) {
            if (!filter || filter(result)) {
              const itemToEmit = transform ? transform(result) : result;
              this.push(itemToEmit);
            }
          }

          this.currentIndex = endIndex;
        } catch {
          if (errorHandler) {
            try {
              errorHandler(undefined);
            } catch (handlerError) {
              this.destroy(new StreamProcessorError('Error in stream error handler', handlerError));
            }
          } else {
            this.destroy(new StreamProcessorError('Error streaming from Vector'));
          }
        }
      }
    });
  }

  public createTransformStream<TInput = unknown>(
    transformer: (item: TInput, encoding: string, callback: TransformCallback) => void,
    errorHandler?: (error: unknown) => void
  ): Transform {
    return new Transform({
      objectMode: true,
      transform(chunk: TInput, encoding, callback) {
        try {
          transformer(chunk, encoding, callback);
        } catch (error) {
          if (errorHandler) {
            try {
              errorHandler(error);
              callback(null);
            } catch (handlerError) {
              callback(new StreamProcessorError('Error in transform error handler', handlerError));
            }
          } else {
            callback(new StreamProcessorError('Error in transform stream', error));
          }
        }
      }
    });
  }

  public async processStream<T = unknown>(
    inputStream: Readable,
    handler: (item: T) => Promise<void>,
    errorHandler?: (error: unknown, item?: T) => Promise<void>
  ): Promise<void> {
    const processorStream = this.createTransformStream<T>(
      async function(item, _encoding, callback) {
        try {
          await handler(item);
          callback(null, item);
        } catch (error) {
          if (errorHandler) {
            try {
              await errorHandler(error, item);
              callback(null);
            } catch (handlerError) {
              callback(new StreamProcessorError(`Error handling error in stream processor`, handlerError));
            }
          } else {
            callback(new StreamProcessorError(`Error processing item in stream`, error));
          }
        }
      }
    );

    await new Promise<void>((resolve, reject) => {
      inputStream.pipe(processorStream).on('finish', resolve).on('error', reject);
    });
  }
}

// Export the singleton instance for easier access
export const streamProcessor = StreamProcessor.getInstance();

export default StreamProcessor;

================
File: lib/memory/upstash/agent-state-store.ts
================
import { getRedisClient } from './upstashClients';
import { generateId } from 'ai';
import { AgentState } from '../../agents/agent.types';
import { z } from 'zod'; // Add zod import
import { RediSearchHybridQuery, QStashTaskPayload, WorkflowNode } from './upstashTypes';
import { runRediSearchHybridQuery, enqueueQStashTask, trackWorkflowNode } from './upstashClients';

// --- Constants for Redis Keys ---
const AGENT_STATE_PREFIX = "agent:state:";
const AGENT_STATE_INDEX = "agent:states"; // Sorted set for all agent states, scored by last update timestamp
const THREAD_AGENT_STATES_PREFIX = "thread:"; // Prefix for thread-specific agent states
const THREAD_AGENT_STATES_SUFFIX = ":agent_states"; // Suffix for thread-specific agent states

// --- Zod Schemas ---

/**
 * Schema for agent state
 */
export const AgentStateSchema = z.object({
  // Define known fields explicitly
  _thread_id: z.string().optional(),
  _agent_id: z.string().optional(),
  _created_at: z.string().optional(),
  _updated_at: z.string().optional()
}).catchall(z.any()); // Allow any other fields

/**
 * Schema for agent state with required fields
 */
export const StoredAgentStateSchema = AgentStateSchema.extend({
  _thread_id: z.string(),
  _agent_id: z.string(),
  _updated_at: z.string()
});

// --- Error Handling ---
export class AgentStateStoreError extends Error {
  constructor(message: string, public cause?: unknown) {
    super(message);
    this.name = "AgentStateStoreError";
    Object.setPrototypeOf(this, AgentStateStoreError.prototype);
  }
}

function toLoggerError(err: unknown): Error | { error: string } {
  if (err instanceof Error) return err;
  return { error: String(err) };
}

// --- Validate agent state using Zod schema ---
function validateAgentState(state: unknown): AgentState {
  try {
    if (typeof state !== 'object' || state === null) {
      throw new AgentStateStoreError('Agent state must be an object');
    }
    return AgentStateSchema.parse(state) as AgentState;
  } catch (error) {
    if (error instanceof z.ZodError) {
      throw new AgentStateStoreError(`Invalid agent state: ${error.message}`, error);
    }
    throw error;
  }
}

// --- Save agent state ---
export async function saveAgentState(
  threadId: string,
  agentId: string,
  state: AgentState,
  ttl?: number
): Promise<void> {
  if (!threadId) throw new AgentStateStoreError('Thread ID is required');
  if (!agentId) throw new AgentStateStoreError('Agent ID is required');
  const redis = getRedisClient();
  const stateKey = `${AGENT_STATE_PREFIX}${threadId}:${agentId}`;
  const threadStatesKey = `${THREAD_AGENT_STATES_PREFIX}${threadId}${THREAD_AGENT_STATES_SUFFIX}`;
  const now = Date.now();
  try {
    validateAgentState(state);
    const stateData = {
      ...state,
      _thread_id: threadId,
      _agent_id: agentId,
      _updated_at: new Date().toISOString(),
      _created_at: (state as Record<string, unknown>)._created_at || new Date().toISOString()
    };
    const stateJson = JSON.stringify(stateData);
    const pipeline = redis.pipeline();
    pipeline.set(stateKey, stateJson);
    if (ttl && ttl > 0) pipeline.expire(stateKey, ttl);
    pipeline.sadd(threadStatesKey, agentId);
    pipeline.zadd(AGENT_STATE_INDEX, { score: now, member: `${threadId}:${agentId}` });
    const results = await pipeline.exec();
    if (results.some((result: unknown) => result instanceof Error)) {
      const errors = results.filter((result: unknown) => result instanceof Error) as Error[];
      throw new AgentStateStoreError(`Pipeline execution failed: ${errors.map(e => e.message).join(', ')}`);
    }
  } catch (error) {
    throw new AgentStateStoreError(`Failed to save agent state for thread ${threadId}, agent ${agentId}`, toLoggerError(error));
  }
}

// --- Load agent state ---
export async function loadAgentState(
  threadId: string,
  agentId: string
): Promise<AgentState> {
  if (!threadId) throw new AgentStateStoreError('Thread ID is required');
  if (!agentId) throw new AgentStateStoreError('Agent ID is required');
  const redis = getRedisClient();
  const stateKey = `${AGENT_STATE_PREFIX}${threadId}:${agentId}`;
  try {
    const stateJson = await redis.get(stateKey);
    if (!stateJson) return {};
    let state: AgentState;
    try {
      state = JSON.parse(stateJson as string) as AgentState;
    } catch (e: unknown) {
      throw new AgentStateStoreError(`Failed to parse agent state JSON: ${toLoggerError(e)}`);
    }
    validateAgentState(state);
    await redis.zadd(AGENT_STATE_INDEX, { score: Date.now(), member: `${threadId}:${agentId}` });
    return state;
  } catch (error) {
    throw new AgentStateStoreError(`Failed to load agent state for thread ${threadId}, agent ${agentId}`, toLoggerError(error));
  }
}

// --- List all agent states for a thread ---
export async function listThreadAgentStates(threadId: string): Promise<string[]> {
  if (!threadId) throw new AgentStateStoreError('Thread ID is required');
  const redis = getRedisClient();
  const threadStatesKey = `${THREAD_AGENT_STATES_PREFIX}${threadId}${THREAD_AGENT_STATES_SUFFIX}`;
  try {
    const agentIds = await redis.smembers(threadStatesKey);
    return agentIds as string[];
  } catch (error) {
    throw new AgentStateStoreError(`Failed to list agent states for thread ${threadId}`, toLoggerError(error));
  }
}

// --- Delete agent state for a thread ---
export async function deleteAgentState(
  threadId: string,
  agentId: string
): Promise<boolean> {
  if (!threadId) throw new AgentStateStoreError('Thread ID is required');
  if (!agentId) throw new AgentStateStoreError('Agent ID is required');
  const redis = getRedisClient();
  const stateKey = `${AGENT_STATE_PREFIX}${threadId}:${agentId}`;
  const threadStatesKey = `${THREAD_AGENT_STATES_PREFIX}${threadId}${THREAD_AGENT_STATES_SUFFIX}`;
  try {
    const exists = await redis.exists(stateKey);
    if (!exists) return false;
    const pipeline = redis.pipeline();
    pipeline.del(stateKey);
    pipeline.srem(threadStatesKey, agentId);
    pipeline.zrem(AGENT_STATE_INDEX, `${threadId}:${agentId}`);
    const results = await pipeline.exec();
    if (results.some((result: unknown) => result instanceof Error)) {
      const errors = results.filter((result: unknown) => result instanceof Error) as Error[];
      throw new AgentStateStoreError(`Pipeline execution failed: ${errors.map(e => e.message).join(', ')}`);
    }
    return true;
  } catch (error) {
    throw new AgentStateStoreError(`Failed to delete agent state for thread ${threadId}, agent ${agentId}`, toLoggerError(error));
  }
}

// --- Delete all agent states for a thread ---
export async function deleteThreadAgentStates(threadId: string): Promise<number> {
  if (!threadId) throw new AgentStateStoreError('Thread ID is required');
  const redis = getRedisClient();
  const threadStatesKey = `${THREAD_AGENT_STATES_PREFIX}${threadId}${THREAD_AGENT_STATES_SUFFIX}`;
  try {
    const agentIds = await redis.smembers(threadStatesKey) as string[];
    if (agentIds.length === 0) return 0;
    const pipeline = redis.pipeline();
    for (const agentId of agentIds) {
      const stateKey = `${AGENT_STATE_PREFIX}${threadId}:${agentId}`;
      pipeline.del(stateKey);
      pipeline.zrem(AGENT_STATE_INDEX, `${threadId}:${agentId}`);
    }
    pipeline.del(threadStatesKey);
    const results = await pipeline.exec();
    if (results.some((result: unknown) => result instanceof Error)) {
      const errors = results.filter((result: unknown) => result instanceof Error) as Error[];
      throw new AgentStateStoreError(`Pipeline execution failed: ${errors.map(e => e.message).join(', ')}`);
    }
    return agentIds.length;
  } catch (error) {
    throw new AgentStateStoreError(`Failed to delete all agent states for thread ${threadId}`, toLoggerError(error));
  }
}

// --- Create a new agent state with a generated ID ---
export async function createAgentState(
  threadId: string,
  initialState: AgentState = {},
  ttl?: number
): Promise<{ agentId: string; state: AgentState }> {
  if (!threadId) throw new AgentStateStoreError('Thread ID is required');
  try {
    const agentId = generateId();
    if (Object.keys(initialState).length > 0) {
      validateAgentState(initialState);
    }
    const completeState: AgentState = {
      ...initialState,
      _thread_id: threadId,
      _agent_id: agentId,
      _created_at: new Date().toISOString(),
      _updated_at: new Date().toISOString()
    };
    await saveAgentState(threadId, agentId, completeState, ttl);
    return { agentId, state: completeState };
  } catch (error) {
    throw new AgentStateStoreError(`Failed to create agent state for thread ${threadId}`, toLoggerError(error));
  }
}

// --- Get all agent states across all threads ---
export async function getAllAgentStates(
  limit?: number,
  offset?: number
): Promise<Array<AgentState & { _thread_id: string; _agent_id: string }>> {
  const redis = getRedisClient();
  try {
    const stateKeys = await redis.zrange(AGENT_STATE_INDEX, 0, -1, { rev: true });
    const paginatedKeys = stateKeys.slice(offset || 0, limit ? (offset || 0) + limit : undefined);
    if (paginatedKeys.length === 0) return [];
    const pipeline = redis.pipeline();
    for (const key of paginatedKeys as string[]) {
      const [threadId, agentId] = key.split(':');
      pipeline.get(`${AGENT_STATE_PREFIX}${threadId}:${agentId}`);
    }
    const stateJsons = await pipeline.exec();
    const states = (stateJsons as Array<string | null>)
      .filter((json): json is string => json !== null && typeof json === 'string')
      .map(json => {
        try {
          return JSON.parse(json) as AgentState & { _thread_id: string; _agent_id: string };
        } catch {
          return null;
        }
      })
      .filter((state): state is AgentState & { _thread_id: string; _agent_id: string } =>
        state !== null && typeof state === 'object' && '_thread_id' in state && '_agent_id' in state
      );
    return states;
  } catch (error) {
    throw new AgentStateStoreError('Failed to get all agent states', toLoggerError(error));
  }
}

// --- Advanced RediSearch/Hybrid Search ---
export async function advancedAgentStateHybridSearch(query: RediSearchHybridQuery) {
  return runRediSearchHybridQuery(query);
}

// --- QStash/Workflow Integration Example ---
export async function enqueueAgentStateWorkflow(type: string, data: Record<string, unknown>) {
  const payload: QStashTaskPayload = {
    id: typeof crypto !== 'undefined' && crypto.randomUUID ? crypto.randomUUID() : Math.random().toString(36).slice(2),
    type,
    data,
    created_at: new Date().toISOString(),
    status: 'pending',
  };
  return enqueueQStashTask(payload);
}

export async function trackAgentStateWorkflowNode(node: WorkflowNode) {
  return trackWorkflowNode(node);
}

================
File: lib/memory/upstash/index.ts
================
/**
 * Barrel file for the Upstash memory module.
 * Exports all necessary functions, types, and classes for interacting with
 * Upstash Redis and VectorDB as a memory store and logger.
 */

// From upstashClients.ts
export {
  getRedisClient,
  getVectorClient,
  checkUpstashAvailability,
  UpstashClientError,
  validateRedisConfig,
  validateVectorConfig,
  RedisConfigSchema,
  VectorConfigSchema,
  EnvVarsSchema,
  type IndexConfig
} from './upstashClients';

// From redis-store.ts
export {
  createRedisThread,
  getRedisThreadById,
  updateRedisThread,
  listRedisThreads,
  deleteRedisThread,
  createRedisMessage,
  getRedisMessageById,
  getRedisMessagesByThreadId,
  deleteRedisMessage,
  RedisStoreError,
  type Thread,
  type Message,
  type ThreadMetadata,
  createRedisSettings,
  getRedisSettingsById,
  updateRedisSettings,
  deleteRedisSettings,
  listRedisSettings,
  createRedisSystemMetric,
  getRedisSystemMetricById,
  updateRedisSystemMetric,
  deleteRedisSystemMetric,
  listRedisSystemMetrics,
  createRedisTrace,
  getRedisTraceById,
  updateRedisTrace,
  deleteRedisTrace,
  listRedisTraces,
  createRedisSpan,
  getRedisSpanById,
  updateRedisSpan,
  deleteRedisSpan,
  listRedisSpans,
  createRedisEvent,
  getRedisEventById,
  updateRedisEvent,
  deleteRedisEvent,
  listRedisEvents,
  createRedisProvider,
  getRedisProviderById,
  updateRedisProvider,
  deleteRedisProvider,
  listRedisProviders,
  createRedisModel,
  getRedisModelById,
  updateRedisModel,
  deleteRedisModel,
  listRedisModels,
  createRedisAuthProvider,
  getRedisAuthProviderById,
  updateRedisAuthProvider,
  deleteRedisAuthProvider,
  listRedisAuthProviders,
  createRedisDashboardConfig,
  getRedisDashboardConfigById,
  updateRedisDashboardConfig,
  deleteRedisDashboardConfig,
  listRedisDashboardConfigs
} from './redis-store';

// From vector-store.ts
export {
  upsertEmbeddings,
  searchSimilarEmbeddings,
  getEmbeddingsByIds,
  deleteEmbeddingsByIds,
  resetVectorIndex,
  getVectorIndexInfo,
  VectorStoreError,
  type EmbeddingMetadata,
  type EmbeddingVector,
  type SearchEmbeddingsOptions,
  type EmbeddingSearchResult
} from './vector-store';

// From upstash-logger.ts
export {
  logInfo,
  logWarn,
  logError,
  logDebug,
  getLogs,
  deleteLogs,
  clearLogs,
  LoggerError,
  LogLevelSchema,
  LogEntrySchema,
  type LogLevel,
  type LogEntry
} from './upstash-logger';

// From agent-state-store.ts
export {
  saveAgentState,
  loadAgentState,
  listThreadAgentStates,
  deleteAgentState,
  deleteThreadAgentStates,
  createAgentState,
  getAllAgentStates,
  AgentStateStoreError,
  AgentStateSchema,
  StoredAgentStateSchema
} from './agent-state-store';

// From memory-processor.ts
export {
  MemoryProcessor,
  MemoryProcessorError
} from './memory-processor';

// From upstashTypes.ts
export {
  RedisClientError,
  VectorStoreError as VectorClientError,
  VectorMetadataSchema,
  VectorDocumentSchema,
  type VectorMetadata as VectorClientMetadata,
  type VectorDocument as VectorClientDocument,
  type RedisClientConfig,
  type VectorStoreConfig,
  type VectorQueryOptions,
  type VectorQueryResult,
  type VectorFetchResult,
  type RedisPipeline,
  type VectorIndexConfig,
  type RedisType,
  type IndexType,
  type VectorType,
  type ZodType
} from './upstashTypes';

// From stream-processor.ts
export {
  streamProcessor,
  StreamProcessor,
  StreamProcessorError,
  type StreamProcessorOptions,
  type RedisStreamOptions,
  type VectorStreamOptions
} from './stream-processor';

// From supabase-adapter.ts
export {
  getData,
  getItemById,
  createItem,
  updateItem,
  deleteItem,
  vectorSearch,
  upsertVectors as upsertSupabaseVectors,
  type TableRow,
  type FilterOptions,
  type OrderOptions,
  type QueryOptions
} from './supabase-adapter';

// From supabase-adapter-factory.ts
export {
  createSupabaseClient,
  type SupabaseClient,
  type TableClient,
  type VectorClient
} from './supabase-adapter-factory';

================
File: lib/memory/upstash/memoryStore.ts
================
import { generateId } from 'ai';
import { RediSearchHybridQuery, QStashTaskPayload, WorkflowNode } from './upstashTypes';
import {
  getRedisClient,
  getVectorClient,
  runRediSearchHybridQuery,
  enqueueQStashTask,
  trackWorkflowNode
} from './upstashClients';

// Check if Upstash is available
export const isUpstashAvailable = async (): Promise<boolean> => {
  try {
    const redis = getRedisClient();
    await redis.ping();
    return true;
  } catch {
    // Use robust error handling, do not use console
    return false;
  }
};

// Thread operations
export async function createThread(name: string, metadata: Record<string, unknown> = {}): Promise<string> {
  const redis = getRedisClient();
  const threadId = generateId();
  const now = new Date().toISOString();

  const thread = {
    id: threadId,
    name,
    metadata,
    created_at: now,
    updated_at: now,
  };

  await redis.hset(`thread:${threadId}`, thread);
  await redis.zadd('threads', { score: Date.now(), member: threadId });

  return threadId;
}

export async function getThread(threadId: string): Promise<Record<string, unknown> | null> {
  const redis = getRedisClient();
  const thread = await redis.hgetall(`thread:${threadId}`);
  return thread && Object.keys(thread).length > 0 ? thread : null;
}

export async function listThreads(limit = 10, offset = 0): Promise<Record<string, unknown>[]> {
  const redis = getRedisClient();
  const threadIds = await redis.zrange('threads', offset, offset + limit - 1, { rev: true });

  const threads: Record<string, unknown>[] = [];
  for (const threadId of threadIds) {
    const thread = await getThread(threadId as string);
    if (thread) threads.push(thread);
  }

  return threads;
}

export async function deleteThread(threadId: string): Promise<boolean> {
  const redis = getRedisClient();

  // Get all message IDs for this thread
  const messageIds = await redis.smembers(`thread:${threadId}:messages`);

  // Delete all messages
  for (const messageId of messageIds) {
    await redis.del(`message:${messageId}`);
  }

  // Delete thread metadata and references
  await redis.del(`thread:${threadId}:messages`);
  await redis.del(`thread:${threadId}`);
  await redis.zrem('threads', threadId);

  return true;
}

// Message operations
export async function saveMessage(
  threadId: string,
  message: {
    role: string;
    content: string;
    metadata?: Record<string, unknown>;
  }
): Promise<string> {
  const redis = getRedisClient();
  const messageId = generateId();
  const now = new Date().toISOString();

  const messageData = {
    id: messageId,
    thread_id: threadId,
    role: message.role,
    content: message.content,
    metadata: JSON.stringify(message.metadata || {}),
    created_at: now,
  };

  // Save message
  await redis.hset(`message:${messageId}`, messageData);

  // Add to thread's message set
  await redis.sadd(`thread:${threadId}:messages`, messageId);

  // Update thread's updated_at timestamp
  await redis.hset(`thread:${threadId}`, { updated_at: now });

  // Update thread's position in the sorted set
  await redis.zadd('threads', { score: Date.now(), member: threadId });

  return messageId;
}

export async function getMessages(threadId: string): Promise<Record<string, unknown>[]> {
  const redis = getRedisClient();

  // Get all message IDs for this thread
  const messageIds = await redis.smembers(`thread:${threadId}:messages`);

  // Get all messages
  const messages: Record<string, unknown>[] = [];
  for (const messageId of messageIds) {
    const message = await redis.hgetall(`message:${messageId}`);
    if (message) {
      // Parse metadata
      if (message.metadata) {
        try {
          message.metadata = JSON.parse(message.metadata as string);
        } catch {
          message.metadata = {};
        }
      }
      messages.push(message);
    }
  }

  // Sort by created_at
  return messages.sort((a, b) => {
    const aTime = a.created_at ? new Date(a.created_at as string).getTime() : 0;
    const bTime = b.created_at ? new Date(b.created_at as string).getTime() : 0;
    return aTime - bTime;
  });
}

// Vector operations
export async function storeEmbedding(
  text: string,
  vector: number[],
  metadata: Record<string, unknown> = {}
): Promise<string> {
  const vectorDb = getVectorClient();
  const id = generateId();

  await vectorDb.upsert({
    id,
    vector,
    metadata: {
      ...metadata,
      text,
      created_at: new Date().toISOString(),
    },
  });

  return id;
}

export async function searchEmbeddings(vector: number[], limit = 5): Promise<unknown[]> {
  const vectorDb = getVectorClient();

  const results = await vectorDb.query({
    vector,
    topK: limit,
    includeMetadata: true,
  });

  return results;
}

// --- Advanced RediSearch/Hybrid Search ---
export async function advancedThreadHybridSearch(query: RediSearchHybridQuery): Promise<unknown> {
  return runRediSearchHybridQuery(query);
}

// --- QStash/Workflow Integration Example ---
export async function enqueueMemoryWorkflow(type: string, data: Record<string, unknown>): Promise<unknown> {
  const payload: QStashTaskPayload = {
    id: generateId(),
    type,
    data,
    created_at: new Date().toISOString(),
    status: 'pending',
  };
  return enqueueQStashTask(payload);
}

export async function trackMemoryWorkflowNode(node: WorkflowNode): Promise<unknown> {
  return trackWorkflowNode(node);
}

// Export for convenience
export { getRedisClient as Memory, getVectorClient as Vectordb };

================
File: lib/memory/upstash/supabase-adapter-factory.ts
================
/**
 * Supabase Adapter Factory
 *
 * This module provides a factory for creating Supabase-like clients using Upstash Redis and Vector.
 * It implements similar interfaces and functionality to make the transition seamless.
 *
 * @module supabase-adapter-factory
 */

import {
  getData,
  getItemById,
  createItem,
  updateItem,
  deleteItem,
  vectorSearch,
  upsertSupabaseVectors,
  TableRow,
  FilterOptions,
  QueryOptions
} from './index';
import {
  entityApi,
  upsertItem,
  existsItem,
  countItems,
  batchGetItems,
  VectorMetadata,
  VectorQueryOptions
} from './supabase-adapter';

// --- Enhanced Type-Safe TableClient ---
export interface TableClient<T extends TableRow = TableRow> {
  getAll(options?: QueryOptions): Promise<T[]>;
  getById(id: string): Promise<T | null>;
  create(item: Omit<T, 'id'> & { id?: string }): Promise<T>;
  update(id: string, updates: Partial<T>): Promise<T>;
  delete(id: string): Promise<boolean>;
  upsert(item: T): Promise<T>;
  exists(id: string): Promise<boolean>;
  count(options?: QueryOptions): Promise<number>;
  batchGet(ids: string[]): Promise<(T | null)[]>;
  select(...columns: (keyof T)[]): TableClient<T>;
  filter(field: keyof T, operator: FilterOptions['operator'], value: unknown): TableClient<T>;
  order(column: keyof T, ascending?: boolean): TableClient<T>;
  limit(limit: number): TableClient<T>;
  offset(offset: number): TableClient<T>;
}

export interface VectorClient {
  search(
    query: number[] | string,
    options?: VectorQueryOptions
  ): Promise<Array<Record<string, unknown>>>;
  upsert(
    vectors: Array<{
      id: string;
      vector: number[];
      metadata?: Record<string, unknown>;
    }>,
    options?: { namespace?: string }
  ): Promise<Record<string, unknown>>;
  upsertTexts(
    texts: Array<{ id: string; text: string; metadata?: VectorMetadata }>,
    options?: { namespace?: string }
  ): Promise<unknown>;
  semanticSearch(
    text: string,
    options?: VectorQueryOptions
  ): Promise<unknown[]>;
}

export interface SupabaseClient {
  from<T extends TableRow = TableRow>(tableName: string): TableClient<T>;
  vector: VectorClient;
  entity: typeof entityApi;
}

export function createSupabaseClient(): SupabaseClient {
  function createTableClient<T extends TableRow = TableRow>(tableName: string): TableClient<T> {
    let options: QueryOptions = {};
    const client: TableClient<T> = {
      getAll: async (queryOptions?: QueryOptions) => {
        return getData(tableName as any, { ...options, ...queryOptions }) as unknown as Promise<T[]>;
      },
      getById: async (id: string) => {
        return getItemById(tableName as any, id) as unknown as Promise<T | null>;
      },
      create: async (item: Omit<T, 'id'> & { id?: string }) => {
        return createItem(tableName as any, item) as unknown as Promise<T>;
      },
      update: async (id: string, updates: Partial<T>) => {
        return updateItem(tableName as any, id, updates) as unknown as Promise<T>;
      },
      delete: async (id: string) => {
        return deleteItem(tableName as any, id) as unknown as Promise<boolean>;
      },
      upsert: async (item: T) => {
        return upsertItem(tableName as any, item) as unknown as Promise<T>;
      },
      exists: async (id: string) => {
        return existsItem(tableName as any, id) as unknown as Promise<boolean>;
      },
      count: async (queryOptions?: QueryOptions) => {
        return countItems(tableName as any, queryOptions) as unknown as Promise<number>;
      },
      batchGet: async (ids: string[]) => {
        return batchGetItems(tableName as any, ids) as unknown as Promise<(T | null)[]>;
      },
      select: (...columns: (keyof T)[]) => {
        options = { ...options, select: columns as string[] };
        return client;
      },
      filter: (field: keyof T, operator: FilterOptions['operator'], value: unknown) => {
        const filters = options.filters || [];
        filters.push({ field: field as string, operator, value });
        options = { ...options, filters };
        return client;
      },
      order: (column: keyof T, ascending?: boolean) => {
        options = { ...options, orderBy: { column: column as string, ascending } };
        return client;
      },
      limit: (limit: number) => {
        options = { ...options, limit };
        return client;
      },
      offset: (offset: number) => {
        options = { ...options, offset };
        return client;
      }
    };
    return client;
  }

  function createVectorClient(): VectorClient {
    return {
      search: async (query, options) => {
        return vectorSearch(query, options) as Promise<Record<string, unknown>[]>;
      },
      upsert: async (vectors, options) => {
        const vectorsWithSparse = vectors.map(v => ({
          ...v,
          sparseVector: {
            indices: Array.from(v.vector.keys()),
            values: v.vector
          }
        }));
        return upsertSupabaseVectors(vectorsWithSparse, options) as Promise<Record<string, unknown>>;
      },
      upsertTexts: async (texts, options) => {
        return entityApi.upsertTexts(texts, options);
      },
      semanticSearch: async (text, options) => {
        return entityApi.semanticSearch(text, options);
      }
    };
  }

  return {
    from: createTableClient,
    vector: createVectorClient(),
    entity: entityApi
  };
}

export default createSupabaseClient;

================
File: lib/memory/upstash/vector-store.ts
================
import { generateId } from 'ai';
import { getVectorClient, isUpstashVectorAvailable, runRediSearchHybridQuery, enqueueQStashTask, trackWorkflowNode } from './upstashClients';
import type { Index, Vector, QueryResult, FetchResult } from '@upstash/vector';
import { generateEmbedding } from '../../ai-integration';
import { z } from 'zod';
import { RediSearchHybridQuery, RediSearchHybridResult, QStashTaskPayload, WorkflowNode, UpstashEntityBase } from './upstashTypes';
import { upstashLogger } from './upstash-logger';

// --- Zod Schemas ---

/**
 * Zod schema for embedding metadata
 */
export const EmbeddingMetadataSchema = z.record(z.any()).and(
  z.object({
    text: z.string().optional(),
    source_url: z.string().optional(),
    document_id: z.string().optional(),
    chunk_id: z.string().optional(),
    user_id: z.string().optional(),
    created_at: z.string().optional(),
  }).partial()
);

/**
 * Zod schema for embedding vector
 */
export const EmbeddingVectorSchema = z.object({
  id: z.string(),
  vector: z.array(z.number()),
  metadata: EmbeddingMetadataSchema.optional(),
  sparseVector: z.object({
    indices: z.array(z.number()),
    values: z.array(z.number())
  }).optional(),
});

/**
 * Zod schema for search embeddings options
 */
export const SearchEmbeddingsOptionsSchema = z.object({
  topK: z.number().positive().optional().default(10),
  includeVectors: z.boolean().optional().default(false),
  includeMetadata: z.boolean().optional().default(true),
  filter: z.string().optional(),
});

/**
 * Zod schema for embedding search result
 */
export const EmbeddingSearchResultSchema = z.object({
  id: z.string(),
  score: z.number(),
  vector: z.array(z.number()).optional(),
  metadata: EmbeddingMetadataSchema.optional(),
});

// --- Types ---

/**
 * Metadata for an embedding. Can be any JSON-serializable object.
 * It's recommended to include fields that might be useful for filtering searches.
 */
export interface EmbeddingMetadata {
  text?: string; // The original text chunk, often useful to store
  source_url?: string;
  document_id?: string;
  chunk_id?: string;
  user_id?: string;
  created_at?: string; // ISO 8601 timestamp
  [key: string]: unknown; // Allow other arbitrary metadata
}

/**
 * Represents a vector to be upserted into the Upstash Vector database.
 */
export interface EmbeddingVector extends Vector {
  id: string; // Unique ID for the vector
  vector: number[];
  metadata?: EmbeddingMetadata;
}

/**
 * Options for querying similar embeddings.
 */
export interface SearchEmbeddingsOptions {
  topK?: number;
  includeVectors?: boolean;
  includeMetadata?: boolean;
  filter?: string; // Upstash Vector metadata filter string (e.g., "user_id = 'abc' AND type = 'document'")
}

/**
 * Represents a search result from Upstash Vector.
 */
export interface EmbeddingSearchResult extends QueryResult {
  id: string;
  score: number;
  vector?: number[];
  metadata?: EmbeddingMetadata;
}

// --- Error Handling ---
export class VectorStoreError extends Error {
  constructor(message: string, public cause?: unknown) {
    super(message);
    this.name = "VectorStoreError";
    Object.setPrototypeOf(this, VectorStoreError.prototype);
  }
}

// --- Vector Operations ---

/**
 * Upserts (inserts or updates) one or more embedding vectors into the Upstash Vector index.
 * @param embeddings An array of EmbeddingVector objects or a single EmbeddingVector.
 * @returns A promise that resolves with the result of the upsert operation from Upstash.
 * @throws VectorStoreError if upsertion fails.
 */
export async function upsertEmbeddings(
  embeddings: EmbeddingVector | EmbeddingVector[]
): Promise<string> {
  const vectorDb: Index = getVectorClient();
  try {
    const result = await vectorDb.upsert(embeddings);
    return result as string;
  } catch (error: unknown) {
    upstashLogger.error('vector-store', 'Error upserting embeddings to Upstash Vector', error instanceof Error ? error : { message: String(error) });
    throw new VectorStoreError("Failed to upsert embeddings", error);
  }
}

/**
 * Searches for embeddings similar to a given query vector.
 * @param queryVector The vector to find similar embeddings for.
 * @param options Optional search parameters (topK, includeVectors, includeMetadata, filter).
 * @returns A promise that resolves to an array of EmbeddingSearchResult objects.
 * @throws VectorStoreError if the search fails.
 */
export async function searchSimilarEmbeddings(
  queryVector: number[],
  options?: SearchEmbeddingsOptions
): Promise<EmbeddingSearchResult[]> {
  const vectorDb: Index = getVectorClient();
  const { topK = 10, includeVectors = false, includeMetadata = true, filter } = options || {};

  try {
    const results = await vectorDb.query({
      vector: queryVector,
      topK,
      includeVectors,
      includeMetadata,
      filter,
    });
    return results as EmbeddingSearchResult[];
  } catch (error: unknown) {
    upstashLogger.error('vector-store', 'Error searching embeddings in Upstash Vector', error instanceof Error ? error : { message: String(error) });
    throw new VectorStoreError("Failed to search embeddings", error);
  }
}

/**
 * Fetches one or more embedding vectors by their IDs.
 * @param ids An array of vector IDs or a single vector ID.
 * @param includeVectors Whether to include the vector data in the result (default: false).
 * @param includeMetadata Whether to include metadata in the result (default: true).
 * @returns A promise that resolves to an array of fetched EmbeddingVector objects (or null if not found), or a single object/null.
 * @throws VectorStoreError if fetching fails.
 */
export async function getEmbeddingsByIds(
  ids: string | string[],
  includeVectors: boolean = false,
  includeMetadata: boolean = true
): Promise<Array<FetchResult<EmbeddingMetadata> | null> | FetchResult<EmbeddingMetadata> | null> {
  const vectorDb: Index = getVectorClient();
  try {
    const normalizedIds = Array.isArray(ids) ? ids : [ids];
    const results = await vectorDb.fetch(normalizedIds, { includeVectors, includeMetadata });
    return results as Array<FetchResult<EmbeddingMetadata> | null> | FetchResult<EmbeddingMetadata> | null;
  } catch (error: unknown) {
    upstashLogger.error('vector-store', 'Error fetching embeddings by ID from Upstash Vector', error instanceof Error ? error : { message: String(error) });
    throw new VectorStoreError("Failed to fetch embeddings by ID", error);
  }
}

/**
 * Deletes one or more embedding vectors by their IDs.
 * @param ids An array of vector IDs or a single vector ID.
 * @returns A promise that resolves with the result of the delete operation from Upstash.
 * @throws VectorStoreError if deletion fails.
 */
export async function deleteEmbeddingsByIds(ids: string | string[]): Promise<number> {
  const vectorDb: Index = getVectorClient();
  try {
    const result = await vectorDb.delete(ids);
    // Upstash Vector returns { deleted: number }
    if (typeof result === 'object' && result !== null && 'deleted' in result) {
      return (result as { deleted: number }).deleted;
    }
    throw new VectorStoreError('Unexpected response from Upstash Vector delete', result);
  } catch (error: unknown) {
    upstashLogger.error('vector-store', 'Error deleting embeddings by ID from Upstash Vector', error instanceof Error ? error : { message: String(error) });
    throw new VectorStoreError("Failed to delete embeddings by ID", error);
  }
}

/**
 * Resets the entire vector index, deleting all vectors. Use with extreme caution.
 * @returns A promise that resolves when the reset operation is complete.
 * @throws VectorStoreError if reset fails.
 */
export async function resetVectorIndex(): Promise<void> {
  const vectorDb: Index = getVectorClient();
  try {
    await vectorDb.reset();
  } catch (error: unknown) {
    upstashLogger.error('vector-store', 'Error resetting Upstash Vector index', error instanceof Error ? error : { message: String(error) });
    throw new VectorStoreError("Failed to reset vector index", error);
  }
}

/**
 * Gets information about the vector index, such as vector count, pending vector count, and dimension.
 * @returns A promise that resolves with the index information.
 * @throws VectorStoreError if fetching info fails.
 */
export async function getVectorIndexInfo(): Promise<unknown> {
  const vectorDb: Index = getVectorClient();
  try {
    const info = await vectorDb.info();
    return info;
  } catch (error: unknown) {
    upstashLogger.error('vector-store', 'Error fetching Upstash Vector index info', error instanceof Error ? error : { message: String(error) });
    throw new VectorStoreError("Failed to fetch vector index info", error);
  }
}

// --- RAG-specific Functions ---

/**
 * Stores text embedding in Upstash Vector.
 * This function generates an embedding for the given text and stores it in the vector database.
 *
 * @param text - The text to generate an embedding for
 * @param metadata - Optional metadata to store with the embedding
 * @returns Promise resolving to the ID of the stored embedding
 * @throws VectorStoreError if storing fails
 */
export async function storeTextEmbedding(
  text: string,
  metadata?: EmbeddingMetadata
): Promise<string> {
  try {
    // Check if Upstash Vector is available
    if (!isUpstashVectorAvailable()) {
      throw new VectorStoreError('Upstash Vector is not available. Please set UPSTASH_VECTOR_REST_URL and UPSTASH_VECTOR_REST_TOKEN environment variables.');
    }

    // Validate text input
    if (!text || typeof text !== 'string') {
      throw new VectorStoreError('Invalid text input for embedding generation');
    }

    // Generate embedding for the text
    const embedding = await generateEmbedding(text);

    // Convert Float32Array to regular array
    const embeddingArray = Array.from(embedding) as number[];

    // Generate a unique ID for the embedding
    const id = generateId();

    // Prepare metadata with the original text
    const fullMetadata: EmbeddingMetadata = {
      text,
      created_at: new Date().toISOString(),
      ...metadata
    };

    // Validate with Zod schema
    const vectorData = EmbeddingVectorSchema.parse({
      id,
      vector: embeddingArray,
      metadata: fullMetadata
    });

    // Store the embedding in Upstash Vector
    await upsertEmbeddings(vectorData);

    return id;
  } catch (error: unknown) {
    upstashLogger.error('vector-store', 'Error storing text embedding', error instanceof Error ? error : { message: String(error) });
    if (error instanceof VectorStoreError) {
      throw error;
    }
    throw new VectorStoreError('Failed to store text embedding', error);
  }
}

/**
 * Searches for similar text in the vector store.
 * This function generates an embedding for the query text and searches for similar embeddings.
 *
 * @param query - The text query to search for
 * @param limit - Maximum number of results to return
 * @param filter - Optional filter for the search
 * @returns Promise resolving to an array of search results
 * @throws VectorStoreError if search fails
 */
export async function searchTextStore(
  query: string,
  limit: number = 10,
  filter?: string
): Promise<EmbeddingSearchResult[]> {
  try {
    // Check if Upstash Vector is available
    if (!isUpstashVectorAvailable()) {
      throw new VectorStoreError('Upstash Vector is not available. Please set UPSTASH_VECTOR_REST_URL and UPSTASH_VECTOR_REST_TOKEN environment variables.');
    }

    // Validate query input
    if (!query || typeof query !== 'string') {
      throw new VectorStoreError('Invalid query text for search');
    }

    // Generate embedding for the query
    const embedding = await generateEmbedding(query);

    // Convert Float32Array to regular array
    const embeddingArray = Array.from(embedding) as number[];

    // Validate search options with Zod schema
    const searchOptions = SearchEmbeddingsOptionsSchema.parse({
      topK: limit,
      includeMetadata: true,
      filter
    });

    // Search for similar embeddings
    const results = await searchSimilarEmbeddings(embeddingArray, searchOptions);

    return results;
  } catch (error: unknown) {
    upstashLogger.error('vector-store', 'Error searching text store', error instanceof Error ? error : { message: String(error) });
    if (error instanceof VectorStoreError) {
      throw error;
    }
    throw new VectorStoreError('Failed to search text store', error);
  }
}

/**
 * Performs a hybrid search combining vector similarity and keyword matching.
 *
 * @param query - The text query to search for
 * @param options - Search options
 * @returns Promise resolving to an array of search results
 * @throws VectorStoreError if search fails
 */
export async function hybridSearch(
  query: string,
  options?: {
    limit?: number;
    filter?: string;
    keywordWeight?: number; // Weight for keyword matching (0-1)
    vectorWeight?: number;  // Weight for vector similarity (0-1)
  }
): Promise<EmbeddingSearchResult[]> {
  try {
    // Default options
    const limit = options?.limit || 10;
    const filter = options?.filter;
    const keywordWeight = options?.keywordWeight || 0.3;
    const vectorWeight = options?.vectorWeight || 0.7;

    // Validate weights
    if (keywordWeight < 0 || keywordWeight > 1 || vectorWeight < 0 || vectorWeight > 1) {
      throw new VectorStoreError('Weights must be between 0 and 1');
    }

    // Perform vector search
    const vectorResults = await searchTextStore(query, limit * 2, filter);

    // Extract keywords from query (simple implementation)
    const keywords = query.toLowerCase()
      .split(/\s+/)
      .filter(word => word.length > 3) // Filter out short words
      .map(word => word.replace(/[^\w]/g, '')); // Remove non-word characters

    // Re-rank results based on keyword matching
    const rerankedResults = vectorResults.map(result => {
      const text = result.metadata?.text || '';

      // Calculate keyword score
      let keywordScore = 0;
      if (text && keywords.length > 0) {
        const textLower = text.toLowerCase();
        const matchedKeywords = keywords.filter(keyword => textLower.includes(keyword));
        keywordScore = matchedKeywords.length / keywords.length;
      }

      // Calculate combined score
      const combinedScore = (result.score * vectorWeight) + (keywordScore * keywordWeight);

      return {
        ...result,
        score: combinedScore
      };
    });

    // Sort by combined score and limit results
    rerankedResults.sort((a, b) => b.score - a.score);
    return rerankedResults.slice(0, limit);
  } catch (error: unknown) {
    upstashLogger.error('vector-store', 'Error performing hybrid search', error instanceof Error ? error : { message: String(error) });
    if (error instanceof VectorStoreError) {
      throw error;
    }
    throw new VectorStoreError('Failed to perform hybrid search', error);
  }
}

// --- Advanced RediSearch/Hybrid Search ---
export async function advancedVectorHybridSearch(query: RediSearchHybridQuery): Promise<RediSearchHybridResult[]> {
  try {
    const results = await runRediSearchHybridQuery(query);
    return results as RediSearchHybridResult[];
  } catch (err) {
    upstashLogger.error('vector-store', 'Failed advanced hybrid search', err instanceof Error ? err : { message: String(err) });
    throw new VectorStoreError('Failed advanced hybrid search', err);
  }
}

// --- QStash/Workflow Integration Example ---
export async function enqueueVectorWorkflow(type: string, data: Record<string, unknown>) {
  const payload: QStashTaskPayload = {
    id: crypto.randomUUID?.() || Math.random().toString(36).slice(2),
    type,
    data,
    created_at: new Date().toISOString(),
    status: 'pending',
  };
  return enqueueQStashTask(payload);
}

export async function trackVectorWorkflowNode(node: WorkflowNode) {
  return trackWorkflowNode(node);
}

================
File: lib/memory/upstash/upstash-logger.ts
================
import { getRedisClient } from './upstashClients';
import { generateId } from 'ai';
import { z } from 'zod';

// --- Constants for Redis Keys ---
const LOG_STREAM_PREFIX = "log_stream:"; // For Redis Streams
const MAX_LOG_ENTRIES = 1000; // Max entries per stream (approximate)

// --- Types ---
export type LogLevel = "INFO" | "WARN" | "ERROR" | "DEBUG";

export interface LogEntry {
  id: string;
  timestamp: string;
  level: LogLevel;
  service: string;
  message: string;
  details?: Record<string, unknown> | null;
}

// --- Zod Schemas ---
export const LogLevelSchema = z.enum(["INFO", "WARN", "ERROR", "DEBUG"]);

export const LogEntrySchema = z.object({
  id: z.string(),
  timestamp: z.string(),
  level: LogLevelSchema,
  service: z.string(),
  message: z.string(),
  details: z.record(z.unknown()).nullable().optional(),
});

// --- Error Handling ---
export class LoggerError extends Error {
  constructor(message: string, public cause?: unknown) {
    super(message);
    this.name = "LoggerError";
    Object.setPrototypeOf(this, LoggerError.prototype);
  }
}

const generateLogId = (): string => generateId();

function validateLogEntry(entry: unknown): LogEntry {
  try {
    return LogEntrySchema.parse(entry) as LogEntry;
  } catch (error: unknown) {
    if (error instanceof z.ZodError) {
      throw new LoggerError(`Invalid log entry: ${error.message}`, error);
    }
    if (error instanceof Error) {
      throw error;
    }
    throw new LoggerError('An unexpected error occurred during log entry validation.', error);
  }
}

async function logToStream(
  level: LogLevel,
  service: string,
  message: string,
  details?: Record<string, unknown> | null
): Promise<string> {
  const redis = getRedisClient();
  const streamKey = `${LOG_STREAM_PREFIX}${service.toLowerCase()}`;
  const now = new Date();

  if (!LogLevelSchema.safeParse(level).success) {
    throw new LoggerError(`Invalid log level: ${level}`);
  }

  const logEntry: Omit<LogEntry, 'id'> = {
    timestamp: now.toISOString(),
    level,
    service,
    message,
    details: details || null,
  };

  const streamEntry: { [key: string]: string } = {};
  for (const [key, value] of Object.entries(logEntry)) {
    if (value === null || value === undefined) continue;
    if (key === 'details' && typeof value === 'object' && value !== null) {
      streamEntry[key] = JSON.stringify(value);
    } else {
      streamEntry[key] = String(value);
    }
  }

  try {
    const pipeline = redis.multi();
    pipeline.xadd(streamKey, "*", streamEntry);
    pipeline.xtrim(streamKey, { strategy: "MAXLEN", threshold: MAX_LOG_ENTRIES });
    const results = await pipeline.exec();
    const loggedEntryId = results[0] as string | null;
    if (typeof loggedEntryId !== 'string' || !loggedEntryId) {
      throw new LoggerError("Failed to get log entry ID from XADD operation. Result was not a string or was empty.");
    }
    return loggedEntryId;
  } catch (error: unknown) {
    throw new LoggerError(`Failed to log to service ${service}`, error);
  }
}

export async function logInfo(
  service: string,
  message: string,
  details?: Record<string, unknown> | null
): Promise<string> {
  const traceId = generateLogId();
  const enhancedDetails = details ? { ...details, _trace_id: traceId } : { _trace_id: traceId };
  return logToStream("INFO", service, message, enhancedDetails);
}

export async function logWarn(
  service: string,
  message: string,
  details?: Record<string, unknown> | null
): Promise<string> {
  const traceId = generateLogId();
  const enhancedDetails = details ? { ...details, _trace_id: traceId } : { _trace_id: traceId };
  return logToStream("WARN", service, message, enhancedDetails);
}

export async function logError(
  service: string,
  message: string,
  errorDetails?: Error | Record<string, unknown> | null,
  additionalDetails?: Record<string, unknown> | null
): Promise<string> {
  const traceId = generateLogId();
  let combinedDetails: Record<string, unknown> = { _trace_id: traceId, ...(additionalDetails || {}) };
  if (errorDetails) {
    if (errorDetails instanceof Error) {
      combinedDetails.error_message = errorDetails.message;
      combinedDetails.error_stack = errorDetails.stack;
      combinedDetails.error_name = errorDetails.name;
    } else {
      combinedDetails = { ...combinedDetails, ...errorDetails };
    }
  }
  return logToStream("ERROR", service, message, combinedDetails);
}

export async function logDebug(
  service: string,
  message: string,
  details?: Record<string, unknown> | null
): Promise<string> {
  const traceId = generateLogId();
  const enhancedDetails = details ? { ...details, _trace_id: traceId } : { _trace_id: traceId };
  if (process.env.LOG_LEVEL === 'DEBUG' || process.env.NODE_ENV === 'development') {
    return logToStream("DEBUG", service, message, enhancedDetails);
  }
  return Promise.resolve("DEBUG_LOG_SKIPPED");
}

export async function getLogs(
  service: string,
  count: number = 100,
  startId: string = '-',
  endId: string = '+'
): Promise<LogEntry[]> {
  const redis = getRedisClient();
  const streamKey = `${LOG_STREAM_PREFIX}${service.toLowerCase()}`;
  try {
    const streamMessages = await redis.xrevrange(streamKey, endId, startId, count);
    if (!streamMessages || !Array.isArray(streamMessages) || streamMessages.length === 0) {
      return [];
    }
    const logEntries = streamMessages.map((msg: { message: Record<string, string>; id: string; }) => {
      const partialEntry: Partial<LogEntry> & { id: string } = { id: msg.id };
      for (const [key, value] of Object.entries(msg.message)) {
        if (key === 'details') {
          try {
            partialEntry.details = JSON.parse(value);
          } catch {
            partialEntry.details = { raw_details_parse_error: value };
          }
        } else if (key === 'level') {
          if (LogLevelSchema.safeParse(value).success) {
            partialEntry.level = value as LogLevel;
          }
        } else if (key === 'timestamp') {
          partialEntry.timestamp = value;
        } else if (key === 'service') {
          partialEntry.service = value;
        } else if (key === 'message') {
          partialEntry.message = value;
        } else {
          if (typeof partialEntry.details === 'object' && partialEntry.details !== null) {
            (partialEntry.details as Record<string, unknown>)[key] = value;
          } else if (!partialEntry.details) {
            partialEntry.details = { [key]: value };
          }
        }
      }
      return partialEntry as LogEntry;
    });
    return logEntries.filter(entry => {
      try {
        validateLogEntry(entry);
        return true;
      } catch {
        return false;
      }
    });
  } catch (error: unknown) {
    throw new LoggerError(`Failed to retrieve logs for service ${service}`, error);
  }
}

export async function deleteLogs(
  service: string,
  ids: string[]
): Promise<number> {
  const redis = getRedisClient();
  const streamKey = `${LOG_STREAM_PREFIX}${service.toLowerCase()}`;
  try {
    if (ids.length === 0) {
      return 0;
    }
    const result = await redis.xdel(streamKey, ids);
    return result as number;
  } catch (error: unknown) {
    throw new LoggerError(`Failed to delete logs for service ${service}`, error);
  }
}

export async function clearLogs(
  service: string
): Promise<boolean> {
  const redis = getRedisClient();
  const streamKey = `${LOG_STREAM_PREFIX}${service.toLowerCase()}`;
  try {
    const exists = await redis.exists(streamKey);
    if (!exists) {
      return false;
    }
    await redis.del(streamKey);
    return true;
  } catch (error: unknown) {
    throw new LoggerError(`Failed to clear logs for service ${service}`, error);
  }
}

export const upstashLogger = {
  info: (service: string, message: string, details?: Record<string, unknown> | null) => logInfo(service, message, details),
  warn: (service: string, message: string, details?: Record<string, unknown> | null) => logWarn(service, message, details),
  error: (service: string, message: string, errorDetails?: Error | Record<string, unknown> | null, additionalDetails?: Record<string, unknown> | null) => logError(service, message, errorDetails, additionalDetails),
  debug: (service: string, message: string, details?: Record<string, unknown> | null) => logDebug(service, message, details),
};

================
File: lib/memory/upstash/supabase-adapter.ts
================
/**
 * Upstash Supabase Adapter
 *
 * This module provides a compatibility layer to use Upstash Redis and Vector
 * as a replacement for Supabase. It implements similar interfaces and functionality
 * to make the transition seamless.
 *
 * @module upstash-supabase-adapter
 */

import {
  getRedisClient,
  getVectorClient
} from './upstashClients';
import {
  VectorDocument,
  VectorMetadata,
  VectorQueryOptions,
  VectorDocumentSchema,
  VectorStoreError
} from './upstashTypes';
import { upstashLogger } from './upstash-logger';
import { z } from 'zod';
import { generateEmbedding } from '../../ai-integration';
import {
  createRedisEntity,
  getRedisEntityById,
  updateRedisEntity,
  deleteRedisEntity,
  listRedisEntities,
  batchGetThreads,
  searchThreadsByMetadata,
  ListEntitiesOptions
} from './redis-store';
import {
  Thread,
  Message,
  AgentState,
  ToolExecutionEntity,
  WorkflowNode,
  LogEntry
} from './upstashTypes';
import { getSupabaseClient } from '../supabase';
import type { SupabaseClient } from '@supabase/supabase-js';
import type { Database } from '@/types/supabase';

export type TableName = keyof Database['public']['Tables'];
export type TableRow<T extends TableName = TableName> = Database['public']['Tables'][T]['Row'];
export type TableInsert<T extends TableName = TableName> = Database['public']['Tables'][T]['Insert'];
export type TableUpdate<T extends TableName = TableName> = Database['public']['Tables'][T]['Update'];

// --- Helper Functions ---

/**
 * Generates a Redis key for a table
 *
 * @param tableName - Table name
 * @returns Redis key for the table
 */
function getTableKey(tableName: string): string {
  return `table:${tableName}`;
}

/**
 * Generates a Redis key for a table row
 *
 * @param tableName - Table name
 * @param id - Row ID
 * @returns Redis key for the table row
 */
function getRowKey(tableName: string, id: string): string {
  return `${getTableKey(tableName)}:${id}`;
}

/**
 * Generates embeddings for text using AI integration
 * 
 * @param text - Text to generate embeddings for
 * @returns Promise resolving to embeddings array
 */
async function generateEmbeddings(text: string): Promise<number[]> {
  try {
    const embedding = await generateEmbedding(text);
    // generateEmbedding returns Float32Array or number[]
    return Array.isArray(embedding) ? embedding : Array.from(embedding);
  } catch (error) {
    upstashLogger.error('supabase-adapter', 'Error generating embeddings', error instanceof Error ? error : { message: String(error) });
    throw new VectorStoreError('Failed to generate embeddings');
  }
}

/**
 * Applies filters to a list of items
 *
 * @param items - List of items
 * @param filters - Filter options
 * @returns Filtered list of items
 */
function applyFilters<T>(items: T[], filters?: Array<{ field: string; operator: string; value: unknown }>): T[] {
  if (!filters || filters.length === 0) return items;
  return items.filter(item => {
    return filters.every(filter => {
      const value = (item as Record<string, unknown>)[filter.field];
      switch (filter.operator) {
        case 'eq': return value === filter.value;
        case 'neq': return value !== filter.value;
        case 'gt': return typeof value === 'number' && typeof filter.value === 'number' && value > filter.value;
        case 'gte': return typeof value === 'number' && typeof filter.value === 'number' && value >= filter.value;
        case 'lt': return typeof value === 'number' && typeof filter.value === 'number' && value < filter.value;
        case 'lte': return typeof value === 'number' && typeof filter.value === 'number' && value <= filter.value;
        case 'like': return typeof value === 'string' && typeof filter.value === 'string' && value.includes(filter.value);
        case 'ilike': return typeof value === 'string' && typeof filter.value === 'string' && value.toLowerCase().includes(filter.value.toLowerCase());
        case 'in': return Array.isArray(filter.value) && filter.value.includes(value);
        case 'is': return value === filter.value;
        default: return false;
      }
    });
  });
}

/**
 * Applies ordering to a list of items
 *
 * @param items - List of items
 * @param orderBy - Order options
 * @returns Ordered list of items
 */
function applyOrdering<T>(items: T[], orderBy?: { column: string; ascending?: boolean }): T[] {
  if (!orderBy) return items;
  const { column, ascending = true } = orderBy;
  return [...items].sort((a, b) => {
    const aValue = (a as Record<string, unknown>)[column];
    const bValue = (b as Record<string, unknown>)[column];
    if (aValue === bValue) return 0;
    if (aValue === null || aValue === undefined) return ascending ? 1 : -1;
    if (bValue === null || bValue === undefined) return ascending ? -1 : 1;
    if (ascending) return aValue > bValue ? 1 : -1;
    return aValue < bValue ? -1 : 1;
  });
}

/**
 * Applies pagination to a list of items
 *
 * @param items - List of items
 * @param limit - Limit of items
 * @param offset - Offset of items
 * @returns Paginated list of items
 */
function applyPagination<T>(items: T[], limit?: number, offset?: number): T[] {
  let result = items;
  if (offset !== undefined && offset > 0) result = result.slice(offset);
  if (limit !== undefined && limit > 0) result = result.slice(0, limit);
  return result;
}

/**
 * Selects specific fields from an item
 *
 * @param item - Item to select fields from
 * @param select - Fields to select
 * @returns Item with selected fields
 */
function selectFields<T extends object>(item: T, select?: string[]): Partial<T> {
  if (!select || select.length === 0) return item;
  const result: Partial<T> = {};
  for (const field of select) {
    if (field in item) {
      result[field as keyof T] = item[field as keyof T];
    }
  }
  return result;
}

// --- Primary Key Helper ---
/**
 * Returns the primary key field(s) for a given table/entity name.
 * For most entities, this is 'id', but for some (e.g. agent_tools, settings) it is a composite key.
 * Returns an array of key field names (for composite keys) or a single string for simple keys.
 */
export function getPrimaryKeyForTable(tableName: string): string | string[] {
  switch (tableName) {
    case 'agent_tools':
      return ['agent_id', 'tool_id'];
    case 'settings':
      return ['category', 'key'];
    default:
      return 'id';
  }
}

// --- Helper to extract primary key value(s) from an item ---
/**
 * Given a table name and an item, returns the primary key value(s) for that item.
 * For composite keys, returns an array of values in the correct order.
 * For single key, returns the value directly.
 */
export function getPrimaryKeyValue(tableName: string, item: unknown): string | string[] {
  const key = getPrimaryKeyForTable(tableName);
  if (Array.isArray(key)) {
    return key.map(k => (item as Record<string, string>)[k]);
  }
  return (item as Record<string, string>)[key];
}

// --- Types ---
export type FilterOptions = { field: string; operator: string; value: unknown };
export type OrderOptions = { column: string; ascending?: boolean };
export type QueryOptions = {
  filters?: FilterOptions[];
  orderBy?: OrderOptions;
  limit?: number;
  offset?: number;
  select?: string[];
};

// --- CRUD Functions ---

/**
 * Gets an item by ID from a table (Upstash-first, fallback to Supabase/LibSQL)
 */
export async function getItemById<T extends TableName>(tableName: T, id: string | string[]): Promise<TableRow<T> | null> {
  try {
    const redis = getRedisClient();
    const rowKey = getRowKey(tableName, Array.isArray(id) ? id.join(":") : id);
    const row = await redis.hgetall(rowKey);
    if (!row || Object.keys(row).length === 0) throw new Error('Not found');
    const parsed: Record<string, unknown> = {};
    for (const [k, v] of Object.entries(row)) {
      try { parsed[k] = JSON.parse(v as string); } catch { parsed[k] = v; }
    }
    return { ...parsed, id } as TableRow<T>;
  } catch (error) {
    upstashLogger.error('supabase-adapter', `Error getting item by id from table ${String(tableName)}`, error instanceof Error ? error : { message: String(error) });
    // Fallback to Supabase
    const supabase = getSupabaseClient() as SupabaseClient<Database>;
    const key = getPrimaryKeyForTable(tableName);
    let q = supabase.from(tableName).select('*');
    if (Array.isArray(key)) {
      if (!Array.isArray(id)) throw new Error('Composite key id must be string[]');
      // Use (k as unknown as string) for .eq() to satisfy Supabase's type system for composite keys and strict linters
      key.forEach((k, idx) => {
        q = q.eq(k as unknown as string, id[idx]);
      });
      const { data, error: supaErr } = await q.single();
      if (supaErr || !data) return null;
      return data as unknown as TableRow<T>;
    } else {
      // Use (key as unknown as string) for .eq() to satisfy Supabase's type system for single keys and strict linters
      const { data, error: supaErr } = await q.eq(key as unknown as string, id as string).single();
      if (supaErr || !data) return null;
      return data as unknown as TableRow<T>;
    }
  }
}

/**
 * Creates an item in a table (Upstash-first, fallback to Supabase/LibSQL)
 */
export async function createItem<T extends TableName>(tableName: T, item: TableInsert<T>): Promise<TableRow<T>> {
  try {
    const redis = getRedisClient();
    const keyValue = getPrimaryKeyValue(tableName, item);
    let id: string | undefined;
    if (Array.isArray(keyValue)) {
      id = keyValue.join(':');
    } else {
      id = keyValue || (typeof crypto !== 'undefined' ? crypto.randomUUID() : Math.random().toString(36).slice(2));
    }
    const rowKey = getRowKey(tableName, id);
    const toStore: Record<string, string> = {};
    for (const [k, v] of Object.entries(item)) {
      if (k !== 'id') toStore[k] = JSON.stringify(v);
    }
    await redis.hset(rowKey, toStore);
    await redis.sadd(`${getTableKey(tableName)}:ids`, id);
    return { ...item, id } as TableRow<T>;
  } catch (error) {
    upstashLogger.error('supabase-adapter', `Error creating item in table ${String(tableName)}`, error instanceof Error ? error : { message: String(error) });
    // Fallback to Supabase
    const supabase = getSupabaseClient() as SupabaseClient<Database>;
    // Use [item] as unknown as TableInsert<T>[] to satisfy Supabase's type system for generic inserts and strict linters
    const { data, error: supaErr } = await supabase.from(tableName).insert([item] as unknown as TableInsert<T>[]).select('*').single();
    if (supaErr || !data) throw new VectorStoreError(`Failed to create item in table ${String(tableName)}`);
    return data as unknown as TableRow<T>;
  }
}

/**
 * Updates an item in a table (Upstash-first, fallback to Supabase/LibSQL)
 */
export async function updateItem<T extends TableName>(
  tableName: T,
  id: string | string[],
  updates: TableUpdate<T>
): Promise<TableRow<T>> {
  try {
    const redis = getRedisClient();
    const rowKey = getRowKey(tableName, Array.isArray(id) ? id.join(":") : id);
    const toStore: Record<string, string> = {};
    for (const [k, v] of Object.entries(updates)) {
      if (k !== "id") toStore[k] = JSON.stringify(v);
    }
    await redis.hset(rowKey, toStore);
    const updated = await redis.hgetall(rowKey);
    if (!updated) throw new VectorStoreError("No data found after update");
    const parsed: Record<string, unknown> = {};
    for (const [k, v] of Object.entries(updated)) {
      try {
        parsed[k] = JSON.parse(v as string);
      } catch {
        parsed[k] = v;
      }
    }
    return { ...parsed, id } as TableRow<T>;
  } catch (error) {
    upstashLogger.error(
      "supabase-adapter",
      `Error updating item in table ${String(tableName)}`,
      error instanceof Error ? error : { message: String(error) }
    );
    // Fallback to Supabase
    const supabase = getSupabaseClient() as SupabaseClient<Database>;
    const key = getPrimaryKeyForTable(tableName);
    if (Array.isArray(key)) {
      if (!Array.isArray(id)) throw new Error("Composite key id must be string[]");
      // Use updates as unknown as TableUpdate<T> and (k as unknown as string) for .eq() to satisfy Supabase's type system for composite keys and strict linters
      let q = supabase.from(tableName).update(updates as unknown as TableUpdate<T>);
      key.forEach((k, idx) => {
        q = q.eq(k as unknown as string, id[idx]);
      });
      const { data, error: supaErr } = await q.select("*").single();
      if (supaErr) throw supaErr;
      return data as unknown as TableRow<T>;
    } else {
      // Use updates as unknown as TableUpdate<T> and (key as unknown as string) for .eq() to satisfy Supabase's type system for single keys and strict linters
      const { data, error: supaErr } = await supabase
        .from(tableName)
        .update(updates as unknown as TableUpdate<T>)
        .eq(key as unknown as string, id as string)
        .select("*")
        .single();
      if (supaErr) throw supaErr;
      return data as unknown as TableRow<T>;
    }
  }
}

/**
 * Deletes an item from a table (Upstash-first, fallback to Supabase/LibSQL)
 */
export async function deleteItem<T extends TableName>(
  tableName: T,
  id: string | string[]
): Promise<boolean> {
  try {
    const redis = getRedisClient();
    const rowKey = getRowKey(tableName, Array.isArray(id) ? id.join(":") : id);
    await redis.del(rowKey);
    await redis.srem(`${getTableKey(tableName)}:ids`, Array.isArray(id) ? id.join(":") : id);
    return true;
  } catch (error) {
    upstashLogger.error(
      "supabase-adapter",
      `Error deleting item from table ${String(tableName)}`,
      error instanceof Error ? error : { message: String(error) }
    );
    // Fallback to Supabase
    const supabase = getSupabaseClient() as SupabaseClient<Database>;
    const key = getPrimaryKeyForTable(tableName);
    if (Array.isArray(key)) {
      if (!Array.isArray(id)) throw new Error("Composite key id must be string[]");
      // Use (k as unknown as string) for .eq() to satisfy Supabase's type system for composite keys and strict linters
      let q = supabase.from(tableName).delete();
      key.forEach((k, idx) => {
        q = q.eq(k as unknown as string, id[idx]);
      });
      const { error: supaErr } = await q;
      if (supaErr) throw supaErr;
      return true;
    } else {
      // Use (key as unknown as string) for .eq() to satisfy Supabase's type system for single keys and strict linters
      const { error: supaErr } = await supabase
        .from(tableName)
        .delete()
        .eq(key as unknown as string, id as string);
      if (supaErr) throw supaErr;
      return true;
    }
  }
}

/**
 * Gets data from a table (Upstash-first, fallback to Supabase/LibSQL)
 */
export async function getData<T extends TableName>(
  tableName: T,
  options?: QueryOptions
): Promise<Array<TableRow<T>>> {
  try {
    // Try Upstash first
    const redis = getRedisClient();
    const ids = await redis.smembers(`${getTableKey(tableName)}:ids`);
    if (!ids || ids.length === 0) throw new Error('No data');
    const pipeline = redis.pipeline();
    for (const id of ids) {
      pipeline.hgetall(getRowKey(tableName, id));
    }
    const results = await pipeline.exec();
    const rows = (results as Array<Record<string, unknown> | null>).map((data, i) => {
      if (!data) return null;
      const parsed: Record<string, unknown> = {};
      for (const [k, v] of Object.entries(data)) {
        try { parsed[k] = JSON.parse(v as string); } catch { parsed[k] = v; }
      }
      return { ...parsed, id: ids[i] } as TableRow<T>;
    }).filter(Boolean) as TableRow<T>[];
    // Apply filters/order/pagination if needed
    let filtered = rows;
    if (options?.filters) filtered = applyFilters(filtered, options.filters);
    if (options?.orderBy) filtered = applyOrdering(filtered, options.orderBy);
    filtered = applyPagination(filtered, options?.limit, options?.offset);
    if (options?.select) filtered = filtered.map(e => selectFields(e, options.select) as TableRow<T>);
    return filtered;
  } catch (error) {
    upstashLogger.error('supabase-adapter', `Error getting data from table ${String(tableName)}`, error instanceof Error ? error : { message: String(error) });
    // Fallback to Supabase
    const supabase = getSupabaseClient() as SupabaseClient<Database>;
    let q = supabase.from(tableName).select('*');
    if (options?.filters) {
      for (const f of options.filters) {
        // Use (f.field as unknown as string) for .eq() to satisfy Supabase's type system for generic filters and strict linters
        q = q.eq(f.field as unknown as string, f.value);
      }
    }
    if (options?.orderBy) {
      q = q.order(options.orderBy.column as string, { ascending: options.orderBy.ascending ?? true });
    }
    if (options?.limit !== undefined && options?.offset !== undefined) {
      q = q.range(options.offset, options.offset + options.limit - 1);
    }
    const { data, error: supaErr } = await q;
    if (supaErr || !data) return [];
    if (options?.select) {
      return (data as unknown as TableRow<T>[]).map((e) => selectFields(e, options.select) as TableRow<T>);
    }
    return data as unknown as TableRow<T>[];
  }
}

/**
 * Performs a vector search using Upstash Vector
 *
 * @param query - Vector query
 * @param options - Search options
 * @returns Promise resolving to search results
 * @throws VectorStoreError if search fails
 */
export async function vectorSearch(
  query: number[] | string,
  options?: VectorQueryOptions
): Promise<unknown[]> {
  try {
    const vector = getVectorClient();
    const topK = options?.topK ?? 10;
    const includeMetadata = options?.includeMetadata ?? true;
    const includeVectors = options?.includeVectors ?? false;
    let filter: string | undefined = undefined;
    if (options?.filter && typeof options.filter === 'object') {
      filter = JSON.stringify(options.filter);
    } else if (typeof options?.filter === 'string') {
      filter = options.filter;
    }
    const searchQuery = Array.isArray(query) ? query : await generateEmbeddings(query);
    const result = await vector.query({
      vector: searchQuery,
      topK,
      includeMetadata,
      includeVectors,
      filter
    });
    return result;
  } catch (error: unknown) {
    upstashLogger.error('supabase-adapter', 'Error performing vector search', error instanceof Error ? error : { message: String(error) });
    throw new VectorStoreError('Failed to perform vector search');
  }
}

/**
 * Upserts vectors into Upstash Vector
 *
 * @param vectors - Vectors to upsert
 * @param options - Upsert options
 * @returns Promise resolving to upsert results
 * @throws VectorStoreError if upsert fails
 */
export async function upsertVectors(
  vectors: VectorDocument[],
  options?: { namespace?: string }
): Promise<unknown> {
  try {
    const vector = getVectorClient();
    const validatedVectors = z.array(VectorDocumentSchema).parse(vectors);
    const upserted = await vector.upsert(validatedVectors, options);
    return upserted;
  } catch (error: unknown) {
    upstashLogger.error('supabase-adapter', 'Error upserting vectors', error instanceof Error ? error : { message: String(error) });
    throw new VectorStoreError('Failed to upsert vectors');
  }
}

/**
 * Upserts vectors with sparse representation into Upstash Vector
 *
 * @param vectors - Vectors to upsert
 * @param options - Upsert options
 * @returns Promise resolving to upsert results
 * @throws VectorStoreError if upsert fails
 */
export async function upsertSupabaseVectors(
  vectors: Array<{ id: string; vector: number[]; metadata?: VectorMetadata }>,
  options?: { namespace?: string }
): Promise<unknown> {
  try {
    const vector = getVectorClient();
    const vectorsWithSparse = vectors.map(v => ({
      ...v,
      sparseVector: {
        indices: Array.from(v.vector.keys()),
        values: v.vector
      }
    }));
    const validatedVectors = z.array(VectorDocumentSchema).parse(vectorsWithSparse);
    const upserted = await vector.upsert(validatedVectors, options);
    return upserted;
  } catch (error: unknown) {
    upstashLogger.error('supabase-adapter', 'Error upserting supabase vectors', error instanceof Error ? error : { message: String(error) });
    throw new VectorStoreError('Failed to upsert supabase vectors');
  }
}

/**
 * Generates embeddings and upserts text to vector store
 * 
 * @param texts - Array of text items with IDs and optional metadata
 * @param options - Upsert options
 * @returns Promise resolving to upsert results
 * @throws VectorStoreError if operation fails
 */
export async function upsertTexts(
  texts: Array<{ id: string; text: string; metadata?: VectorMetadata }>,
  options?: { namespace?: string }
): Promise<unknown> {
  try {
    const vector = getVectorClient();
    const vectors: VectorDocument[] = await Promise.all(
      texts.map(async ({ id, text, metadata }) => ({
        id,
        vector: await generateEmbeddings(text),
        metadata,
        data: text
      }))
    );
    const validatedVectors = z.array(VectorDocumentSchema).parse(vectors);
    const upserted = await vector.upsert(validatedVectors, options);
    return upserted;
  } catch (error: unknown) {
    upstashLogger.error('supabase-adapter', 'Error upserting texts', error instanceof Error ? error : { message: String(error) });
    throw new VectorStoreError('Failed to upsert texts');
  }
}

/**
 * Performs a semantic search using text query
 * 
 * @param text - Text query
 * @param options - Search options
 * @returns Promise resolving to search results
 * @throws VectorStoreError if search fails
 */
export async function semanticSearch(
  text: string,
  options?: VectorQueryOptions
): Promise<unknown[]> {
  try {
    const embedding = await generateEmbeddings(text);
    return vectorSearch(embedding, options);
  } catch (error: unknown) {
    upstashLogger.error('supabase-adapter', 'Error performing semantic search', error instanceof Error ? error : { message: String(error) });
    throw new VectorStoreError('Failed to perform semantic search');
  }
}

// --- Enhanced Generic Entity CRUD API ---
export const entityApi = {
  create: createRedisEntity,
  getById: getRedisEntityById,
  update: updateRedisEntity,
  delete: deleteRedisEntity,
  list: listRedisEntities,
  batchGetThreads,
  searchThreadsByMetadata,
  upsertTexts,
  semanticSearch
};

// --- Enhanced Table CRUD helpers ---
export async function upsertItem<T extends TableName>(
  tableName: T,
  item: TableRow<T>
): Promise<TableRow<T>> {
  // Use getPrimaryKeyValue to support composite keys
  const key = getPrimaryKeyForTable(tableName);
  const id = Array.isArray(key)
    ? key.map((k) => (item as Record<string, string>)[k])
    : (item as Record<string, string>)[key];
  const found = await getItemById(tableName, id);
  if (found) return updateItem(tableName, id, item as TableUpdate<T>);
  return createItem(tableName, item as TableInsert<T>);
}

export async function existsItem<T extends TableName>(tableName: T, id: string): Promise<boolean> {
  const found = await getItemById(tableName, id);
  return !!found;
}

export async function countItems<T extends TableName>(tableName: T, options?: QueryOptions): Promise<number> {
  const all = await getData(tableName, options);
  return all.length;
}

export async function batchGetItems<T extends TableName>(tableName: T, ids: string[]): Promise<(TableRow<T> | null)[]> {
  if (tableName === 'thread') {
    return batchGetThreads(ids) as Promise<(TableRow<T> | null)[]>;
  }
  return Promise.all(ids.map(id => getItemById(tableName, id) as Promise<TableRow<T> | null>));
}

// --- Export all types for downstream use ---
export type {
  ListEntitiesOptions,
  Thread,
  Message,
  AgentState,
  ToolExecutionEntity,
  WorkflowNode,
  LogEntry,
  VectorDocument,
  VectorMetadata,
  VectorQueryOptions
};

export { applyFilters, applyOrdering, applyPagination, selectFields };

================
File: lib/memory/upstash/redis-store.ts
================
import { generateId } from 'ai';
import { createItem, getItemById, updateItem, deleteItem, getData, applyFilters, applyOrdering, applyPagination, selectFields, type QueryOptions, type TableName, type TableRow, type TableInsert, type TableUpdate } from './supabase-adapter';
import { z } from 'zod';

import {
  UserEntity,
  WorkflowEntity,
  UserEntitySchema,
  WorkflowEntitySchema,
  ToolExecutionEntity,
  ToolExecutionEntitySchema,
  WorkflowNodeEntity,
  WorkflowNodeEntitySchema,
  LogEntryEntity,
  LogEntryEntitySchema,
  ListEntitiesOptions,
  RedisStoreError,
  Thread,
  Message,
  RedisHashData,
  ThreadMetadata,
  RediSearchHybridQuery,
  RediSearchHybridResult,
  QStashTaskPayload,
  WorkflowNode,
  SettingsEntity,
  SettingsEntitySchema,
  SystemMetricEntity,
  SystemMetricEntitySchema,
  TraceEntity,
  TraceEntitySchema,
  SpanEntity,
  SpanEntitySchema,
  EventEntity,
  EventEntitySchema,
  ProviderEntity,
  ProviderEntitySchema,
  ModelEntity,
  ModelEntitySchema,
  AuthProviderEntity,
  AuthProviderEntitySchema,
  DashboardConfigEntity,
  DashboardConfigEntitySchema
} from './upstashTypes';

import {
  getRedisClient,
  runRediSearchHybridQuery,
  enqueueQStashTask,
  trackWorkflowNode,
  shouldFallbackToBackup
} from './upstashClients';
import { logError } from './upstash-logger';

// --- Constants for Redis Keys ---
const THREAD_PREFIX = "thread:";
const THREADS_SET = "threads"; // Sorted set for all thread IDs, scored by last update timestamp
const THREAD_MESSAGES_SET_SUFFIX = ":messages"; // Set of message IDs for a thread
const MESSAGE_PREFIX = "message:";

// --- Logger-safe error helper ---
function toLoggerError(err: unknown): Error | { error: string } {
  if (err instanceof Error) return err;
  return { error: String(err) };
}

// Helper to prepare data for Redis (handles metadata stringification)
function prepareDataForRedis<T extends { metadata?: Record<string, unknown> | null }>(data: T): RedisHashData {
  const result: RedisHashData = {};
  for (const [k, v] of Object.entries(data)) {
    if (k === 'metadata' && v != null) {
      result[k] = JSON.stringify(v);
    } else if (v !== undefined) {
      result[k] = v as string | number | boolean | null;
    }
  }
  return result;
}

// Overload for generic objects without metadata
function prepareDataForRedisGeneric(data: object): RedisHashData {
  const result: RedisHashData = {};
  for (const [k, v] of Object.entries(data)) {
    result[k] = v as string | number | boolean | null;
  }
  return result;
}

// Helper to parse raw Redis data and metadata string into the target type
function parseRedisHashData<T extends { metadata?: Record<string, unknown> | null }>(rawData: RedisHashData | null): T | null {
  if (!rawData) return null;
  const parsed: Record<string, unknown> = { ...rawData };
  if (parsed.metadata && typeof parsed.metadata === 'string') {
    try { parsed.metadata = JSON.parse(parsed.metadata); } catch { parsed.metadata = null; }
  }
  return parsed as T;
}

// Overload for generic objects without metadata
function parseRedisHashDataGeneric<T extends object>(rawData: RedisHashData | null): T | null {
  if (!rawData) return null;
  return { ...rawData } as T;
}

// --- Primary Key Helper ---
/**
 * Returns the primary key field(s) for a given table/entity name.
 * For most entities, this is 'id', but for some (e.g. agent_tools, settings) it is a composite key.
 * Returns an array of key field names (for composite keys) or a single string for simple keys.
 */
export function getPrimaryKeyForTable(tableName: string): string | string[] {
  switch (tableName) {
    case 'agent_tools':
      return ['agent_id', 'tool_id'];
    case 'settings':
      return ['category', 'key'];
    default:
      return 'id';
  }
}

// --- TableName mapping and type guard ---
const upstashToSupabaseTable: Record<string, TableName> = {
  user: 'users',
  workflow: 'workflows',
  tool_execution: 'tools',
  workflow_node: 'workflow_steps',
  log_entry: 'events',
  settings: 'settings',
  system_metric: 'model_performance',
  trace: 'traces',
  span: 'spans',
  event: 'events',
  provider: 'agents',
  model: 'models',
  auth_provider: 'agent_personas',
  dashboard_config: 'documents',
};
export function getSupabaseTableName(entityType: string): TableName | undefined {
  return upstashToSupabaseTable[entityType];
}

// --- Thread Operations ---
export async function createRedisThread(
  name?: string | null,
  userId?: string | null,
  agentId?: string | null,
  initialMetadata?: ThreadMetadata | null
): Promise<Thread> {
  const redis = getRedisClient();
  const threadId = generateId();
  const now = new Date().toISOString();
  const thread: Thread = {
    id: threadId,
    name: name || '',
    user_id: userId || '',
    agent_id: agentId || '',
    metadata: initialMetadata || {},
    created_at: now,
    updated_at: now,
  };
  try {
    await redis.hset(`${THREAD_PREFIX}${threadId}`, prepareDataForRedis(thread));
    await redis.zadd(THREADS_SET, { score: Date.now(), member: threadId });
    return thread;
  } catch (err) {
    await logError('redis-store', 'Failed to create thread', toLoggerError(err));
    throw new RedisStoreError('Failed to create thread', err);
  }
}

export async function getRedisThreadById(threadId: string): Promise<Thread | null> {
  const redis = getRedisClient();
  try {
    const data = await redis.hgetall(`${THREAD_PREFIX}${threadId}`);
    return parseRedisHashData<Thread>(data as RedisHashData);
  } catch (err) {
    await logError('redis-store', 'Failed to get thread by id', toLoggerError(err));
    throw new RedisStoreError('Failed to get thread by id', err);
  }
}

export async function updateRedisThread(
  threadId: string,
  updates: Partial<Pick<Thread, 'name' | 'metadata' | 'user_id' | 'agent_id'>>
): Promise<Thread | null> {
  const redis = getRedisClient();
  try {
    const existing = await getRedisThreadById(threadId);
    if (!existing) return null;
    const updated: Thread = {
      ...existing,
      ...updates,
      updated_at: new Date().toISOString(),
    };
    await redis.hset(`${THREAD_PREFIX}${threadId}`, prepareDataForRedis(updated));
    await redis.zadd(THREADS_SET, { score: Date.now(), member: threadId });
    return updated;
  } catch (err) {
    await logError('redis-store', 'Failed to update thread', toLoggerError(err));
    throw new RedisStoreError('Failed to update thread', err);
  }
}

export async function listRedisThreads(
  limit: number = 10,
  offset: number = 0,
  userId?: string,
  agentId?: string
): Promise<Thread[]> {
  const redis = getRedisClient();
  try {
    const threadIds = (await redis.zrange(THREADS_SET, offset, offset + limit - 1, { rev: true })) as string[];
    const threads: Thread[] = [];
    for (const threadId of threadIds) {
      const thread = await getRedisThreadById(threadId);
      if (thread) {
        if ((userId && thread.user_id !== userId) || (agentId && thread.agent_id !== agentId)) continue;
        threads.push(thread);
      }
    }
    return threads;
  } catch (err) {
    await logError('redis-store', 'Failed to list threads', toLoggerError(err));
    throw new RedisStoreError('Failed to list threads', err);
  }
}

export async function deleteRedisThread(threadId: string): Promise<boolean> {
  const redis = getRedisClient();
  try {
    const messageIds = (await redis.smembers(`${THREAD_PREFIX}${threadId}${THREAD_MESSAGES_SET_SUFFIX}`)) as string[];
    for (const messageId of messageIds) {
      await redis.del(`${MESSAGE_PREFIX}${messageId}`);
    }
    await redis.del(`${THREAD_PREFIX}${threadId}${THREAD_MESSAGES_SET_SUFFIX}`);
    await redis.del(`${THREAD_PREFIX}${threadId}`);
    await redis.zrem(THREADS_SET, threadId);
    return true;
  } catch (err) {
    await logError('redis-store', 'Failed to delete thread', toLoggerError(err));
    throw new RedisStoreError('Failed to delete thread', err);
  }
}

// --- Message Operations ---
export async function createRedisMessage(
  threadId: string,
  messageData: Omit<Message, 'id' | 'thread_id' | 'created_at'>
): Promise<Message> {
  const redis = getRedisClient();
  const messageId = generateId();
  const now = new Date().toISOString();
  const message: Message = {
    id: messageId,
    thread_id: threadId,
    ...messageData,
    created_at: now,
  };
  try {
    await redis.hset(`${MESSAGE_PREFIX}${messageId}`, prepareDataForRedis(message));
    await redis.sadd(`${THREAD_PREFIX}${threadId}${THREAD_MESSAGES_SET_SUFFIX}`, messageId);
    await redis.hset(`${THREAD_PREFIX}${threadId}`, { updated_at: now });
    return message;
  } catch (err) {
    await logError('redis-store', 'Failed to create message', toLoggerError(err));
    throw new RedisStoreError('Failed to create message', err);
  }
}

export async function getRedisMessageById(messageId: string): Promise<Message | null> {
  const redis = getRedisClient();
  try {
    const data = await redis.hgetall(`${MESSAGE_PREFIX}${messageId}`);
    return parseRedisHashData<Message>(data as RedisHashData);
  } catch (err) {
    await logError('redis-store', 'Failed to get message by id', toLoggerError(err));
    throw new RedisStoreError('Failed to get message by id', err);
  }
}

export async function getRedisMessagesByThreadId(
  threadId: string,
  limit: number = 50,
  offset: number = 0,
  order: 'asc' | 'desc' = 'asc'
): Promise<Message[]> {
  const redis = getRedisClient();
  try {
    const messageIds = (await redis.smembers(`${THREAD_PREFIX}${threadId}${THREAD_MESSAGES_SET_SUFFIX}`)) as string[];
    const sorted = messageIds.slice();
    if (order === 'asc') sorted.sort();
    else sorted.sort().reverse();
    const paged = sorted.slice(offset, offset + limit);
    const messages: Message[] = [];
    for (const messageId of paged) {
      const msg = await getRedisMessageById(messageId);
      if (msg) messages.push(msg);
    }
    return messages;
  } catch (err) {
    await logError('redis-store', 'Failed to get messages by thread id', toLoggerError(err));
    throw new RedisStoreError('Failed to get messages by thread id', err);
  }
}

export async function deleteRedisMessage(
  threadId: string, 
  messageId: string
): Promise<boolean> {
  const redis = getRedisClient();
  try {
    await redis.del(`${MESSAGE_PREFIX}${messageId}`);
    await redis.srem(`${THREAD_PREFIX}${threadId}${THREAD_MESSAGES_SET_SUFFIX}`, messageId);
    return true;
  } catch (err) {
    await logError('redis-store', 'Failed to delete message', toLoggerError(err));
    throw new RedisStoreError('Failed to delete message', err);
  }
}

// --- Hybrid Search Example (Vector + Redis) ---
export async function hybridThreadSearch({
  query,
  limit = 10,
  userId,
  agentId,
  vectorSearchFn,
}: {
  query: string;
  limit?: number;
  userId?: string;
  agentId?: string;
  vectorSearchFn?: (q: string, l: number) => Promise<string[]>;
}): Promise<Thread[]> {
  try {
    let threadIds: string[] = [];
    if (vectorSearchFn) {
      threadIds = await vectorSearchFn(query, limit);
    }
    // Fallback: If no vector results, do a Redis search
    if (!threadIds.length) {
      const redis = getRedisClient();
      const allIds = (await redis.zrange(THREADS_SET, 0, -1, { rev: true })) as string[];
      threadIds = allIds.slice(0, limit);
    }
    const threads: Thread[] = [];
    for (const threadId of threadIds) {
      const thread = await getRedisThreadById(threadId);
      if (thread) {
        if ((userId && thread.user_id !== userId) || (agentId && thread.agent_id !== agentId)) continue;
        threads.push(thread);
      }
    }
    return threads;
  } catch (err) {
    await logError('redis-store', 'Failed hybrid thread search', toLoggerError(err));
    throw new RedisStoreError('Failed hybrid thread search', err);
  }
}

// --- Advanced RediSearch/Hybrid Search ---
export async function advancedThreadHybridSearch(query: RediSearchHybridQuery): Promise<RediSearchHybridResult[]> {
  try {
    const results = await runRediSearchHybridQuery(query);
    return results as RediSearchHybridResult[];
  } catch (err) {
    await logError('redis-store', 'Failed advanced hybrid search', toLoggerError(err));
    throw new RedisStoreError('Failed advanced hybrid search', err);
  }
}

// --- QStash/Workflow Integration Example ---
export async function enqueueThreadWorkflow(threadId: string, type: string, data: Record<string, unknown>) {
  const payload: QStashTaskPayload = {
    id: generateId(),
    type,
    data: { threadId, ...data },
    created_at: new Date().toISOString(),
    status: 'pending',
  };
  return enqueueQStashTask(payload);
}

export async function trackThreadWorkflowNode(node: WorkflowNode) {
  return trackWorkflowNode(node);
}

// --- Generic Entity CRUD ---
/**
 * Generic create for any entity type (Upstash-first, fallback to Supabase/LibSQL)
 */
export async function createRedisEntity<T extends object>(
  entityType: string,
  entity: T,
  schema?: z.ZodType<T>
): Promise<T> {
  try {
    if (schema) schema.parse(entity);
    const redis = getRedisClient();
    const id = (entity as { id?: string }).id || generateId();
    const key = `${entityType}:${id}`;
    // Use correct prepareDataForRedis overload
    const redisData = 'metadata' in entity
      ? prepareDataForRedis(entity as { metadata?: Record<string, unknown> | null })
      : prepareDataForRedisGeneric({ ...entity, id });
    await redis.hset(key, redisData);
    await redis.sadd(`${entityType}:ids`, id);
    return { ...entity, id };
  } catch (err) {
    await logError('redis-store', `Failed to create entity: ${entityType}`, toLoggerError(err));
    if (shouldFallbackToBackup()) {
      const supabaseTable = getSupabaseTableName(entityType);
      if (supabaseTable) {
        return createItem(
          supabaseTable,
          entity as TableInsert<typeof supabaseTable>
        ) as Promise<TableRow<typeof supabaseTable>> as unknown as Promise<T>;
      }
    }
    throw new RedisStoreError(`Failed to create entity: ${entityType}`, err);
  }
}

/**
 * Generic get by ID for any entity type
 */
export async function getRedisEntityById<T extends object>(entityType: string, id: string): Promise<T | null> {
  try {
    const redis = getRedisClient();
    const data = await redis.hgetall(`${entityType}:${id}`);
    return parseRedisHashData<T>(data as RedisHashData);
  } catch (err) {
    await logError('redis-store', `Failed to get entity by id: ${entityType}`, toLoggerError(err));
    if (shouldFallbackToBackup()) {
      const supabaseTable = getSupabaseTableName(entityType);
      if (supabaseTable) {
        return getItemById(supabaseTable, id) as Promise<TableRow<typeof supabaseTable> | null> as unknown as Promise<T | null>;
      }
    }
    throw new RedisStoreError(`Failed to get entity by id: ${entityType}`, err);
  }
}

/**
 * Generic update for any entity type
 */
export async function updateRedisEntity<T extends object>(entityType: string, id: string, updates: Partial<T>, schema?: z.ZodType<T>): Promise<T | null> {
  try {
    if (schema) schema.parse({ ...updates, id });
    const redis = getRedisClient();
    const key = `${entityType}:${id}`;
    const existing = await getRedisEntityById<T>(entityType, id);
    if (!existing) return null;
    const updated = { ...existing, ...updates };
    await redis.hset(key, prepareDataForRedis(updated));
    return updated;
  } catch (err) {
    await logError('redis-store', `Failed to update entity: ${entityType}`, toLoggerError(err));
    if (shouldFallbackToBackup()) {
      const supabaseTable = getSupabaseTableName(entityType);
      if (supabaseTable) {
        return updateItem(
          supabaseTable,
          id,
          updates as TableUpdate<typeof supabaseTable>
        ) as Promise<TableRow<typeof supabaseTable> | null> as unknown as Promise<T | null>;
      }
    }
    throw new RedisStoreError(`Failed to update entity: ${entityType}`, err);
  }
}

/**
 * Generic delete for any entity type
 */
export async function deleteRedisEntity(entityType: string, id: string): Promise<boolean> {
  try {
    const redis = getRedisClient();
    const key = `${entityType}:${id}`;
    await redis.del(key);
    await redis.srem(`${entityType}:ids`, id);
    return true;
  } catch (err) {
    await logError('redis-store', `Failed to delete entity: ${entityType}`, toLoggerError(err));
    if (shouldFallbackToBackup()) {
      const supabaseTable = getSupabaseTableName(entityType);
      if (supabaseTable) {
        return deleteItem(supabaseTable, id);
      }
    }
    throw new RedisStoreError(`Failed to delete entity: ${entityType}`, err);
  }
}

/**
 * Generic list/search for any entity type (with optional filters, order, pagination)
 */
export async function listRedisEntities<T extends object>(
  entityType: string,
  options?: ListEntitiesOptions
): Promise<T[]> {
  try {
    const redis = getRedisClient();
    const ids = await redis.smembers(`${entityType}:ids`);
    if (!ids || ids.length === 0) return [];
    const pipeline = redis.pipeline();
    for (const id of ids) {
      pipeline.hgetall(`${entityType}:${id}`);
    }
    const results = await pipeline.exec();
    let entities = (results as Array<Record<string, unknown> | null>).map((data) => {
      if (!data) return null;
      return parseRedisHashData<T>(data as RedisHashData);
    }).filter((e): e is T => !!e);
    if (options?.filters) {
      const filterArray = Object.entries(options.filters).map(([field, value]) => ({ field, operator: 'eq', value }));
      entities = applyFilters(entities, filterArray);
    }
    if (options?.sortBy) {
      entities = applyOrdering(entities, { column: options.sortBy, ascending: options.sortOrder !== 'DESC' });
    }
    entities = applyPagination(entities, options?.limit, options?.offset);
    if (options?.select) entities = entities.map(e => selectFields(e, options.select) as T);
    return entities;
  } catch (err) {
    await logError('redis-store', `Failed to list entities: ${entityType}`, toLoggerError(err));
    if (shouldFallbackToBackup()) {
      const supabaseTable = getSupabaseTableName(entityType);
      if (supabaseTable) {
        // Map ListEntitiesOptions to QueryOptions for Supabase
        const queryOptions: QueryOptions = {
          select: options?.select,
          filters: options?.filters
            ? Object.entries(options.filters).map(([field, value]) => ({ field, operator: 'eq', value }))
            : undefined,
          orderBy: options?.sortBy ? { column: options.sortBy, ascending: options.sortOrder !== 'DESC' } : undefined,
          limit: options?.limit,
          offset: options?.offset,
        };
        return getData(supabaseTable, queryOptions) as Promise<TableRow<typeof supabaseTable>[]> as unknown as Promise<T[]>;
      }
    }
    throw new RedisStoreError(`Failed to list entities: ${entityType}`, err);
  }
}

// Example: Use pipelining for batch operations
export async function batchGetThreads(threadIds: string[]): Promise<(Thread | null)[]> {
  try {
    const redis = getRedisClient();
    const pipeline = redis.pipeline();
    for (const threadId of threadIds) {
      pipeline.hgetall(`${THREAD_PREFIX}${threadId}`);
    }
    const results = await pipeline.exec();
    return (results as Array<Record<string, unknown> | null>).map((data) => {
      if (!data) return null;
      try {
        return parseRedisHashData<Thread>(data as RedisHashData);
      } catch (e) {
        logError('redis-store', 'Thread parse error', toLoggerError(e));
        return null;
      }
    });
  } catch (err) {
    await logError('redis-store', 'Error in batchGetThreads', toLoggerError(err));
    throw new RedisStoreError('Error in batchGetThreads', err);
  }
}

// --- RediSearch: Advanced Query Support for API Integration ---
/**
 * Search threads by metadata using Redis and in-memory filtering.
 * This is robust and ready for API route integration (e.g. /api/threads/search).
 *
 * @param query - Metadata fields to match (e.g. { user_id: 'abc', agent_id: 'xyz' })
 * @param options - Optional limit, offset
 * @returns Array of matching Thread objects
 */
export async function searchThreadsByMetadata(
  query: Record<string, unknown>,
  options?: { limit?: number; offset?: number }
): Promise<Thread[]> {
  try {
    const threads = await listRedisThreads(1000, 0); // Get all threads (or a large page)
    const matches = threads.filter(thread => {
      if (!thread.metadata) return false;
      return Object.entries(query).every(([k, v]) => {
        return thread.metadata && thread.metadata[k] === v;
      });
    });
    const offset = options?.offset ?? 0;
    const limit = options?.limit ?? 10;
    return matches.slice(offset, offset + limit);
  } catch (err) {
    await logError('redis-store', 'Failed RediSearch query', toLoggerError(err));
    throw new RedisStoreError('Failed RediSearch query', err);
  }
}

// --- Helper functions for filtering, ordering, pagination, select ---

// --- UserEntity CRUD ---
export async function createRedisUser(user: UserEntity): Promise<UserEntity> {
  return createRedisEntity<UserEntity>('user', user, UserEntitySchema);
}
export async function getRedisUserById(id: string): Promise<UserEntity | null> {
  return getRedisEntityById<UserEntity>('user', id);
}
export async function updateRedisUser(id: string, updates: Partial<UserEntity>): Promise<UserEntity | null> {
  return updateRedisEntity<UserEntity>('user', id, updates, UserEntitySchema);
}
export async function deleteRedisUser(id: string): Promise<boolean> {
  return deleteRedisEntity('user', id);
}
export async function listRedisUsers(options?: ListEntitiesOptions): Promise<UserEntity[]> {
  return listRedisEntities<UserEntity>('user', options);
}

// --- WorkflowEntity CRUD ---
export async function createRedisWorkflow(workflow: WorkflowEntity): Promise<WorkflowEntity> {
  return createRedisEntity<WorkflowEntity>('workflow', workflow, WorkflowEntitySchema);
}
export async function getRedisWorkflowById(id: string): Promise<WorkflowEntity | null> {
  return getRedisEntityById<WorkflowEntity>('workflow', id);
}
export async function updateRedisWorkflow(id: string, updates: Partial<WorkflowEntity>): Promise<WorkflowEntity | null> {
  return updateRedisEntity<WorkflowEntity>('workflow', id, updates, WorkflowEntitySchema);
}
export async function deleteRedisWorkflow(id: string): Promise<boolean> {
  return deleteRedisEntity('workflow', id);
}
export async function listRedisWorkflows(options?: ListEntitiesOptions): Promise<WorkflowEntity[]> {
  return listRedisEntities<WorkflowEntity>('workflow', options);
}

// --- ToolExecutionEntity CRUD ---
export async function createRedisToolExecution(exec: ToolExecutionEntity): Promise<ToolExecutionEntity> {
  return createRedisEntity<ToolExecutionEntity>('tool_execution', exec, ToolExecutionEntitySchema);
}
export async function getRedisToolExecutionById(id: string): Promise<ToolExecutionEntity | null> {
  return getRedisEntityById<ToolExecutionEntity>('tool_execution', id);
}
export async function updateRedisToolExecution(id: string, updates: Partial<ToolExecutionEntity>): Promise<ToolExecutionEntity | null> {
  return updateRedisEntity<ToolExecutionEntity>('tool_execution', id, updates, ToolExecutionEntitySchema);
}
export async function deleteRedisToolExecution(id: string): Promise<boolean> {
  return deleteRedisEntity('tool_execution', id);
}
export async function listRedisToolExecutions(options?: ListEntitiesOptions): Promise<ToolExecutionEntity[]> {
  return listRedisEntities<ToolExecutionEntity>('tool_execution', options);
}

// --- WorkflowNodeEntity CRUD ---
export async function createRedisWorkflowNode(node: WorkflowNodeEntity): Promise<WorkflowNodeEntity> {
  return createRedisEntity<WorkflowNodeEntity>('workflow_node', node, WorkflowNodeEntitySchema);
}
export async function getRedisWorkflowNodeById(id: string): Promise<WorkflowNodeEntity | null> {
  return getRedisEntityById<WorkflowNodeEntity>('workflow_node', id);
}
export async function updateRedisWorkflowNode(id: string, updates: Partial<WorkflowNodeEntity>): Promise<WorkflowNodeEntity | null> {
  return updateRedisEntity<WorkflowNodeEntity>('workflow_node', id, updates, WorkflowNodeEntitySchema);
}
export async function deleteRedisWorkflowNode(id: string): Promise<boolean> {
  return deleteRedisEntity('workflow_node', id);
}
export async function listRedisWorkflowNodes(options?: ListEntitiesOptions): Promise<WorkflowNodeEntity[]> {
  return listRedisEntities<WorkflowNodeEntity>('workflow_node', options);
}

// --- LogEntryEntity CRUD ---
export async function createRedisLogEntry(entry: LogEntryEntity): Promise<LogEntryEntity> {
  return createRedisEntity<LogEntryEntity>('log_entry', entry, LogEntryEntitySchema);
}
export async function getRedisLogEntryById(id: string): Promise<LogEntryEntity | null> {
  return getRedisEntityById<LogEntryEntity>('log_entry', id);
}
export async function updateRedisLogEntry(id: string, updates: Partial<LogEntryEntity>): Promise<LogEntryEntity | null> {
  return updateRedisEntity<LogEntryEntity>('log_entry', id, updates, LogEntryEntitySchema);
}
export async function deleteRedisLogEntry(id: string): Promise<boolean> {
  return deleteRedisEntity('log_entry', id);
}
export async function listRedisLogEntries(options?: ListEntitiesOptions): Promise<LogEntryEntity[]> {
  return listRedisEntities<LogEntryEntity>('log_entry', options);
}

// --- SettingsEntity CRUD ---
export async function createRedisSettings(settings: SettingsEntity): Promise<SettingsEntity> {
  return createRedisEntity<SettingsEntity>('settings', settings, SettingsEntitySchema);
}
export async function getRedisSettingsById(id: string): Promise<SettingsEntity | null> {
  return getRedisEntityById<SettingsEntity>('settings', id);
}
export async function updateRedisSettings(id: string, updates: Partial<SettingsEntity>): Promise<SettingsEntity | null> {
  return updateRedisEntity<SettingsEntity>('settings', id, updates, SettingsEntitySchema);
}
export async function deleteRedisSettings(id: string): Promise<boolean> {
  return deleteRedisEntity('settings', id);
}
export async function listRedisSettings(options?: ListEntitiesOptions): Promise<SettingsEntity[]> {
  return listRedisEntities<SettingsEntity>('settings', options);
}

// --- SystemMetricEntity CRUD ---
export async function createRedisSystemMetric(metric: SystemMetricEntity): Promise<SystemMetricEntity> {
  return createRedisEntity<SystemMetricEntity>('system_metric', metric, SystemMetricEntitySchema);
}
export async function getRedisSystemMetricById(id: string): Promise<SystemMetricEntity | null> {
  return getRedisEntityById<SystemMetricEntity>('system_metric', id);
}
export async function updateRedisSystemMetric(id: string, updates: Partial<SystemMetricEntity>): Promise<SystemMetricEntity | null> {
  return updateRedisEntity<SystemMetricEntity>('system_metric', id, updates, SystemMetricEntitySchema);
}
export async function deleteRedisSystemMetric(id: string): Promise<boolean> {
  return deleteRedisEntity('system_metric', id);
}
export async function listRedisSystemMetrics(options?: ListEntitiesOptions): Promise<SystemMetricEntity[]> {
  return listRedisEntities<SystemMetricEntity>('system_metric', options);
}

// --- TraceEntity CRUD ---
export async function createRedisTrace(trace: TraceEntity): Promise<TraceEntity> {
  return createRedisEntity<TraceEntity>('trace', trace, TraceEntitySchema);
}
export async function getRedisTraceById(id: string): Promise<TraceEntity | null> {
  return getRedisEntityById<TraceEntity>('trace', id);
}
export async function updateRedisTrace(id: string, updates: Partial<TraceEntity>): Promise<TraceEntity | null> {
  return updateRedisEntity<TraceEntity>('trace', id, updates, TraceEntitySchema);
}
export async function deleteRedisTrace(id: string): Promise<boolean> {
  return deleteRedisEntity('trace', id);
}
export async function listRedisTraces(options?: ListEntitiesOptions): Promise<TraceEntity[]> {
  return listRedisEntities<TraceEntity>('trace', options);
}

// --- SpanEntity CRUD ---
export async function createRedisSpan(span: SpanEntity): Promise<SpanEntity> {
  return createRedisEntity<SpanEntity>('span', span, SpanEntitySchema);
}
export async function getRedisSpanById(id: string): Promise<SpanEntity | null> {
  return getRedisEntityById<SpanEntity>('span', id);
}
export async function updateRedisSpan(id: string, updates: Partial<SpanEntity>): Promise<SpanEntity | null> {
  return updateRedisEntity<SpanEntity>('span', id, updates, SpanEntitySchema);
}
export async function deleteRedisSpan(id: string): Promise<boolean> {
  return deleteRedisEntity('span', id);
}
export async function listRedisSpans(options?: ListEntitiesOptions): Promise<SpanEntity[]> {
  return listRedisEntities<SpanEntity>('span', options);
}

// --- EventEntity CRUD ---
export async function createRedisEvent(event: EventEntity): Promise<EventEntity> {
  return createRedisEntity<EventEntity>('event', event, EventEntitySchema);
}
export async function getRedisEventById(id: string): Promise<EventEntity | null> {
  return getRedisEntityById<EventEntity>('event', id);
}
export async function updateRedisEvent(id: string, updates: Partial<EventEntity>): Promise<EventEntity | null> {
  return updateRedisEntity<EventEntity>('event', id, updates, EventEntitySchema);
}
export async function deleteRedisEvent(id: string): Promise<boolean> {
  return deleteRedisEntity('event', id);
}
export async function listRedisEvents(options?: ListEntitiesOptions): Promise<EventEntity[]> {
  return listRedisEntities<EventEntity>('event', options);
}

// --- ProviderEntity CRUD ---
export async function createRedisProvider(provider: ProviderEntity): Promise<ProviderEntity> {
  return createRedisEntity<ProviderEntity>('provider', provider, ProviderEntitySchema);
}
export async function getRedisProviderById(id: string): Promise<ProviderEntity | null> {
  return getRedisEntityById<ProviderEntity>('provider', id);
}
export async function updateRedisProvider(id: string, updates: Partial<ProviderEntity>): Promise<ProviderEntity | null> {
  return updateRedisEntity<ProviderEntity>('provider', id, updates, ProviderEntitySchema);
}
export async function deleteRedisProvider(id: string): Promise<boolean> {
  return deleteRedisEntity('provider', id);
}
export async function listRedisProviders(options?: ListEntitiesOptions): Promise<ProviderEntity[]> {
  return listRedisEntities<ProviderEntity>('provider', options);
}

// --- ModelEntity CRUD ---
export async function createRedisModel(model: ModelEntity): Promise<ModelEntity> {
  return createRedisEntity<ModelEntity>('model', model, ModelEntitySchema);
}
export async function getRedisModelById(id: string): Promise<ModelEntity | null> {
  return getRedisEntityById<ModelEntity>('model', id);
}
export async function updateRedisModel(id: string, updates: Partial<ModelEntity>): Promise<ModelEntity | null> {
  return updateRedisEntity<ModelEntity>('model', id, updates, ModelEntitySchema);
}
export async function deleteRedisModel(id: string): Promise<boolean> {
  return deleteRedisEntity('model', id);
}
export async function listRedisModels(options?: ListEntitiesOptions): Promise<ModelEntity[]> {
  return listRedisEntities<ModelEntity>('model', options);
}

// --- AuthProviderEntity CRUD ---
export async function createRedisAuthProvider(authProvider: AuthProviderEntity): Promise<AuthProviderEntity> {
  return createRedisEntity<AuthProviderEntity>('auth_provider', authProvider, AuthProviderEntitySchema);
}
export async function getRedisAuthProviderById(id: string): Promise<AuthProviderEntity | null> {
  return getRedisEntityById<AuthProviderEntity>('auth_provider', id);
}
export async function updateRedisAuthProvider(id: string, updates: Partial<AuthProviderEntity>): Promise<AuthProviderEntity | null> {
  return updateRedisEntity<AuthProviderEntity>('auth_provider', id, updates, AuthProviderEntitySchema);
}
export async function deleteRedisAuthProvider(id: string): Promise<boolean> {
  return deleteRedisEntity('auth_provider', id);
}
export async function listRedisAuthProviders(options?: ListEntitiesOptions): Promise<AuthProviderEntity[]> {
  return listRedisEntities<AuthProviderEntity>('auth_provider', options);
}

// --- DashboardConfigEntity CRUD ---
export async function createRedisDashboardConfig(config: DashboardConfigEntity): Promise<DashboardConfigEntity> {
  return createRedisEntity<DashboardConfigEntity>('dashboard_config', config, DashboardConfigEntitySchema);
}
export async function getRedisDashboardConfigById(id: string): Promise<DashboardConfigEntity | null> {
  return getRedisEntityById<DashboardConfigEntity>('dashboard_config', id);
}
export async function updateRedisDashboardConfig(id: string, updates: Partial<DashboardConfigEntity>): Promise<DashboardConfigEntity | null> {
  return updateRedisEntity<DashboardConfigEntity>('dashboard_config', id, updates, DashboardConfigEntitySchema);
}
export async function deleteRedisDashboardConfig(id: string): Promise<boolean> {
  return deleteRedisEntity('dashboard_config', id);
}
export async function listRedisDashboardConfigs(options?: ListEntitiesOptions): Promise<DashboardConfigEntity[]> {
  return listRedisEntities<DashboardConfigEntity>('dashboard_config', options);
}

export type { Thread, Message, ThreadMetadata, ListEntitiesOptions };
export { RedisStoreError };

================
File: lib/memory/upstash/upstash.json
================
{
  "@context": [
    "https://schema.org",
    { "proj": "https://github.com/ssdeanx/ai-sdk-DM/ns#" },
    { "feature": "https://schema.org/hasFeature" }
  ],
  "@type": "Graph",
  "name": "Upstash Memory Adapter Knowledge Graph",
  "description": "Living knowledge graph for the /lib/memory/upstash folder, capturing entities (files, types, features), relationships, onboarding, navigation, and AI agent support. Upstash must handle ALL API logic and data for all entities, not just memory, and all business logic must be routed through Upstash-first APIs with fallback only.",
  "version": "1.0.0",
  "generatedAt": "2025-05-15T00:00:00Z",
  "@graph": [
    {
      "@id": "lib/memory/upstash/agent-state-store.ts",
      "@type": ["CodeFile"],
      "path": "lib/memory/upstash/agent-state-store.ts",
      "exports": ["saveAgentState", "loadAgentState", "listThreadAgentStates", "deleteAgentState", "deleteThreadAgentStates", "createAgentState", "getAllAgentStates", "AgentStateStoreError", "AgentStateSchema", "StoredAgentStateSchema"],
      "features": [
        "Agent state management in Redis",
        "Zod schema validation for agent state objects",
        "Error handling with custom error classes",
        "CRUD for agent state keyed by agent/thread",
        "Integration with upstashLogger for all errors and state changes",
        "Supports fallback to Supabase/LibSQL for agent state if Upstash unavailable"
      ],
      "types": ["AgentState", "StoredAgentState", "AgentStateStoreError"],
      "zodSchemas": ["AgentStateSchema", "StoredAgentStateSchema"],
      "commands": [
        "hset", "hget", "hdel", "hscan", "@upstash/query", "RediSearch (FT.SEARCH)", "fallback: supabase upsert/select/delete"
      ],
      "tasksCompleted": [
        "Initial implementation",
        "Added Zod validation",
        "Integrated upstashLogger",
        "Added fallback logic",
        "Replaced uuidv4 with generateId",
        "Documented API routes and relationships",
        "Removed all any types and direct console usage (except in legacy fallback)",
        "Added type-safe CRUD for all entities (threads, messages, agent state, etc.)",
        "Integrated @upstash/query for advanced search (RediSearch, hybrid)",
        "Ensured all Upstash client usage is via singleton helpers",
        "All exports and types now available for API and frontend migration"
      ],
      "tasksPending": [
        "Remove any remaining any types in legacy fallback code",
        "Add more robust error handling and type safety for edge cases",
        "Expand Zod schemas for all new entity types (users, workflows, tool executions, etc.)",
        "Add/expand tests for all CRUD, search, and fallback logic",
        "Ensure all API routes and frontend logic are migrated to Upstash backend",
        "Document all new/changed exports in README and knowledge graph",
        "Add advanced RediSearch and analytics support for all entities",
        "Complete migration of all business logic to Upstash-first APIs"
      ],
      "status": "incomplete",
      "observations": [
        "Type errors present (see get_errors)",
        "Direct console usage found",
        "No advanced search support yet",
        "Agent state is persisted in Upstash, with fallback to Supabase/LibSQL if unavailable",
        "API routes for agents/threads depend on this module for state management",
        "Directly depends on upstashTypes.ts for type safety and Zod validation.",
        "All agent state CRUD operations are logged via upstashLogger.",
        "Fallback to Supabase/LibSQL is triggered on Upstash errors.",
        "Should be tested with reasoningTools (debuggingapproach, metacognitivemonitoring) for robust error handling.",
        "Semantic search can be used to trace agent state usage across API routes.",
        "Code smells: Any direct console usage or 'any' types should be flagged and refactored.",
        "Integration with memoryStore.ts and index.ts is critical for system-wide agent state consistency.",
        "All changes should be reflected in the knowledge graph and README for traceability.",
        "@upstash/query can be used for advanced agent state search and analytics.",
        "RediSearch integration is possible for full-text and filtered agent state queries.",
        "All agent state changes should be observable via upstashLogger and analytics routes.",
        "Fallback logic must be tested for all CRUD/search paths, with logs for each failure mode.",
        "Use reasoningTools (debuggingapproach, metacognitivemonitoring, codesmells) for troubleshooting and migration planning.",
        "Onboarding should include walkthroughs of agent state flows, fallback triggers, and log analysis.",
        "Observability and analytics are critical for agent state debugging and system health monitoring.",
        "Semantic search can help map agent state usage and dependencies across the codebase.",
        "All changes must be reflected in the knowledge graph and README for traceability."
      ],
      "tags": [
        "upstash",
        "agent-state",
        "memory",
        "ai-sdk-core",
        "ai-sdk-ui",
        "observability",
        "analytics",
        "fallback",
        "supabase",
        "libsql",
        "zod",
        "tracing",
        "OpenTelemetry",
        "Langfuse",
        "integration",
        "backend",
        "frontend",
        "project:ai-sdk-DM",
        "knowledge-graph",
        "onboarding",
        "tool-logging",
        "state-debugging",
        "context7",
        "documentation",
        "dynamic-docs",
        "integration-tool",
        "search",
        "vector",
        "ratelimit",
        "qstash",
        "redis",
        "logging",
        "metrics",
        "monitoring",
        "troubleshooting",
        "types",
        "functions",
        "const",
        "methods",
        "imports",
        "exports",
        "inferred-types",
        "api-routes",
        "legacy-api",
        "ai-sdk-ui",
        "test-coverage",
        "migration-status"
      ],
      "connections": [
        { "with": "memoryStore.ts", "purpose": "agent state CRUD and fallback integration" },
        { "with": "upstash-logger.ts", "purpose": "logging for all agent state ops" },
        { "with": "supabase-adapter.ts", "purpose": "fallback and compatibility for agent state" },
        { "with": "upstashTypes.ts", "purpose": "type safety and Zod validation for agent state" },
        { "with": "stream-processor.ts", "purpose": "streaming agent state changes for analytics and observability" },
        { "with": "tools.json", "purpose": "agent state analytics and tool execution logging" },
        { "with": "otel-tracing.ts", "purpose": "OpenTelemetry tracing for agent state ops" },
        { "with": "langfuse-integration.ts", "purpose": "Langfuse observability and metrics for agent state" },
        { "with": "README.md", "purpose": "project onboarding and knowledge graph documentation" },
        { "with": "lib/README.md", "purpose": "backend onboarding and architecture" },
        { "with": "onboarding:get-library-docs", "purpose": "fetch up-to-date docs for any package or integration" },
        { "with": "onboarding:resolve-library-id", "purpose": "resolve npm package names for doc lookup" },
        { "with": "onboarding:git_files", "purpose": "view and search project source for onboarding and troubleshooting" },
        { "with": "context7", "purpose": "dynamic documentation and context lookup for any package or API" }
      ],
      "apiRoutes": [
        "/api/ai-sdk/agents",
        "/api/ai-sdk/threads",
        "/api/ai-sdk/dashboard",
        "/api/ai-sdk/system",
        "/api/ai-sdk/apps",
        "/api/ai-sdk/mdx",
        "/api/ai-sdk/settings",
        "/api/ai-sdk/observability",
        "/api/ai-sdk/content",
        "/api/ai-sdk/blog",
        "/api/ai-sdk/auth"
      ],
      "reasoningTools": [
        {
          "name": "debuggingapproach",
          "addUsage": "Use for step-by-step debugging of agent state flows and fallback logic. Document findings in troubleshooting section."
        },
        {
          "name": "metacognitivemonitoring",
          "addUsage": "Apply for monitoring error patterns and log analysis. Integrate with upstashLogger and analytics."
        },
        {
          "name": "codesmells",
          "addUsage": "Run periodically to flag direct console usage, any types, and missing error handling. Document in migration status."
        }
      ],
      "usageNotes": "Use for all agent state persistence. Always validate with Zod. Log all errors. Integrate with OpenTelemetry and Langfuse for observability. Ensure fallback to Supabase/LibSQL is robust. Update knowledge graph and onboarding docs with any changes.",
      "onboarding": "See README.md, lib/README.md, and the documentation graph (see below) for setup, usage, and project context. Ensure fallback logic, observability, and analytics are implemented. Cross-reference all changes in the knowledge graph.",
      "navigation": "Imported by memoryStore.ts, index.ts, and referenced in project onboarding docs.",
      "troubleshooting": "Check for type errors, missing logger usage, and incomplete tracing/observability integration. Validate fallback logic and knowledge graph updates.",
      "graphNotes": "Central node for agent state in Upstash and ai-sdk-DM knowledge graph. Connects to ai-sdk-core, ai-sdk-ui, OpenTelemetry, Langfuse, and project onboarding. For a full list of available documentation, see the documentation graph below.",
      "relationships": [
        { "type": "memory", "target": "memory" },
        { "type": "api-route", "target": "app/api/ai-sdk/agents" },
        { "type": "api-route", "target": "app/api/ai-sdk/threads" },
        { "type": "api-route", "target": "app/api/ai-sdk/dashboard" },
        { "type": "api-route", "target": "app/api/ai-sdk/system" },
        { "type": "api-route", "target": "app/api/ai-sdk/apps" },
        { "type": "api-route", "target": "app/api/ai-sdk/mdx" },
        { "type": "api-route", "target": "app/api/ai-sdk/settings" },
        { "type": "api-route", "target": "app/api/ai-sdk/observability" },
        { "type": "api-route", "target": "app/api/ai-sdk/content" },
        { "type": "api-route", "target": "app/api/ai-sdk/blog" },
        { "type": "api-route", "target": "app/api/ai-sdk/auth" },
        { "type": "uses", "target": "lib/memory/upstash/upstash-logger.ts" },
        { "type": "uses", "target": "lib/memory/upstash/upstashTypes.ts" },
        { "type": "fallback", "target": "lib/memory/supabase.ts" },
        { "type": "observability", "target": "otel-tracing.ts" },
        { "type": "analytics", "target": "langfuse-integration.ts" },
        { "type": "docs", "target": "README.md" },
        { "type": "docs", "target": "lib/README.md" },
        { "type": "integration", "target": "ai-sdk-core" },
        { "type": "integration", "target": "ai-sdk-ui" },
        { "type": "integration", "target": "OpenTelemetry" },
        { "type": "integration", "target": "Langfuse" }
      ],
      "mentalModels": [
        "First Principles Thinking",
        "Feedback Loops",
        "Rubber Ducking",
        "Inversion",
        "Mindmaps & Hill Charts"
      ]
    },
    {
      "@id": "lib/memory/upstash/index.ts",
      "@type": ["CodeFile"],
      "path": "lib/memory/upstash/index.ts",
      "exports": [
        "getRedisClient", "getVectorClient", "checkUpstashAvailability", "createRedisThread", "getRedisThreadById", "updateRedisThread", "listRedisThreads", "deleteRedisThread", "createRedisMessage", "getRedisMessageById", "getRedisMessagesByThreadId", "deleteRedisMessage", "upsertEmbeddings", "searchSimilarEmbeddings", "getEmbeddingsByIds", "deleteEmbeddingsByIds", "resetVectorIndex", "getVectorIndexInfo", "logInfo", "logWarn", "logError", "logDebug", "getLogs", "deleteLogs", "clearLogs", "saveAgentState", "loadAgentState", "listThreadAgentStates", "deleteAgentState", "deleteThreadAgentStates", "createAgentState", "getAllAgentStates", "MemoryProcessor", "MemoryProcessorError", "RedisClientError", "VectorClientError", "streamProcessor", "StreamProcessor", "StreamProcessorError", "getData", "getItemById", "createItem", "updateItem", "deleteItem", "vectorSearch", "upsertSupabaseVectors", "VectorDataSchema", "VectorSearchOptionsSchema", "createSupabaseClient"
      ],
      "features": [
        "Barrel export for Upstash memory module",
        "Exports all Upstash memory, vector, logging, and adapter utilities",
        "Centralizes all exports for easy import",
        "Ensures type safety and up-to-date exports"
      ],
      "commands": [
        "hset", "hget", "hdel", "hscan", "@upstash/query", "RediSearch (FT.SEARCH)", "fallback: supabase upsert/select/delete"
      ],
      "tasksCompleted": [
        "Initial barrel export", "Added new exports as features grew"
      ],
      "tasksPending": [
        "Remove/replace all broken exports (see README errors)", "Ensure all exports are up-to-date and type-safe", "Add documentation for new/advanced exports", "Check for missing/broken exports from dependencies (see get_errors)"
      ],
      "consumers": ["lib/memory/memory.ts", "API: /api/memory/*"],
      "dependencies": [
        "agent-state-store.ts", "memory-processor.ts", "memoryStore.ts", "redis-store.ts", "stream-processor.ts", "supabase-adapter-factory.ts", "supabase-adapter.ts", "upstash-logger.ts", "upstashClients.ts", "upstashTypes.ts", "vector-store.ts"
      ],
      "testFiles": ["tests/upstash/index.test.ts"],
      "docs": ["README.md#index.ts"],
      "examples": ["How to import all Upstash memory features"],
      "changelog": ["Initial barrel export", "Added new exports as features grew"],
      "todo": [
        "Remove/replace all broken exports (see README errors)",
        "Ensure all exports are up-to-date and type-safe",
        "Add documentation for new/advanced exports",
        "Check for missing/broken exports from dependencies (see get_errors)"
      ],
      "status": "incomplete",
      "observations": [
        "Central export node for all Upstash memory features",
        "All API routes under app/api/ai-sdk/* import from here for memory/vector/logging/agent state ops",
        "Fallback to Supabase/LibSQL handled via supabase-adapter exports",
        "No direct errors, but may be blocked by missing/broken exports from dependencies. See get_errors."
      ],
      "tags": [
        "upstash",
        "memory",
        "vector",
        "logging",
        "agent-state",
        "integration",
        "backend",
        "frontend",
        "project:ai-sdk-DM",
        "knowledge-graph",
        "onboarding",
        "documentation",
        "dynamic-docs",
        "integration-tool",
        "search",
        "ratelimit",
        "qstash",
        "redis",
        "metrics",
        "monitoring",
        "troubleshooting",
        "types",
        "functions",
        "const",
        "methods",
        "imports",
        "exports",
        "api-routes",
        "legacy-api",
        "ai-sdk-ui",
        "test-coverage",
        "migration-status"
      ],
      "connections": [
        { "with": "agent-state-store.ts", "purpose": "barrel export for agent state operations" },
        { "with": "memory-processor.ts", "purpose": "barrel export for memory processing" },
        { "with": "memoryStore.ts", "purpose": "barrel export for memory CRUD" },
        { "with": "redis-store.ts", "purpose": "barrel export for Redis operations" },
        { "with": "stream-processor.ts", "purpose": "barrel export for streaming operations" },
        { "with": "supabase-adapter.ts", "purpose": "barrel export for Supabase fallback" },
        { "with": "upstash-logger.ts", "purpose": "barrel export for logging utilities" },
        { "with": "upstashClients.ts", "purpose": "barrel export for Upstash clients" },
        { "with": "upstashTypes.ts", "purpose": "barrel export for shared types and schemas" },
        { "with": "vector-store.ts", "purpose": "barrel export for vector operations" },
        { "with": "onboarding:get-library-docs", "purpose": "fetch up-to-date docs for any package or integration" },
        { "with": "onboarding:resolve-library-id", "purpose": "resolve npm package names for doc lookup" },
        { "with": "onboarding:git_files", "purpose": "view and search project source for onboarding and troubleshooting" },
        { "with": "context7", "purpose": "dynamic documentation and context lookup for any package or API" }
      ],
      "onboardingTools": [
        "onboarding:get-library-docs",
        "onboarding:resolve-library-id",
        "onboarding:git_files",
        "context7"
      ],
      "usageNotes": "Use this file to import any Upstash memory feature.",
      "onboarding": "Check README for export list and update policy.",
      "navigation": "Barrel for all Upstash memory files.",
      "troubleshooting": "If an export is missing, check this file and README.",
      "graphNotes": "Central export node.",
      "relationships": [
        { "type": "barrel", "target": "lib/memory/upstash/*" },
        { "type": "api-route", "target": "app/api/ai-sdk/*" },
        { "type": "api-route", "target": "app/api/ai-sdk/dashboard" },
        { "type": "api-route", "target": "app/api/ai-sdk/system" },
        { "type": "api-route", "target": "app/api/ai-sdk/apps" },
        { "type": "api-route", "target": "app/api/ai-sdk/mdx" },
        { "type": "api-route", "target": "app/api/ai-sdk/settings" },
        { "type": "api-route", "target": "app/api/ai-sdk/observability" },
        { "type": "api-route", "target": "app/api/ai-sdk/content" },
        { "type": "api-route", "target": "app/api/ai-sdk/blog" },
        { "type": "api-route", "target": "app/api/ai-sdk/auth" },
        { "type": "consumer", "target": "lib/memory/memory.ts" },
        { "type": "consumer", "target": "app/api/ai-sdk/threads" },
        { "type": "consumer", "target": "app/api/ai-sdk/messages" },
        { "type": "consumer", "target": "app/api/ai-sdk/agents" },
        { "type": "consumer", "target": "app/api/ai-sdk/logs" },
        { "type": "consumer", "target": "app/api/ai-sdk/analytics" }
      ],
      "mentalModels": [
        "First Principles Thinking",
        "Feedback Loops",
        "Occam's Razor",
        "Mindmaps & Hill Charts"
      ]
    },
    {
      "@id": "lib/memory/upstash/redis-store.ts",
      "relationships": [
        { "type": "api-route", "target": "app/api/ai-sdk/threads" },
        { "type": "api-route", "target": "app/api/ai-sdk/messages" },
        { "type": "api-route", "target": "app/api/ai-sdk/dashboard" },
        { "type": "api-route", "target": "app/api/ai-sdk/system" },
        { "type": "api-route", "target": "app/api/ai-sdk/apps" },
        { "type": "api-route", "target": "app/api/ai-sdk/mdx" },
        { "type": "api-route", "target": "app/api/ai-sdk/settings" },
        { "type": "api-route", "target": "app/api/ai-sdk/observability" },
        { "type": "api-route", "target": "app/api/ai-sdk/content" },
        { "type": "api-route", "target": "app/api/ai-sdk/blog" },
        { "type": "api-route", "target": "app/api/ai-sdk/auth" },
        { "type": "api-route", "target": "app/api/ai-sdk/logs" },
        { "type": "api-route", "target": "app/api/ai-sdk/analytics" },
        { "type": "api-route", "target": "app/api/ai-sdk/users" },
        { "type": "api-route", "target": "app/api/ai-sdk/workflows" },
        { "type": "api-route", "target": "app/api/ai-sdk/models" },
        { "type": "api-route", "target": "app/api/ai-sdk/tools" },
        { "type": "uses", "target": "lib/memory/upstash/upstash-logger.ts" },
        { "type": "uses", "target": "lib/memory/upstash/upstashTypes.ts" },
        { "type": "uses", "target": "lib/memory/upstash/upstashClients.ts" },
        { "type": "fallback", "target": "lib/memory/supabase.ts" },
        { "type": "onboarding:get-library-docs", "purpose": "fetch up-to-date docs for any package or integration" },
        { "type": "onboarding:resolve-library-id", "purpose": "resolve npm package names for doc lookup" },
        { "type": "onboarding:git_files", "purpose": "view and search project source for onboarding and troubleshooting" },
        { "type": "context7", "purpose": "dynamic documentation and context lookup for any package or API" }
      ],
      "connections": [
        { "with": "memoryStore.ts", "purpose": "thread/message CRUD, search, and RediSearch" },
        { "with": "upstash-logger.ts", "purpose": "logging for all thread/message ops" },
        { "with": "supabase-adapter.ts", "purpose": "fallback and compatibility" }
      ],
      "commands": [
        "hset", "hget", "hdel", "hscan", "zadd", "zrem", "zrange", "zrevrange", "RediSearch (FT.SEARCH)", "@upstash/query", "pipeline", "fallback: supabase upsert/select/delete"
      ],
      "tasksCompleted": [
        "Replaced uuidv4 with generateId from 'ai' for all ID generation",
        "Integrated upstashLogger for all error and operation logging",
        "Type-safe CRUD for threads/messages using Zod schemas",
        "Fallback logic to Supabase/LibSQL for all CRUD/search paths",
        "Documented API routes and relationships",
        "Initial @upstash/query client integration"
      ],
      "tasksPending": [
        "Remove all any types (see README and get_errors)",
        "Remove unused @ts-expect-error directives",
        "Use @upstash/query for advanced thread/message search (RediSearch, full-text, filters)",
        "Add more type-safe helpers for RediSearch results",
        "Remove all direct console statements, use upstashLogger",
        "Add tests for thread/message search and RediSearch integration",
        "Expand Zod schemas for all entity types (not just threads/messages)",
        "Document all Redis/RediSearch commands used",
        "Ensure all business logic is routed through Upstash-first APIs"
      ],
      "observations": [
        "Handles thread/message CRUD for all entities, not just memory.",
        "Integrates with upstashLogger for all error and operation logging.",
        "Uses upstashTypes.ts for type safety and Zod validation.",
        "Fallback logic to Supabase/LibSQL must be tested for all CRUD/search paths.",
        "Should leverage reasoningTools (debuggingapproach, sequentialthinking) for troubleshooting complex data flows.",
        "Semantic search can help map thread/message relationships across the codebase.",
        "Code smells: Look for any direct console statements, unused types, or missing error handling.",
        "RediSearch and advanced filtering should be documented and tested for all entity types.",
        "@upstash/query can be used for advanced thread/message search and analytics.",
        "RediSearch integration is possible for full-text and filtered thread/message queries.",
        "All thread/message changes should be observable via upstashLogger and analytics routes.",
        "Fallback logic must be tested for all CRUD/search paths, with logs for each failure mode.",
        "Use reasoningTools (debuggingapproach, metacognitivemonitoring, codesmells) for troubleshooting and migration planning.",
        "Onboarding should include walkthroughs of thread/message flows, fallback triggers, and log analysis.",
        "Observability and analytics are critical for thread/message debugging and system health monitoring.",
        "Semantic search can help map thread/message usage and dependencies across the codebase.",
        "All changes must be reflected in the knowledge graph and README for traceability.",
        "Full Upstash Redis command set available. See: https://context7.com/upstash/docs/llms.txt?folders=redis&tokens=84007 for all supported commands, pipelining, and advanced LLM/RediSearch usage."
      ],
      "mentalModels": [
        "First Principles Thinking",
        "Feedback Loops",
        "Inversion",
        "Occam's Razor",
        "Mindmaps & Hill Charts"
      ],
      "docs": [
        "README.md#redis-store.ts",
        "https://context7.com/upstash/docs/llms.txt?folders=redis&tokens=84007"
      ]
    },
    {
      "@id": "lib/memory/upstash/vector-store.ts",
      "relationships": [
        { "type": "api-route", "target": "app/api/ai-sdk/embeddings" },
        { "type": "api-route", "target": "app/api/ai-sdk/vector-search" },
        { "type": "api-route", "target": "app/api/ai-sdk/dashboard" },
        { "type": "api-route", "target": "app/api/ai-sdk/system" },
        { "type": "api-route", "target": "app/api/ai-sdk/apps" },
        { "type": "api-route", "target": "app/api/ai-sdk/mdx" },
        { "type": "api-route", "target": "app/api/ai-sdk/settings" },
        { "type": "api-route", "target": "app/api/ai-sdk/observability" },
        { "type": "api-route", "target": "app/api/ai-sdk/content" },
        { "type": "api-route", "target": "app/api/ai-sdk/blog" },
        { "type": "api-route", "target": "app/api/ai-sdk/auth" },
        { "type": "api-route", "target": "app/api/ai-sdk/logs" },
        { "type": "api-route", "target": "app/api/ai-sdk/analytics" },
        { "type": "api-route", "target": "app/api/ai-sdk/users" },
        { "type": "api-route", "target": "app/api/ai-sdk/workflows" },
        { "type": "api-route", "target": "app/api/ai-sdk/models" },
        { "type": "api-route", "target": "app/api/ai-sdk/tools" },
        { "type": "uses", "target": "lib/memory/upstash/upstashClients.ts" },
        { "type": "uses", "target": "lib/memory/upstash/upstashTypes.ts" },
        { "type": "uses", "target": "lib/memory/upstash/upstash-logger.ts" },
        { "type": "fallback", "target": "lib/memory/supabase.ts" },
        { "type": "onboarding:get-library-docs", "purpose": "fetch up-to-date docs for any package or integration" },
        { "type": "onboarding:resolve-library-id", "purpose": "resolve npm package names for doc lookup" },
        { "type": "onboarding:git_files", "purpose": "view and search project source for onboarding and troubleshooting" },
        { "type": "context7", "purpose": "dynamic documentation and context lookup for any package or API" }
      ],
      "connections": [
        { "with": "memoryStore.ts", "purpose": "embedding storage/search for all entities" },
        { "with": "upstash-logger.ts", "purpose": "logging for vector ops" },
        { "with": "supabase-adapter.ts", "purpose": "fallback and compatibility" },
        { "with": "memory-processor.ts", "purpose": "semantic/streaming search for all entities" }
      ],
      "commands": [
        "upsert", "query", "delete", "info", "reset", "@upstash/query", "RediSearch (FT.SEARCH)", "pipeline", "fallback: supabase upsert/select/delete"
      ],
      "tasksCompleted": [
        "Replaced uuidv4 with generateId from 'ai' for all ID generation",
        "Integrated upstashLogger for all vector operation logging",
        "Type-safe CRUD for embeddings using Zod schemas",
        "Fallback logic to Supabase/LibSQL for all vector operations",
        "Initial @upstash/query client integration"
      ],
      "tasksPending": [
        "Remove all direct console statements, use upstashLogger",
        "Use precise types for metadata, results, and errors",
        "Add @upstash/query integration for hybrid search, advanced filtering",
        "Add more robust error handling and logging",
        "Add tests for hybrid and filtered search",
        "Expand Zod schemas for all entity types (not just embeddings)",
        "Document all Vector/RediSearch commands used",
        "Ensure all business logic is routed through Upstash-first APIs"
      ],
      "observations": [
        "Central node for all vector/embedding CRUD and search.",
        "All vector operations are logged via upstashLogger.",
        "Type safety enforced via upstashTypes.ts and Zod schemas.",
        "Fallback to Supabase/LibSQL for vector operations must be robust and tested.",
        "Should use reasoningTools (scientificmethod, decisionframework) for evaluating search/filtering strategies.",
        "Semantic search is essential for tracing embedding usage and debugging search results.",
        "Code smells: Any use of 'any' types, missing logging, or direct console statements should be flagged.",
        "Integration with memoryStore.ts and supabase-adapter.ts is key for end-to-end vector data flow.",
        "@upstash/query can be used for advanced vector search and analytics.",
        "RediSearch integration is possible for full-text and filtered vector queries.",
        "All vector changes should be observable via upstashLogger and analytics routes.",
        "Fallback logic must be tested for all CRUD/search paths, with logs for each failure mode.",
        "Use reasoningTools (debuggingapproach, metacognitivemonitoring, codesmells) for troubleshooting and migration planning.",
        "Onboarding should include walkthroughs of vector flows, fallback triggers, and log analysis.",
        "Observability and analytics are critical for vector debugging and system health monitoring.",
        "Semantic search can help map vector usage and dependencies across the codebase.",
        "All changes must be reflected in the knowledge graph and README for traceability.",
        "Full Upstash Vector DB command set available. See: https://context7.com/upstash/docs/llms.txt?folders=vector&tokens=40216 for all supported commands, hybrid search, and advanced LLM/vector usage."
      ],
      "mentalModels": [
        "First Principles Thinking",
        "Feedback Loops",
        "Inversion",
        "Lean Startup",
        "Mindmaps & Hill Charts"
      ],
      "docs": [
        "README.md#vector-store.ts",
        "https://context7.com/upstash/docs/llms.txt?folders=vector&tokens=40216"
      ]
    },
    {
      "@id": "lib/memory/upstash/upstash-logger.ts",
      "relationships": [
        { "type": "api-route", "target": "app/api/ai-sdk/logs" },
        { "type": "api-route", "target": "app/api/ai-sdk/analytics" },
        { "type": "api-route", "target": "app/api/ai-sdk/dashboard" },
        { "type": "api-route", "target": "app/api/ai-sdk/system" },
        { "type": "api-route", "target": "app/api/ai-sdk/apps" },
        { "type": "api-route", "target": "app/api/ai-sdk/mdx" },
        { "type": "api-route", "target": "app/api/ai-sdk/settings" },
        { "type": "api-route", "target": "app/api/ai-sdk/observability" },
        { "type": "api-route", "target": "app/api/ai-sdk/content" },
        { "type": "api-route", "target": "app/api/ai-sdk/blog" },
        { "type": "api-route", "target": "app/api/ai-sdk/auth" },
        { "type": "api-route", "target": "app/api/ai-sdk/users" },
        { "type": "uses", "target": "lib/memory/upstash/upstashTypes.ts" },
        { "type": "uses", "target": "lib/memory/upstash/upstashClients.ts" },
        { "type": "onboarding:get-library-docs", "purpose": "fetch up-to-date docs for any package or integration" },
        { "type": "onboarding:resolve-library-id", "purpose": "resolve npm package names for doc lookup" },
        { "type": "onboarding:git_files", "purpose": "view and search project source for onboarding and troubleshooting" },
        { "type": "context7", "purpose": "dynamic documentation and context lookup for any package or API" }
      ],
      "connections": [
        { "with": "agent-state-store.ts", "purpose": "logging for agent state ops" },
        { "with": "redis-store.ts", "purpose": "logging for thread/message ops" },
        { "with": "vector-store.ts", "purpose": "logging for vector ops" }
      ],
      "commands": [
        "xadd", "xread", "xrange", "xdel", "@upstash/query", "pipeline"
      ],
      "tasksCompleted": [
        "Replaced uuidv4 with generateId from 'ai' for all log IDs",
        "Integrated upstashLogger for all logging",
        "Type-safe log entry parsing with Zod schemas",
        "Centralized logging for all Upstash modules"
      ],
      "tasksPending": [
        "Replace all any types with precise types (see errors)",
        "Remove unused types/vars (e.g., RedisClient)",
        "Remove all console statements, use upstashLogger only",
        "Ensure all log entry parsing is type-safe",
        "Add advanced log querying (e.g., by level, time range)",
        "Add tests for log streaming and retrieval",
        "Document all Redis Stream commands used"
      ],
      "observations": [
        "All logging for Upstash modules is centralized here.",
        "Type safety and Zod validation are required for all log entries.",
        "Should be integrated with reasoningTools (metacognitivemonitoring, codesmells) for log quality and anomaly detection.",
        "Semantic search can be used to analyze log patterns and trace issues across modules.",
        "Code smells: Any direct console usage or missing log validation should be flagged.",
        "Advanced log querying and streaming should be documented and tested.",
        "@upstash/query can be used for advanced log search and analytics.",
        "All log changes should be observable via analytics routes.",
        "Use reasoningTools (debuggingapproach, metacognitivemonitoring, codesmells) for troubleshooting and migration planning.",
        "Onboarding should include walkthroughs of log flows, triggers, and analysis.",
        "Observability and analytics are critical for log debugging and system health monitoring.",
        "Semantic search can help map log usage and dependencies across the codebase.",
        "All changes must be reflected in the knowledge graph and README for traceability."
      ],
      "mentalModels": [
        "Feedback Loops",
        "Inversion",
        "Rubber Ducking",
        "Mindmaps & Hill Charts"
      ]
    },
    {
      "@id": "lib/memory/upstash/upstashClients.ts",
      "relationships": [
        { "type": "api-route", "target": "app/api/ai-sdk/*" },
        { "type": "api-route", "target": "app/api/ai-sdk/dashboard" },
        { "type": "api-route", "target": "app/api/ai-sdk/system" },
        { "type": "api-route", "target": "app/api/ai-sdk/apps" },
        { "type": "api-route", "target": "app/api/ai-sdk/mdx" },
        { "type": "api-route", "target": "app/api/ai-sdk/settings" },
        { "type": "api-route", "target": "app/api/ai-sdk/observability" },
        { "type": "api-route", "target": "app/api/ai-sdk/content" },
        { "type": "api-route", "target": "app/api/ai-sdk/blog" },
        { "type": "api-route", "target": "app/api/ai-sdk/auth" },
        { "type": "api-route", "target": "app/api/ai-sdk/logs" },
        { "type": "api-route", "target": "app/api/ai-sdk/analytics" },
        { "type": "api-route", "target": "app/api/ai-sdk/users" },
        { "type": "api-route", "target": "app/api/ai-sdk/workflows" },
        { "type": "api-route", "target": "app/api/ai-sdk/models" },
        { "type": "api-route", "target": "app/api/ai-sdk/tools" },
        { "type": "uses", "target": "lib/memory/upstash/upstashTypes.ts" },
        { "type": "uses", "target": "lib/memory/upstash/upstash-logger.ts" },
        { "type": "onboarding:get-library-docs", "purpose": "fetch up-to-date docs for any package or integration" },
        { "type": "onboarding:resolve-library-id", "purpose": "resolve npm package names for doc lookup" },
        { "type": "onboarding:git_files", "purpose": "view and search project source for onboarding and troubleshooting" },
        { "type": "context7", "purpose": "dynamic documentation and context lookup for any package or API" }
      ],
      "connections": [
        { "with": "redis-store.ts", "purpose": "client management for Redis" },
        { "with": "vector-store.ts", "purpose": "client management for VectorDB" },
        { "with": "supabase-adapter.ts", "purpose": "Upstash-first client selection and fallback" }
      ],
      "commands": [
        "Redis.fromEnv", "Index", "Query", "validate config (Zod)", "health checks", "@upstash/query"
      ],
      "tasksCompleted": [
        "Type-safe, robust, singleton clients for Redis, Vector, and Query",
        "Uses Zod schemas for config validation",
        "upstashLogger for all logging",
        "Health checks and availability functions"
      ],
      "tasksPending": [
        "Fix Query config: { url, token } is not valid for QueryConfig (see get_errors)",
        "Add advanced Query client usage examples in docs",
        "Document how to use Query for RediSearch and advanced filtering",
        "Add tests for client initialization and error handling"
      ],
      "observations": [
        "Manages singleton clients for Redis and Vector, used by all Upstash modules.",
        "All client config is validated with Zod schemas from upstashTypes.ts.",
        "Should be tested with reasoningTools (debuggingapproach, metacognitivemonitoring) for connection reliability.",
        "Semantic search can help trace client usage and fallback logic across the codebase.",
        "Code smells: Any missing error handling, unused imports, or direct console statements should be flagged.",
        "Integration with supabase-adapter.ts and fallback logic is critical for reliability.",
        "@upstash/query can be used for advanced client search and analytics.",
        "All client changes should be observable via analytics routes.",
        "Use reasoningTools (debuggingapproach, metacognitivemonitoring, codesmells) for troubleshooting and migration planning.",
        "Onboarding should include walkthroughs of client flows, triggers, and analysis.",
        "Observability and analytics are critical for client debugging and system health monitoring.",
        "Semantic search can help map client usage and dependencies across the codebase.",
        "All changes must be reflected in the knowledge graph and README for traceability.",
        "Type error: Object literal may only specify known properties, and 'url' does not exist in type 'QueryConfig'. See get_errors."
      ],
      "todo": [
        "Fix Query config: { url, token } is not valid for QueryConfig (see get_errors)"
      ],
      "status": "incomplete",
      "mentalModels": [
        "First Principles Thinking",
        "Feedback Loops",
        "Circle of Competence",
        "Mindmaps & Hill Charts"
      ]
    },
    {
      "@id": "lib/memory/upstash",
      "@type": ["Directory"],
      "path": "lib/memory/upstash",
      "files": [
        "agent-state-store.ts",
        "index.ts",
        "memory-processor.ts",
        "memoryStore.ts",
        "README.md",
        "redis-store.ts",
        "stream-processor.ts",
        "supabase-adapter-factory.ts",
        "supabase-adapter.ts",
        "upstash-logger.ts",
        "upstash.json",
        "upstashClients.ts",
        "upstashTypes.ts",
        "vector-store.ts"
      ],
      "status": "incomplete",
      "observations": [
        "Directory listing as of 2025-05-15. All files are tracked in the knowledge graph and README.",
        "Migration is blocked until all type safety, adapter, and CRUD issues are resolved (see README)."
      ],
      "todos": [
        "Ensure all files are type-safe, table-aware, and production-ready.",
        "Remove all any types and unsafe type assertions from all files.",
        "Update README and upstash.json after every significant change."
      ]
    }
  ],
  "meta": {
    "source": "auto-generated from README.md, memory.json, and codebase as of 2025-05-15",
    "updateStrategy": "automated extraction and continuous update via CI/CD and AI agent workflows",
    "intendedUse": [
      "Continuous improvement and documentation enforcement"
    ],
    "diamondCore": "A diamond core file is one that is absolutely central to the Upstash memory system's integrity, reliability, and extensibility. Bugs or design flaws here have system-wide impact. These files require the highest level of review, testing, and documentation.",
    "backup": "LibSQL and Supabase are backup/fallback backends. All features must work with Upstash as primary, and degrade gracefully to backup if needed."
  },
  "onboarding": {
    "purpose": "This onboarding is for AI agents (and advanced human contributors). Its goal is to ensure robust, error-free, and continuously improving Upstash memory adapter development. All steps are designed for AI agent reliability, self-improvement, and persistent insight.",
    "audience": "AI agents (Copilot, LLMs, automated CI/CD bots)",
    "corePrinciples": [
      "Type safety and Zod validation are required for all modules.",
      "After every file edit, always use get_errors to check for errors before considering the task complete.",
      "All direct console statements must be replaced with upstashLogger or equivalent.",
      "Every file must have comprehensive tests, docs, and usage examples.",
      "Knowledge graph and README must be updated with every significant change.",
      "Unused imports, types, and variables in diamond core files must be implemented and used if possible, not removed unless absolutely certain they are dead code. Removing them can break critical system behavior.",
      "Use semantic/graph search and mental models for navigation, troubleshooting, and continuous improvement.",
      "Apply mental models (see 'mentalModels' section) to break down, analyze, and solve coding and architectural problems.",
      "Onboarding and troubleshooting should be agent-friendly, with step-by-step guidance and references to code, docs, and graph nodes.",
      "Continuous improvement: treat every error, warning, or TODO as a learning opportunity and update the knowledge graph accordingly.",
      "For diamond core files, always prefer refactoring to implementation over removal. Only remove code if it is provably unused and not referenced anywhere in the system."
    ],
    "steps": [
      "Read the README.md in full, focusing on the Implementation Guide, Feature Table, and Best Practices.",
      "Review the @graph array for a map of all files, features, and relationships.",
      "For each file, check the 'todo', 'status', and 'observations' fields to identify what is needed for production-readiness.",
      "Use the 'mentalModels' section to select the best approach for the current coding or troubleshooting task.",
      "After editing any file, run get_errors and update the knowledge graph and README as needed.",
      "If a file is incomplete, follow the taskList for actionable steps to bring it to production-grade.",
      "If stuck, use mental models like Rubber Ducking, First Principles, or Feedback Loops to analyze and resolve the issue.",
      "Document all lessons learned and improvements in the notepad and changelog sections."
    ],
    "navigation": {
      "crossref": "Use 'relationships' to see which files import, use, or export others.",
      "byFile": "Use the @graph array to locate files, their features, status, and relationships.",
      "byFeature": "Search for features (e.g., vector search, CRUD, logging) in the 'features' fields.",
      "byType": "Find types and Zod schemas in each file and referenced in each file's 'exports'.",
      "byStatus": "Track progress using the 'status' and 'todo' fields for each entity.",
      "insightAccu": [
        "All Upstash modules must reference canonical types and Zod schemas for every entity (users, threads, messages, workflows, models, tools, logs, analytics, etc.) to ensure migration is seamless.",
        "Every API route and business logic layer must validate request/response types using upstashTypes.ts, referencing types/supabase.ts and Drizzle schemas as needed.",
        "Knowledge graph must be updated after every major edit, and all relationships, connections, and observations must be kept in sync with code changes.",
        "Fallback logic and error handling must be type-safe and tested for all entities, not just memory.",
        "Graph should be reviewed before each migration or integration to catch missing types, schemas, or relationships before CI/CD is enabled."
      ],
      "integrationNotes": "Integration must always be guided by the latest accumulated insights in 'insightAccu'. Before any migration or integration, review 'insightAccu' for missing types, schemas, or relationships. Adapt integration plans based on these insights to ensure all Upstash modules, API routes, and business logic are type-safe, robust, and ready for CI/CD."
    },
    "mentalModels": {
      "description": "A curated set of mental models for software development, debugging, and codebase improvement. Use these models to break down complex problems, verify assumptions, and drive continuous improvement. Each model below includes a summary, practical usage, and tips for applying it to the Upstash/Supabase/LibSQL integration context.",
      "models": [
        {
          "name": "Rubber Ducking",
          "summary": "Rubber ducking is the practice of explaining your code, logic, or problem step-by-step to an inanimate object or another person. This process forces you to clarify your thinking, often revealing hidden bugs or misunderstandings.",
          "application": "When stuck or debugging, write out your reasoning in the notepad, as comments, or in the knowledge graph. For Upstash/Supabase/LibSQL integration, use rubber ducking to walk through the data flow between adapters (e.g., supabase-adapter.ts to supabase.ts to memory.ts/db.ts/libsql.ts) and spot mismatches or missing logic.",
          "bestFor": ["Debugging complex bugs", "Explaining code to others", "Onboarding new contributors"],
          "howToUse": "Start by describing the problem or feature as if teaching it to someone new. For integration, narrate how a request flows from the API through supabase-adapter.ts, into supabase.ts, and down to memory.ts/db.ts/libsql.ts. Note any unclear steps or assumptions—these are likely sources of bugs or missing features."
        },
        {
          "name": "First Principles Thinking",
          "summary": "First principles thinking means breaking down a problem into its most basic elements and reasoning up from there, rather than relying on analogy or existing patterns.",
          "application": "Use for architectural decisions, refactoring, or when existing solutions are insufficient. For Upstash/Supabase/LibSQL, break down the requirements for memory, vector, and logging into their core primitives, then design the integration from scratch, ensuring each adapter and backend is used optimally.",
          "bestFor": ["Major refactors", "Designing new features", "Fixing systemic issues"],
          "howToUse": "Start by describing the problem or feature as if teaching it to someone new. For integration, narrate how a request flows from the API through supabase-adapter.ts, into supabase.ts, and down to memory.ts/db.ts/libsql.ts. Note any unclear steps or assumptions—these are likely sources of bugs or missing features."
        },
        {
          "name": "Occam's Razor",
          "summary": "Occam's Razor is the principle that the simplest solution is usually best. Avoid unnecessary complexity, especially in integration code.",
          "application": "When connecting Upstash, Supabase, and LibSQL, prefer the simplest, most direct data flow and fallback logic. Only add complexity if it is justified by requirements.",
          "bestFor": ["Refactoring", "API design", "Performance tuning"],
          "howToUse": "Review integration code for unnecessary indirection or abstraction. Simplify wherever possible, and document why any complexity is required."
        },
        {
          "name": "Mindmaps & Hill Charts",
          "summary": "Mindmaps and hill charts are visual tools for mapping out dependencies, progress, and relationships. They are invaluable for onboarding and integration planning.",
          "application": "Use mindmaps to visualize how supabase-adapter.ts, supabase.ts, memory.ts, db.ts, and libsql.ts connect and interact. Use hill charts to track progress on integration and testing.",
          "bestFor": ["Project planning", "Onboarding", "Dependency analysis"],
          "howToUse": "Draw a diagram showing the flow of data and control between all adapters and backends. Update as the architecture evolves."
        },
        {
          "name": "Parkinson's Law",
          "summary": "Parkinson's Law states that work expands to fill the time available. Set clear deadlines and constraints to keep integration work focused and efficient.",
          "application": "Timebox integration tasks (e.g., connecting supabase-adapter.ts to supabase.ts and memory.ts) to avoid endless refactoring or scope creep.",
          "bestFor": ["Sprint planning", "Bugfixes", "Feature delivery"],
          "howToUse": "Set a deadline for each integration milestone. If a task is taking too long, review for unnecessary complexity or blockers."
        },
        {
          "name": "Lean Startup",
          "summary": "Lean Startup is about building, measuring, and learning quickly. For integrations, ship small, test, and iterate.",
          "application": "For Upstash/Supabase/LibSQL, implement the minimal integration first (e.g., basic CRUD from supabase-adapter.ts to supabase.ts to memory.ts), then add features and fallback logic incrementally.",
          "bestFor": ["Prototyping", "New features", "Continuous delivery"],
          "howToUse": "Start with a working MVP for the integration. Add tests and features in small increments, validating each step."
        }
      ],
      "usageNotes": "For Upstash/Supabase/LibSQL integration, always map out the relationships between supabase-adapter.ts, supabase.ts, memory.ts, db.ts, and libsql.ts. Use the above models to guide design, debugging, and onboarding. Document integration points and lessons learned in the knowledge graph."
    },
    "reasoningTools": {
      "description": "A curated set of advanced reasoning, analysis, and quality tools for dynamic problem-solving, debugging, collaboration, and code health. Each tool provides a systematic approach to breaking down, analyzing, and solving problems, and can be used alongside mental models for continuous improvement.",
      "tools": [
        {
          "name": "sequentialthinking",
          "summary": "A tool for dynamic and reflective problem-solving through thoughts. Each thought can build on, question, or revise previous insights as understanding deepens.",
          "purpose": "Analyze problems through a flexible, evolving thinking process."
        },
        {
          "name": "debuggingapproach",
          "summary": "A tool for applying systematic debugging approaches to solve technical issues. Supports binary search, reverse engineering, divide and conquer, backtracking, cause elimination, and program slicing.",
          "purpose": "Identify and resolve issues using structured debugging methods."
        },
        {
          "name": "collaborativereasoning",
          "summary": "A tool for simulating expert collaboration with diverse perspectives. Helps coordinate multiple viewpoints for complex problems.",
          "purpose": "Enable structured collaborative reasoning and perspective integration."
        },
        {
          "name": "decisionframework",
          "summary": "A tool for structured decision analysis and rational choice. Supports multiple frameworks, probability estimates, and value judgments.",
          "purpose": "Systematically evaluate options, criteria, and outcomes."
        },
        {
          "name": "metacognitivemonitoring",
          "summary": "A tool for systematic self-monitoring of knowledge and reasoning quality. Tracks knowledge boundaries, claim certainty, and reasoning biases.",
          "purpose": "Enable metacognitive assessment across domains and tasks."
        },
        {
          "name": "scientificmethod",
          "summary": "A tool for applying formal scientific reasoning to questions and problems. Guides through hypothesis testing, variable identification, prediction, and evidence evaluation.",
          "purpose": "Enforce structured scientific reasoning and hypothesis testing."
        },
        {
          "name": "structuredargumentation",
          "summary": "A tool for systematic dialectical reasoning and argument analysis. Facilitates creation, critique, and synthesis of competing arguments.",
          "purpose": "Analyze complex questions through formal argumentation structures."
        },
        {
          "name": "visualreasoning",
          "summary": "A tool for visual thinking, problem-solving, and communication. Enables creation and interpretation of diagrams, graphs, and visual representations.",
          "purpose": "Support visual problem-solving and communication."
        },
        {
          "name": "semanticsearch",
          "summary": "A tool for searching and relating concepts, code, and documentation using meaning and context rather than keywords.",
          "purpose": "Enable deep, context-aware search and navigation across the codebase and knowledge graph."
        },
        {
          "name": "codesmells",
          "summary": "A tool for detecting code smells, anti-patterns, and maintainability issues. Integrates with linting and static analysis.",
          "purpose": "Improve code quality and maintainability by identifying problematic patterns."
        }
      ]
    }
  },
  "taskList": {
    "completed": [
      "Created initial upstash.json knowledge graph with entities, features, and relationships.",
      "Removed all any types and direct console usage from all core Upstash backend files (agent-state-store.ts, redis-store.ts, vector-store.ts, upstash-logger.ts, upstashClients.ts, supabase-adapter.ts, supabase-adapter-factory.ts)",
      "Added robust type safety and Zod validation for all entities (threads, messages, agent state, users, workflows, tool executions, logs, etc.)",
      "Integrated upstashLogger for all logging and error handling across all modules.",
      "Implemented singleton client logic for Redis, Vector, and Query clients in upstashClients.ts.",
      "Added fallback logic to Supabase/LibSQL for all CRUD/search paths.",
      "Integrated @upstash/query for advanced RediSearch and hybrid search in all relevant modules.",
      "Ensured all exports are correct and up-to-date in index.ts barrel file, but barrel file still needs to be fully fixed for all new types and API route support.",
      "Updated README.md and knowledge graph to reflect current implementation and migration status.",
      "Documented all new/changed exports, features, and migration steps in README and upstash.json.",
      "Prepared Upstash backend for API route migration and frontend integration, but redis-store.ts and upstashClients.ts still need to import and use all types needed for full API route support (users, workflows, tool executions, logs, etc.) and ensure all CRUD/search logic is ready for production.",
      "Stopped migration work due to repeated issues with type imports/exports and incomplete barrel file; main task remains to ensure all types are imported, used, and exported for all API routes before migration can proceed."
    ],
    "current": [
      "For each file, remove all 'any' types and replace with precise types or Zod schemas.",
      "Replace all direct console statements with upstashLogger or equivalent.",
      "Ensure every file has comprehensive tests, docs, and usage examples.",
      "Add @upstash/query support for advanced search, streaming, and filtering where relevant.",
      "Update the knowledge graph and README after every significant change.",
      "For each incomplete file, follow the 'todo' and 'observations' fields for actionable next steps.",
      "Apply relevant mental models (see onboarding.mentalModels) to break down and solve each task.",
      "After every edit, run get_errors and update the knowledge graph accordingly.",
      "For diamond core files, always implement unused imports/types/vars if possible, and only remove if absolutely certain they are not needed."
    ],
    "longTerm": [
      "Incorporate new onboarding, semantic search, and mental model techniques as they emerge.",
      "Continuously improve type safety, logging, and test coverage across all modules.",
      "Expand the knowledge graph to include per-function and per-type nodes for even richer context.",
      "Automate knowledge graph updates via CI/CD and agent workflows.",
      "Develop and document custom mental models as the project evolves."
    ],
    "fileSpecific": {
      "agent-state-store.ts": [
        "Remove all any types.",
        "Remove all direct console statements, use upstashLogger.",
        "Add @upstash/query support for agent state search if needed.",
        "Add more robust error handling and type safety.",
        "Add tests for agent state operations."
      ],
      "vector-store.ts": [
        "Remove all direct console statements, use upstashLogger.",
        "Use precise types for metadata, results, and errors.",
        "Add @upstash/query integration for hybrid search, advanced filtering.",
        "Add more robust error handling and logging.",
        "Add tests for hybrid and filtered search."
      ],
      "upstash-logger.ts": [
        "Replace all any types with precise types.",
        "Remove unused types/vars.",
        "Remove all console statements, use upstashLogger only.",
        "Ensure all log entry parsing is type-safe.",
        "Add advanced log querying (e.g., by level, time range).",
        "Add tests for log streaming and retrieval."
      ],
      "redis-store.ts": [
        "Remove all any types.",
        "Remove unused @ts-expect-error.",
        "Use @upstash/query for advanced thread/message search (RediSearch, full-text, filters).",
        "Add more type-safe helpers for RediSearch results.",
        "Remove all direct console statements, use upstashLogger.",
        "Add tests for thread/message search and RediSearch integration."
      ],
      "supabase-adapter.ts": [
        "Fix: Property 'sql' does not exist on type 'Query' (update to use correct @upstash/query API).",
        "Remove unused importsv (Query), implement uuidv4.",
        "Add create/update/delete item support for full Supabase compatibility.",
        "Add more advanced query support (RediSearch, full-text, filters).",
        "Add more robust error handling and type safety.",
        "Add tests for all CRUD and query operations."
      ],
      "supabase-adapter-factory.ts": [
        "Remove all any types.",
        "implement all unused imports/vars.",
        "Add @upstash/query support for advanced table/vector operations.",
        "Add more robust error handling and type safety.",
        "Add tests for all factory-generated clients."
      ],
      "stream-processor.ts": [
        "Remove all any types.",
        "Remove all direct console statements, use upstashLogger.",
        "Remove unused imports/vars.",
        "Add @upstash/query support for streaming queries.",
        "Add more robust error handling and type safety.",
        "Add tests for streaming and batch processing."
      ],
      "memoryStore.ts": [
        "Remove all any types.",
        "Remove all direct console statements, use upstashLogger.",
        "Add @upstash/query support for advanced memory/thread/message search.",
        "Add more robust error handling and type safety.",
        "Add tests for memory operations and advanced search."
      ],
      "memory-processor.ts": [
        "Add @upstash/query support for streaming/semantic search if needed.",
        "Add tests for memory processing."
      ],
      "index.ts": [
        "Remove/replace all broken exports (see errors: missing exports from supabase-adapter).",
        "Ensure all exports are up-to-date and type-safe.",
        "Add documentation for new/advanced exports."
      ]
    },
    "completingAllFiles": [
      "For each file, ensure all 'any' types are replaced, all logging is via upstashLogger, and all unused imports/types/vars are either implemented or justified for removal.",
      "Every file must have up-to-date tests, documentation, and usage examples.",
      "All advanced search, streaming, and filtering features should use @upstash/query where possible.",
      "Knowledge graph and README must be updated after every significant change.",
      "Apply the most relevant mental models (see below) to each file's refactor, bugfix, or feature implementation."
    ]
  }
}

================
File: lib/memory/upstash/upstashClients.ts
================
import { z } from 'zod';
import { upstashLogger } from './upstash-logger';
import { Query } from '@upstash/query';
import { Redis } from '@upstash/redis';
import { Index } from '@upstash/vector';
import {
  RediSearchHybridQuery,
  QStashTaskPayload,
  WorkflowNode,
  UpstashEntityBase,
  UpstashEntitySchema,
  VectorIndexConfig,
  RediSearchHybridResult
} from './upstashTypes';

export type IndexConfig = VectorIndexConfig;

// --- Zod Schemas ---

/**
 * Schema for Redis client configuration
 */
export const RedisConfigSchema = z.object({
  url: z.string().url(),
  token: z.string().min(1),
});

/**
 * Schema for Vector client configuration
 */
export const VectorConfigSchema = z.object({
  url: z.string().url(),
  token: z.string().min(1),
  dimensions: z.number().positive().optional(),
  similarity: z.enum(['cosine', 'euclidean', 'dot']).optional(),
  indexName: z.string().optional(),
});

/**
 * Schema for environment variables
 */
export const EnvVarsSchema = z.object({
  UPSTASH_REDIS_REST_URL: z.string().url().optional(),
  UPSTASH_REDIS_REST_TOKEN: z.string().min(1).optional(),
  UPSTASH_VECTOR_REST_URL: z.string().url().optional(),
  UPSTASH_VECTOR_REST_TOKEN: z.string().min(1).optional(),
});

let redisClientInstance: Redis | null = null;
let vectorClientInstance: Index | null = null;
let upstashQueryClient: Query | null = null;

/**
 * Custom error class for Upstash client-related issues.
 */
export class UpstashClientError extends Error {
  constructor(message: string, public cause?: unknown) {
    super(message);
    this.name = 'UpstashClientError';
    Object.setPrototypeOf(this, UpstashClientError.prototype);
  }
}

/**
 * Validates environment variables using Zod schema
 *
 * @returns Validated environment variables
 * @throws UpstashClientError if validation fails
 */
export function validateEnvVars() {
  try {
    const result = EnvVarsSchema.safeParse(process.env);
    if (!result.success) {
      throw new UpstashClientError(`Environment variables validation failed: ${result.error.message}`);
    }
    return result.data;
  } catch (error: unknown) {
    if (error instanceof UpstashClientError) {
      throw error;
    }
    throw new UpstashClientError('Failed to validate environment variables', error);
  }
}

/**
 * Initializes and returns a singleton Upstash Redis client instance.
 * Reads configuration from environment variables:
 * - UPSTASH_REDIS_REST_URL
 * - UPSTASH_REDIS_REST_TOKEN
 * @throws {UpstashClientError} if Redis credentials are not found or initialization fails.
 */
export const getRedisClient = (): Redis => {
  if (redisClientInstance) {
    return redisClientInstance;
  }

  const env = validateEnvVars();
  const url = env.UPSTASH_REDIS_REST_URL;
  const token = env.UPSTASH_REDIS_REST_TOKEN;

  if (!url || !token) {
    upstashLogger.error('upstashClients', 'Upstash Redis credentials not found. Please set UPSTASH_REDIS_REST_URL and UPSTASH_REDIS_REST_TOKEN environment variables.');
    throw new UpstashClientError("Upstash Redis credentials not found. Please set UPSTASH_REDIS_REST_URL and UPSTASH_REDIS_REST_TOKEN environment variables.");
  }

  try {
    const configValidation = RedisConfigSchema.safeParse({ url, token });
    if (!configValidation.success) {
      upstashLogger.error('upstashClients', `Invalid Redis configuration: ${configValidation.error.message}`);
      throw new UpstashClientError(`Invalid Redis configuration: ${configValidation.error.message}`);
    }
    redisClientInstance = new Redis({
      url,
      token,
    });
    upstashLogger.info('upstashClients', 'Upstash Redis client initialized.');
  } catch (error: unknown) {
    upstashLogger.error('upstashClients', 'Failed to initialize Upstash Redis client.', error instanceof Error ? error : { message: String(error) });
    throw new UpstashClientError("Failed to initialize Upstash Redis client.", error);
  }

  return redisClientInstance;
};

/**
 * Initializes and returns an Upstash Vector client instance.
 * If a configuration is provided or no instance exists, a new one is created.
 * Otherwise, the existing singleton instance is returned.
 * Reads configuration from environment variables:
 * - UPSTASH_VECTOR_REST_URL
 * - UPSTASH_VECTOR_REST_TOKEN
 * @param config Optional configuration for the Upstash Vector Index.
 * @throws {UpstashClientError} if Vector credentials are not found or initialization fails.
 */
export const getVectorClient = (config?: IndexConfig): Index => {
  if (config || !vectorClientInstance) {
    const env = validateEnvVars();
    const url = env.UPSTASH_VECTOR_REST_URL;
    const token = env.UPSTASH_VECTOR_REST_TOKEN;

    if (!url || !token) {
      upstashLogger.error('upstashClients', 'Upstash Vector credentials not found. Please set UPSTASH_VECTOR_REST_URL and UPSTASH_VECTOR_REST_TOKEN environment variables.');
      throw new UpstashClientError("Upstash Vector credentials not found. Please set UPSTASH_VECTOR_REST_URL and UPSTASH_VECTOR_REST_TOKEN environment variables.");
    }

    try {
      const configToValidate = {
        url,
        token,
        ...config
      };

      const configValidation = VectorConfigSchema.safeParse(configToValidate);
      if (!configValidation.success) {
        upstashLogger.error('upstashClients', `Invalid Vector configuration: ${configValidation.error.message}`);
        throw new UpstashClientError(`Invalid Vector configuration: ${configValidation.error.message}`);
      }

      const newInstance = new Index({
        url,
        token,
        ...config
      });
      vectorClientInstance = newInstance;
      upstashLogger.info('upstashClients', 'Upstash Vector client initialized.');
      return vectorClientInstance;
    } catch (error: unknown) {
      upstashLogger.error('upstashClients', 'Failed to initialize Upstash Vector client.', error instanceof Error ? error : { message: String(error) });
      throw new UpstashClientError("Failed to initialize Upstash Vector client.", error);
    }
  }
  return vectorClientInstance;
};

/**
 * Initializes and returns a singleton Upstash Query client instance.
 * Uses the Upstash Redis REST client for RediSearch and advanced querying.
 * Throws if credentials are missing or invalid.
 * All config is validated and errors are logged with upstashLogger.
 */
export const getUpstashQueryClient = (): Query => {
  if (upstashQueryClient) return upstashQueryClient;
  const env = validateEnvVars();
  const url = env.UPSTASH_REDIS_REST_URL;
  const token = env.UPSTASH_REDIS_REST_TOKEN;
  if (!url) {
    upstashLogger.error('upstashClients', 'Upstash Query URL not found. Please set UPSTASH_REDIS_REST_URL environment variable.');
    throw new UpstashClientError('Upstash Query URL not found.');
  }
  // Correct config for @upstash/query: expects { url, token }
  upstashQueryClient = new Query({ url, token });
  upstashLogger.info('upstashClients', 'Upstash Query client initialized.');
  return upstashQueryClient;
};

/**
 * Check if Upstash Redis is available based on environment variables
 * @returns Whether Upstash Redis is available
 */
export function isUpstashRedisAvailable(): boolean {
  return !!process.env.UPSTASH_REDIS_REST_URL && !!process.env.UPSTASH_REDIS_REST_TOKEN;
}

/**
 * Check if Upstash Vector is available based on environment variables
 * @returns Whether Upstash Vector is available
 */
export function isUpstashVectorAvailable(): boolean {
  return !!process.env.UPSTASH_VECTOR_REST_URL && !!process.env.UPSTASH_VECTOR_REST_TOKEN;
}

/**
 * Check if Upstash adapter should be used based on environment variables
 * @returns Whether Upstash adapter should be used
 */
export function shouldUseUpstashAdapter(): boolean {
  return process.env.USE_UPSTASH_ADAPTER === 'true';
}

/**
 * Checks the availability of Upstash services (Redis and Vector).
 * @returns A promise that resolves to an object indicating the availability of each service
 *          and any errors encountered.
 */
export const checkUpstashAvailability = async (): Promise<{
  redisAvailable: boolean;
  vectorAvailable: boolean;
  redisError?: UpstashClientError | Error | unknown;
  vectorError?: UpstashClientError | Error | unknown;
  overallStatusMessage: string;
}> => {
  let redisAvailable = false;
  let vectorAvailable = false;
  let redisError: UpstashClientError | Error | unknown = undefined;
  let vectorError: UpstashClientError | Error | unknown = undefined;

  if (!isUpstashRedisAvailable()) {
    redisError = new UpstashClientError("Upstash Redis environment variables not set");
    redisAvailable = false;
  } else {
    try {
      const redis = getRedisClient();
      await redis.ping();
      redisAvailable = true;
      upstashLogger.info('upstashClients', 'Upstash Redis connection successful.');
    } catch (error: unknown) {
      upstashLogger.error('upstashClients', 'Upstash Redis connection failed', error instanceof Error ? error : { message: String(error) });
      redisError = error instanceof UpstashClientError ? error : new UpstashClientError("Redis availability check failed.", error);
      redisAvailable = false;
    }
  }

  if (!isUpstashVectorAvailable()) {
    vectorError = new UpstashClientError("Upstash Vector environment variables not set");
    vectorAvailable = false;
  } else {
    try {
      const vector = getVectorClient();
      await vector.info();
      vectorAvailable = true;
      upstashLogger.info('upstashClients', 'Upstash Vector connection successful (checked via info()).');
    } catch (error: unknown) {
      upstashLogger.error('upstashClients', 'Upstash Vector connection failed or info() call issue', error instanceof Error ? error : { message: String(error) });
      vectorError = error instanceof UpstashClientError ? error : new UpstashClientError("Vector availability check failed.", error);
      vectorAvailable = false;
    }
  }

  let overallStatusMessage = "";
  if (redisAvailable && vectorAvailable) {
    overallStatusMessage = "All Upstash services (Redis, Vector) are available.";
  } else if (redisAvailable) {
    overallStatusMessage = "Upstash Redis is available, but Vector is unavailable.";
  } else if (vectorAvailable) {
    overallStatusMessage = "Upstash Vector is available, but Redis is unavailable.";
  } else {
    overallStatusMessage = "Both Upstash Redis and Vector services are unavailable.";
  }

  return { redisAvailable, vectorAvailable, redisError, vectorError, overallStatusMessage };
};

/**
 * Validates a Redis configuration object using Zod schema
 *
 * @param config - Redis configuration to validate
 * @returns Validated Redis configuration
 * @throws UpstashClientError if validation fails
 */
export function validateRedisConfig(config: unknown): z.infer<typeof RedisConfigSchema> {
  try {
    return RedisConfigSchema.parse(config);
  } catch (error: unknown) {
    if (error instanceof z.ZodError) {
      throw new UpstashClientError(`Invalid Redis configuration: ${error.message}`, error);
    }
    throw new UpstashClientError('Failed to validate Redis configuration', error);
  }
}

/**
 * Validates a Vector configuration object using Zod schema
 *
 * @param config - Vector configuration to validate
 * @returns Validated Vector configuration
 * @throws UpstashClientError if validation fails
 */
export function validateVectorConfig(config: unknown): z.infer<typeof VectorConfigSchema> {
  try {
    return VectorConfigSchema.parse(config);
  } catch (error: unknown) {
    if (error instanceof z.ZodError) {
      throw new UpstashClientError(`Invalid Vector configuration: ${error.message}`, error);
    }
    throw new UpstashClientError('Failed to validate Vector configuration', error);
  }
}

/**
 * Returns true if Upstash should be used as the main DB (not just a cache or fallback).
 * Controlled by env var USE_UPSTASH_ADAPTER=true.
 */
export function isUpstashMainDb(): boolean {
  return process.env.USE_UPSTASH_ADAPTER === 'true';
}

/**
 * Returns true if fallback to Supabase/LibSQL should be attempted (if Upstash is unavailable).
 * Controlled by env var USE_UPSTASH_ADAPTER and presence of backup env vars.
 */
export function shouldFallbackToBackup(): boolean {
  return !isUpstashMainDb() && !!process.env.SUPABASE_URL && !!process.env.SUPABASE_KEY;
}

/**
 * Helper: Serialize entity for Redis hset
 */
function serializeEntityForRedis<T extends UpstashEntityBase>(entity: T): Record<string, string | number | boolean | null> {
  const result: Record<string, string | number | boolean | null> = {};
  for (const [k, v] of Object.entries(entity)) {
    if (k === 'metadata' && v != null) {
      result[k] = JSON.stringify(v);
    } else if (typeof v === 'object' && v !== null) {
      result[k] = JSON.stringify(v);
    } else {
      result[k] = v as string | number | boolean | null;
    }
  }
  return result;
}

/** 
 * Generic create or update for any Upstash entity type. 
 * @param entityType - e.g. 'thread', 'message', 'agent_state', etc.
 * @param entity - The entity object (must match schema)
 * @param schema - The Zod schema for validation
 */
export async function upstashUpsertEntity<T extends UpstashEntityBase>(
  entityType: string,
  entity: T,
  schema: z.ZodType<T> = UpstashEntitySchema as z.ZodType<T>
): Promise<T> {
  const redis = getRedisClient();
  const validated = schema.parse(entity);
  const key = `${entityType}:${entity.id}`;
  await redis.hset(key, serializeEntityForRedis(validated));
  return validated;
}

/**
 * Generic get by ID for any Upstash entity type.
 */
export async function upstashGetEntityById<T extends UpstashEntityBase>(
  entityType: string,
  id: string,
  schema: z.ZodType<T> = UpstashEntitySchema as z.ZodType<T>
): Promise<T | null> {
  const redis = getRedisClient();
  const key = `${entityType}:${id}`;
  const data = await redis.hgetall(key);
  if (!data || Object.keys(data).length === 0) return null;
  return schema.parse(data);
}

/**
 * Generic delete for any Upstash entity type.
 */
export async function upstashDeleteEntity(
  entityType: string,
  id: string
): Promise<boolean> {
  const redis = getRedisClient();
  const key = `${entityType}:${id}`;
  const result = await redis.del(key);
  return result > 0;
}

/**
 * Generic list/search for any Upstash entity type (with optional RediSearch/hybrid query)
 */
export async function upstashListEntities<T extends UpstashEntityBase>(
  entityType: string,
  options?: { limit?: number; offset?: number; filters?: Record<string, unknown>; sortBy?: string; sortOrder?: 'ASC' | 'DESC' },
  schema: z.ZodType<T> = UpstashEntitySchema as z.ZodType<T>
): Promise<T[]> {
  if (options?.filters || options?.sortBy) {
    const query: RediSearchHybridQuery = {
      index: entityType,
      query: '*',
      ...options,
    };
    const results = await runRediSearchHybridQuery(query) as RediSearchHybridResult[];
    return results.map(r => schema.parse(r.fields));
  } else {
    const redis = getRedisClient();
    const pattern = `${entityType}:*`;
    let cursor = 0;
    let entities: T[] = [];
    do {
      const [nextCursor, keys] = await redis.scan(cursor, { match: pattern, count: 100 });
      cursor = Number(nextCursor);
      for (const key of keys) {
        const data = await redis.hgetall(key);
        if (data && Object.keys(data).length > 0) {
          entities.push(schema.parse(data));
        }
      }
    } while (cursor !== 0 && (!options?.limit || entities.length < options.limit));
    if (options?.limit) entities = entities.slice(0, options.limit);
    return entities;
  }
}

/**
 * Add RediSearch/Hybrid Query client helper
 */
export const runRediSearchHybridQuery = async (query: RediSearchHybridQuery) => {
  const client: Query = getUpstashQueryClient();
  type FtSearchFn = (index: string, query: string, options: Record<string, unknown>) => Promise<unknown>;
  type SearchFn = (index: string, query: string, options: Record<string, unknown>) => Promise<unknown>;
  const options = {
    vector: query.vector,
    filters: query.filters,
    sortBy: query.sortBy,
    sortOrder: query.sortOrder,
    offset: query.offset,
    limit: query.limit,
  };
  if (typeof ((client as unknown) as { ftSearch?: FtSearchFn }).ftSearch === 'function') {
    return ((client as unknown) as { ftSearch: FtSearchFn }).ftSearch(query.index, query.query, options);
  } else if (typeof ((client as unknown) as { search?: SearchFn }).search === 'function') {
    return ((client as unknown) as { search: SearchFn }).search(query.index, query.query, options);
  } else {
    throw new UpstashClientError('No RediSearch/hybrid search method found on Query client. Please update @upstash/query or implement advanced search integration.');
  }
};

/**
 * QStash/Workflow client placeholder (to be implemented as needed)
 */
export const enqueueQStashTask = async (payload: QStashTaskPayload) => {
  return { status: 'enqueued', id: payload.id };
};

export const trackWorkflowNode = async (node: WorkflowNode) => {
  return { status: node.status, id: node.id };
};

================
File: lib/memory/upstash/upstashTypes.ts
================
import { z } from 'zod';

// --- Error Classes ---
export class RedisClientError extends Error {
  cause?: unknown;
  constructor(message: string, cause?: unknown) {
    super(message);
    this.name = 'RedisClientError';
    this.cause = cause;
  }
}

export class VectorStoreError extends Error {
  cause?: unknown;
  constructor(message: string, cause?: unknown) {
    super(message);
    this.name = 'VectorStoreError';
    this.cause = cause;
  }
}

export class RedisStoreError extends Error {
  cause?: unknown;
  constructor(message: string, cause?: unknown) {
    super(message);
    this.name = 'RedisStoreError';
    this.cause = cause;
    if (cause) this.stack += '\nCaused by: ' + (cause instanceof Error ? cause.stack : String(cause));
  }
}

// --- Zod Schemas ---
export const VectorMetadataSchema = z.record(z.any()).and(
  z.object({
    text: z.string().optional(),
    source_url: z.string().optional(),
    document_id: z.string().optional(),
    chunk_id: z.string().optional(),
    user_id: z.string().optional(),
    created_at: z.string().optional(),
  }).partial()
);

export const VectorDocumentSchema = z.object({
  id: z.string(),
  vector: z.array(z.number()),
  metadata: VectorMetadataSchema.optional(),
  sparseVector: z
    .object({
      indices: z.array(z.number()),
      values: z.array(z.number()),
    })
    .optional(),
});

// --- Types ---
export type VectorMetadata = z.infer<typeof VectorMetadataSchema>;
export type VectorDocument = z.infer<typeof VectorDocumentSchema>;

export interface RedisClientConfig {
  url: string;
  token: string;
}

export interface VectorStoreConfig {
  url: string;
  token: string;
  dimensions?: number;
  similarity?: 'cosine' | 'euclidean' | 'dot';
  indexName?: string;
}

export interface VectorQueryOptions {
  topK?: number;
  includeVectors?: boolean;
  includeMetadata?: boolean;
  filter?: Record<string, unknown>;
}

export interface VectorQueryResult {
  id: string;
  score: number;
  vector?: number[];
  metadata?: VectorMetadata;
}

export interface VectorFetchResult<T = VectorMetadata> {
  id: string;
  vector?: number[];
  metadata?: T;
}

export type RedisPipeline = Array<{ command: string; args: unknown[] }>;

export interface VectorIndexConfig {
  name: string;
  dimensions: number;
  similarity: 'cosine' | 'euclidean' | 'dot';
}

export type RedisType = 'hash' | 'set' | 'zset' | 'stream';
export type IndexType = 'flat' | 'hnsw';
export type VectorType = 'dense' | 'sparse';
export type ZodType = typeof z;

// --- Additional Types for Query/Hybrid Search ---
export interface VectorSearchOptions {
  query: number[] | string;
  topK?: number;
  filter?: Record<string, unknown>;
  includeVectors?: boolean;
  includeMetadata?: boolean;
}

export interface VectorSearchResult {
  id: string;
  score: number;
  vector?: number[];
  metadata?: VectorMetadata;
}

// --- Upstash Memory Types ---
export type ThreadMetadata = Record<string, unknown>;

export interface MessageMetadata {
  [key: string]: unknown;
  tool_calls?: Record<string, unknown>;
  tool_invocation_id?: string;
}

export interface Thread {
  id: string;
  name?: string | null;
  created_at: string; // ISO 8601 timestamp
  updated_at: string; // ISO 8601 timestamp
  user_id?: string | null;
  agent_id?: string | null;
  metadata?: ThreadMetadata | null;
}

export interface Message {
  id: string;
  thread_id: string;
  role: "user" | "assistant" | "system" | "tool";
  content: string;
  created_at: string; // ISO 8601 timestamp
  metadata?: MessageMetadata | null;
  name?: string; // Optional name, e.g., for tool calls/results
}

export type RedisHashData = Record<string, string | number | boolean | null>;

// --- RediSearch / @upstash/query Types & Schemas ---
export interface RediSearchQueryOptions {
  index: string;
  query: string;
  filters?: Record<string, unknown>;
  sortBy?: string;
  sortOrder?: 'ASC' | 'DESC';
  offset?: number;
  limit?: number;
}

export const RediSearchResultSchema = z.object({
  id: z.string(),
  score: z.number().optional(),
  fields: z.record(z.any()),
});
export type RediSearchResult = z.infer<typeof RediSearchResultSchema>;

export interface QueryIndexOptions {
  name: string;
  terms: string[];
}

export interface QueryMatchOptions {
  [key: string]: string | number | boolean;
}

export interface QueryRangeOptions {
  [key: string]: { gte?: number; lte?: number; gt?: number; lt?: number };
}

export interface QueryDocResult<T = Record<string, unknown>> {
  id: string;
  data: T;
}

// --- RediSearch/Hybrid Search Types ---
export interface RediSearchHybridQuery {
  index: string;
  query: string;
  vector?: number[];
  hybrid?: boolean;
  filters?: Record<string, unknown>;
  sortBy?: string;
  sortOrder?: 'ASC' | 'DESC';
  offset?: number;
  limit?: number;
}

export const RediSearchHybridQuerySchema = z.object({
  index: z.string(),
  query: z.string(),
  vector: z.array(z.number()).optional(),
  hybrid: z.boolean().optional(),
  filters: z.record(z.any()).optional(),
  sortBy: z.string().optional(),
  sortOrder: z.enum(['ASC', 'DESC']).optional(),
  offset: z.number().optional(),
  limit: z.number().optional(),
});

export const RediSearchHybridResultSchema = z.object({
  id: z.string(),
  score: z.number().optional(),
  fields: z.record(z.any()),
  vector: z.array(z.number()).optional(),
  metadata: z.record(z.any()).optional(),
});
export type RediSearchHybridResult = z.infer<typeof RediSearchHybridResultSchema>;

// --- QStash/Workflow Types ---
export interface QStashTaskPayload {
  id: string;
  type: string;
  data: Record<string, unknown>;
  created_at: string;
  status?: 'pending' | 'in_progress' | 'completed' | 'failed';
  result?: unknown;
  error?: string;
}

export const QStashTaskPayloadSchema = z.object({
  id: z.string(),
  type: z.string(),
  data: z.record(z.any()),
  created_at: z.string(),
  status: z.enum(['pending', 'in_progress', 'completed', 'failed']).optional(),
  result: z.any().optional(),
  error: z.string().optional(),
});

export interface WorkflowNode {
  id: string;
  type: string;
  status: 'pending' | 'running' | 'completed' | 'failed';
  started_at?: string;
  completed_at?: string;
  error?: string;
  tags?: string[];
  commands?: string[];
  relationships?: string[];
}

export const WorkflowNodeSchema = z.object({
  id: z.string(),
  type: z.string(),
  status: z.enum(['pending', 'running', 'completed', 'failed']),
  started_at: z.string().optional(),
  completed_at: z.string().optional(),
  error: z.string().optional(),
  tags: z.array(z.string()).optional(),
  commands: z.array(z.string()).optional(),
  relationships: z.array(z.string()).optional(),
});

// --- Generic Upstash Entity Types ---
export interface UpstashEntityBase {
  id: string;
  type: string;
  created_at: string;
  updated_at: string;
  metadata?: Record<string, unknown>;
}

export const UpstashEntitySchema = z.object({
  id: z.string(),
  type: z.string(),
  created_at: z.string(),
  updated_at: z.string(),
  metadata: z.record(z.any()).optional(),
});

// Thread entity (for chat, memory, etc)
export interface ThreadEntity extends UpstashEntityBase {
  name?: string | null;
  user_id?: string | null;
  agent_id?: string | null;
  messages?: string[]; // message IDs
}
export const ThreadEntitySchema = UpstashEntitySchema.extend({
  name: z.string().nullable().optional(),
  user_id: z.string().nullable().optional(),
  agent_id: z.string().nullable().optional(),
  messages: z.array(z.string()).optional(),
});

// Message entity (for chat, memory, etc)
export interface MessageEntity extends UpstashEntityBase {
  thread_id: string;
  role: 'user' | 'assistant' | 'system' | 'tool';
  content: string;
  name?: string;
}
export const MessageEntitySchema = UpstashEntitySchema.extend({
  thread_id: z.string(),
  role: z.enum(['user', 'assistant', 'system', 'tool']),
  content: z.string(),
  name: z.string().optional(),
});

// AgentState entity (for agent state store)
export interface AgentStateEntity extends UpstashEntityBase {
  thread_id: string;
  agent_id: string;
  state: Record<string, unknown>;
}
export const AgentStateEntitySchema = UpstashEntitySchema.extend({
  thread_id: z.string(),
  agent_id: z.string(),
  state: z.record(z.any()),
});

// ToolExecution entity (for tool execution store)
export interface ToolExecutionEntity extends UpstashEntityBase {
  tool_id: string;
  thread_id?: string;
  agent_id?: string;
  status: 'pending' | 'running' | 'completed' | 'failed';
  result?: unknown;
  error?: string;
}
export const ToolExecutionEntitySchema = UpstashEntitySchema.extend({
  tool_id: z.string(),
  thread_id: z.string().optional(),
  agent_id: z.string().optional(),
  status: z.enum(['pending', 'running', 'completed', 'failed']),
  result: z.any().optional(),
  error: z.string().optional(),
});

// WorkflowNode entity (for workflow orchestration)
export interface WorkflowNodeEntity extends UpstashEntityBase {
  workflow_id: string;
  node_type: string;
  status: 'pending' | 'running' | 'completed' | 'failed';
  started_at?: string;
  completed_at?: string;
  error?: string;
  tags?: string[];
  commands?: string[];
  relationships?: string[];
}
export const WorkflowNodeEntitySchema = UpstashEntitySchema.extend({
  workflow_id: z.string(),
  node_type: z.string(),
  status: z.enum(['pending', 'running', 'completed', 'failed']),
  started_at: z.string().optional(),
  completed_at: z.string().optional(),
  error: z.string().optional(),
  tags: z.array(z.string()).optional(),
  commands: z.array(z.string()).optional(),
  relationships: z.array(z.string()).optional(),
});

// LogEntry entity (for logging)
export interface LogEntryEntity extends UpstashEntityBase {
  level: LogLevel;
  message: string;
}
export const LogEntryEntitySchema = UpstashEntitySchema.extend({
  level: z.enum(['info', 'warn', 'error', 'debug']),
  message: z.string(),
});

// --- UserEntity ---
export interface UserEntity extends UpstashEntityBase {
  email: string;
  name?: string | null;
  avatar_url?: string | null;
  role: string;
}
export const UserEntitySchema = UpstashEntitySchema.extend({
  email: z.string().email(),
  name: z.string().nullable().optional(),
  avatar_url: z.string().nullable().optional(),
  role: z.string(),
});

// --- WorkflowEntity ---
export interface WorkflowEntity extends UpstashEntityBase {
  name: string;
  description?: string | null;
  current_step_index: number;
  status: string;
  metadata?: Record<string, unknown>;
}
export const WorkflowEntitySchema = UpstashEntitySchema.extend({
  name: z.string(),
  description: z.string().nullable().optional(),
  current_step_index: z.number(),
  status: z.string(),
  metadata: z.record(z.any()).optional(),
});

// --- SettingsEntity ---
export interface SettingsEntity extends UpstashEntityBase {
  category: string;
  key: string;
  value: string;
}
export const SettingsEntitySchema = UpstashEntitySchema.extend({
  category: z.string(),
  key: z.string(),
  value: z.string(),
});

// --- SystemMetricEntity ---
export interface SystemMetricEntity extends UpstashEntityBase {
  time_range?: string;
  timestamp: string;
  cpu_usage?: number;
  memory_usage?: number;
  database_connections?: number;
  api_requests_per_minute?: number;
  average_response_time_ms?: number;
  active_users?: number;
}
export const SystemMetricEntitySchema = UpstashEntitySchema.extend({
  time_range: z.string().optional(),
  timestamp: z.string(),
  cpu_usage: z.number().optional(),
  memory_usage: z.number().optional(),
  database_connections: z.number().optional(),
  api_requests_per_minute: z.number().optional(),
  average_response_time_ms: z.number().optional(),
  active_users: z.number().optional(),
});

// --- TraceEntity (Observability) ---
export interface TraceEntity extends UpstashEntityBase {
  name: string;
  start_time: string;
  end_time?: string;
  duration_ms?: number;
  status: string;
  user_id?: string;
  session_id?: string;
}
export const TraceEntitySchema = UpstashEntitySchema.extend({
  name: z.string(),
  start_time: z.string(),
  end_time: z.string().optional(),
  duration_ms: z.number().optional(),
  status: z.string(),
  user_id: z.string().optional(),
  session_id: z.string().optional(),
});

// --- SpanEntity (Observability) ---
export interface SpanEntity extends UpstashEntityBase {
  trace_id: string;
  parent_span_id?: string;
  name: string;
  start_time: string;
  end_time?: string;
  duration_ms?: number;
  status: string;
  attributes?: Record<string, unknown>;
}
export const SpanEntitySchema = UpstashEntitySchema.extend({
  trace_id: z.string(),
  parent_span_id: z.string().optional(),
  name: z.string(),
  start_time: z.string(),
  end_time: z.string().optional(),
  duration_ms: z.number().optional(),
  status: z.string(),
  attributes: z.record(z.any()).optional(),
});

// --- EventEntity (Observability) ---
export interface EventEntity extends UpstashEntityBase {
  trace_id: string;
  span_id?: string;
  name: string;
  timestamp: string;
  attributes?: Record<string, unknown>;
}
export const EventEntitySchema = UpstashEntitySchema.extend({
  trace_id: z.string(),
  span_id: z.string().optional(),
  name: z.string(),
  timestamp: z.string(),
  attributes: z.record(z.any()).optional(),
});

// --- ProviderEntity ---
export interface ProviderEntity extends UpstashEntityBase {
  name: string;
  api_key?: string;
  base_url?: string;
  status?: string;
  metadata?: Record<string, unknown>;
}
export const ProviderEntitySchema = UpstashEntitySchema.extend({
  name: z.string(),
  api_key: z.string().optional(),
  base_url: z.string().optional(),
  status: z.string().optional(),
  metadata: z.record(z.any()).optional(),
});

// --- ModelEntity ---
export interface ModelEntity extends UpstashEntityBase {
  name: string;
  provider: string;
  model_id: string;
  max_tokens?: number;
  input_cost_per_token?: number;
  output_cost_per_token?: number;
  supports_vision?: boolean;
  supports_functions?: boolean;
  supports_streaming?: boolean;
  default_temperature?: number;
  default_top_p?: number;
  default_frequency_penalty?: number;
  default_presence_penalty?: number;
  context_window?: number;
  description?: string;
  category?: string;
  capabilities?: Record<string, unknown>;
  base_url?: string;
  api_key?: string;
  status?: string;
}
export const ModelEntitySchema = UpstashEntitySchema.extend({
  name: z.string(),
  provider: z.string(),
  model_id: z.string(),
  max_tokens: z.number().optional(),
  input_cost_per_token: z.number().optional(),
  output_cost_per_token: z.number().optional(),
  supports_vision: z.boolean().optional(),
  supports_functions: z.boolean().optional(),
  supports_streaming: z.boolean().optional(),
  default_temperature: z.number().optional(),
  default_top_p: z.number().optional(),
  default_frequency_penalty: z.number().optional(),
  default_presence_penalty: z.number().optional(),
  context_window: z.number().optional(),
  description: z.string().optional(),
  category: z.string().optional(),
  capabilities: z.record(z.any()).optional(),
  base_url: z.string().optional(),
  api_key: z.string().optional(),
  status: z.string().optional(),
});

// --- AuthProviderEntity ---
export interface AuthProviderEntity extends UpstashEntityBase {
  provider: string;
  user_id: string;
  access_token?: string;
  refresh_token?: string;
  expires_at?: string;
  metadata?: Record<string, unknown>;
}
export const AuthProviderEntitySchema = UpstashEntitySchema.extend({
  provider: z.string(),
  user_id: z.string(),
  access_token: z.string().optional(),
  refresh_token: z.string().optional(),
  expires_at: z.string().optional(),
  metadata: z.record(z.any()).optional(),
});

// --- DashboardConfigEntity ---
export interface DashboardConfigEntity extends UpstashEntityBase {
  user_id?: string;
  widgets?: Record<string, unknown>[];
  layout?: Record<string, unknown>;
}
export const DashboardConfigEntitySchema = UpstashEntitySchema.extend({
  user_id: z.string().optional(),
  widgets: z.array(z.record(z.any())).optional(),
  layout: z.record(z.any()).optional(),
});

// --- Logging Types & Schemas ---
export type LogLevel = 'info' | 'warn' | 'error' | 'debug';

export const LogEntrySchema = z.object({
  id: z.string(),
  level: z.string(),
  message: z.string(),
  timestamp: z.string(),
  metadata: z.record(z.any()).optional(),
});
export type LogEntry = z.infer<typeof LogEntrySchema>;

export interface LogQueryOptions {
  level?: LogLevel;
  startTime?: string; // ISO 8601
  endTime?: string;   // ISO 8601
  limit?: number;
  offset?: number;
}

// --- Advanced Log Query Options ---
export interface AdvancedLogQueryOptions extends LogQueryOptions {
  thread_id?: string;
  agent_id?: string;
  workflow_id?: string;
  tool_id?: string;
  search?: string;
}

export const AdvancedLogQueryOptionsSchema = LogEntrySchema.extend({
  thread_id: z.string().optional(),
  agent_id: z.string().optional(),
  workflow_id: z.string().optional(),
  tool_id: z.string().optional(),
  search: z.string().optional(),
});

// --- Agent State Types & Schemas ---
export const AgentStateSchema = z.object({
  id: z.string(),
  thread_id: z.string(),
  agent_id: z.string(),
  state: z.record(z.any()),
  created_at: z.string(),
  updated_at: z.string(),
});
export type AgentState = z.infer<typeof AgentStateSchema>;

export const StoredAgentStateSchema = AgentStateSchema.extend({
  metadata: z.record(z.any()).optional(),
});
export type StoredAgentState = z.infer<typeof StoredAgentStateSchema>;

export class AgentStateStoreError extends Error {
  cause?: unknown;
  constructor(message: string, cause?: unknown) {
    super(message);
    this.name = 'AgentStateStoreError';
    this.cause = cause;
  }
}

// --- Thread/Message Search Result Types ---
export const ThreadSearchResultSchema = z.object({
  id: z.string(),
  name: z.string().nullable().optional(),
  created_at: z.string(),
  updated_at: z.string(),
  user_id: z.string().nullable().optional(),
  agent_id: z.string().nullable().optional(),
  metadata: z.record(z.any()).nullable().optional(),
  score: z.number().optional(),
});
export type ThreadSearchResult = z.infer<typeof ThreadSearchResultSchema>;

export const MessageSearchResultSchema = z.object({
  id: z.string(),
  thread_id: z.string(),
  role: z.string(),
  content: z.string(),
  created_at: z.string(),
  metadata: z.record(z.any()).nullable().optional(),
  name: z.string().optional(),
  score: z.number().optional(),
});
export type MessageSearchResult = z.infer<typeof MessageSearchResultSchema>;

// --- ListEntitiesOptions ---
export interface ListEntitiesOptions {
  limit?: number;
  offset?: number;
  filters?: Record<string, unknown>;
  sortBy?: string;
  sortOrder?: 'ASC' | 'DESC';
  select?: string[];
}

================
File: lib/memory/upstash/README.md
================
# Upstash Memory & Logging Implementation

---

## 🚨 MIGRATION BLOCKER: ADAPTER FACTORY & TYPE SAFETY FAILURE (2025-05-15)

> **CRITICAL BLOCKER (Updated):**
>
> The Upstash adapter and factory remain **not production-ready** due to:
> - Pervasive use of `any`, unsafe type assertions, and generic string table names in `supabase-adapter-factory.ts`, `supabase-adapter.ts`, and `redis-store.ts`.
> - Type system incompatibility with Supabase/Upstash generics, especially for composite keys and fallback logic.
> - The current implementation cannot be safely used as a drop-in replacement for Supabase in backend API routes.
>
> **Current State (2025-05-15):**
>
> - All core files exist in `/lib/memory/upstash/`:
>   - agent-state-store.ts
>   - index.ts
>   - memory-processor.ts
>   - memoryStore.ts
>   - redis-store.ts
>   - stream-processor.ts
>   - supabase-adapter-factory.ts
>   - supabase-adapter.ts
>   - upstash-logger.ts
>   - upstash.json
>   - upstashClients.ts
>   - upstashTypes.ts
>   - vector-store.ts
> - All files are tracked in the knowledge graph (`upstash.json`) and this README.
> - **Migration is blocked** until all `any` types, unsafe casts, and broken adapter logic are removed and replaced with type-safe, table-aware, production-grade implementations.
> - See `upstash.json` for per-file status, todos, and relationships.
>
> **Next steps for the next agent:**
>
> 1. Remove all `any` types and unsafe type assertions from the adapter factory, Upstash adapter, and redis-store.
> 2. Refactor all CRUD/search logic to use table-aware, type-safe interfaces and helpers (see Supabase/Drizzle patterns).
> 3. Ensure all Upstash CRUD/search logic is compatible with the Supabase type system and can be used as a true drop-in replacement.
> 4. Do not proceed with migration or production use until these issues are fully resolved and all tests pass.
> 5. Update this README and `upstash.json` after every significant change.

---

## Overview

The Upstash implementation provides a modular, production-grade, and feature-rich solution for AI memory, vector search, and logging, including:

1. **Upstash Client Management (`upstashClients.ts`)**: Centralized, singleton initialization and management of Redis, VectorDB, and Query clients, with health checks and config validation.
2. **Redis-based Memory Storage (`redis-store.ts`)**: Typed, efficient storage and retrieval of conversation threads and messages using Redis Hashes and Sorted Sets, with RediSearch and @upstash/query integration for advanced search.
3. **Vector Database Operations (`vector-store.ts`)**: Full vector operations (upsert, search, fetch, delete, reset, info) for managing embeddings with metadata using Upstash VectorDB and @upstash/query for hybrid/filtered search.
4. **Remote Logging (`upstash-logger.ts`)**: Persistent, capped logging system using Redis Streams for capturing application logs (info, warnings, errors, debug) with advanced querying and retrieval.
5. **Supabase Compatibility Layer (`supabase-adapter.ts`, `supabase-adapter-factory.ts`)**: Drop-in replacement for Supabase memory APIs, with Upstash-first, fallback-to-Supabase/LibSQL strategy and @upstash/query support for advanced queries.
6. **Advanced Streaming & Processing (`stream-processor.ts`, `memory-processor.ts`)**: Efficient streaming, batching, and semantic search utilities, with @upstash/query for streaming queries.
7. **Barrel Export (`index.ts`)**: Easy-to-use exports for all functionalities.

---

# Upstash Knowledge Graph & Tooling Overview

This section mirrors the canonical knowledge graph in `upstash.json` and serves as the single source of truth for onboarding, refactoring, and AI agent support. All contributors and AI agents should reference this section for:

- **Todos, tags, features, API routes, onboarding/tooling, and reasoning tools**
- **Deduplicated tool list with usage notes, when/how/why, and relationships**
- **File-by-file status, todos, and feature coverage table**
- **Onboarding, troubleshooting, best practices, and mental models**

---

## 📚 Available Tools for Upstash Integration & Project Automation

Below is a deduplicated list of all available tools (from the knowledge graph's onboarding:tool-list), with usage notes, when/how/why to use, and relationships. Use these for onboarding, automation, troubleshooting, and continuous improvement.

| Tool ID                | When to Use                                      | How to Use / Notes                                                                 | Why / Relationships / Connections |
|------------------------|--------------------------------------------------|------------------------------------------------------------------------------------|-----------------------------------|
| add_documentation      | Onboarding new libs/APIs, after refactors        | Provide name & URL. Optionally add tags/topics.                                    | Keeps docs up-to-date. Related: update_documentation, search_documentation |
| update_documentation   | After API/library/workflow changes               | Specify doc to update and new content/URL.                                         | Prevents outdated docs. Related: add_documentation, search_documentation |
| think                  | Before major changes, debugging, migration       | Write out reasoning, hypotheses, next steps. Use as digital rubber duck.           | Improves code quality. Related: debuggingapproach, sequentialthinking |
| open_project           | Onboarding, troubleshooting, multi-repo work     | Specify project/workspace to open.                                                 | Ensures context alignment. Related: set_profile, get_profile_context |
| read_context           | Reviewing legacy code, onboarding, refactoring   | Specify path, file types, recurse.                                                 | Enables deep code analysis. Related: get_chunk_count, generate_outline |
| get_chunk_count        | Before reading/analyzing large files/dirs        | Provide same params as read_context.                                               | Prevents timeouts. Related: read_context |
| set_profile            | Switching work types (backend/frontend, etc)     | Specify profile name/settings.                                                     | Optimizes context/tools. Related: get_profile_context, open_project |
| get_profile_context    | After setting/switching profiles                 | Call after set_profile.                                                            | Gathers context for migration. Related: set_profile |
| generate_outline       | Onboarding, reviewing, refactoring code          | Specify file path.                                                                 | Understand file structure. Related: read_context |
| search_documentation   | Troubleshooting, onboarding, migration           | Provide query string.                                                              | Finds best practices. Related: add_documentation, update_documentation, list_documentation |
| list_documentation     | Onboarding, auditing, updating docs              | Call without params for full list.                                                 | Audits docs. Related: search_documentation, add_documentation |
| get_library_docs       | Integrating/updating libs, troubleshooting       | Resolve library ID, then fetch docs.                                               | Latest best practices. Related: resolve_library_id |
| resolve_library_id     | Before fetching docs for new/updated package     | Provide npm package name.                                                          | Ensures correct docs. Related: get_library_docs |
| write_to_terminal      | Running scripts/tests/deployments, migrations    | Provide command string/params.                                                     | Automates CLI tasks. Related: read_terminal_output, send_control_character |
| read_terminal_output   | After running scripts/tests/deployments          | Specify terminal session/command.                                                  | Validates automation. Related: write_to_terminal |
| send_control_character | Stopping/controlling scripts/processes           | Specify control char & terminal session.                                           | Manages automation. Related: write_to_terminal, read_terminal_output |

**Best Practices:**

- Always use `add_documentation` for new sources and `update_documentation` for changes.
- Use `list_documentation` to check docs before making changes.
- Reference this list when building onboarding flows, troubleshooting, or automating tasks.

---

## 📊 File-by-File Status, Todos, Tags, API Routes, and Reasoning Tools

The following table summarizes the status, todos, tags, API routes, and reasoning tools for each Upstash entity. For full details, see `upstash.json`.

| File                      | Status      | Todos (Key)                                              | Tags (Key)                | API Routes (Key)                | Reasoning Tools (Key)                |
|---------------------------|-------------|----------------------------------------------------------|---------------------------|----------------------------------|--------------------------------------|
| agent-state-store.ts      | incomplete  | Remove all any, console; add query, tests, type safety   | upstash, agent-state, ... | /api/ai-sdk/agents, ...          | debuggingapproach, metacognitivemonitoring, codesmells |
| redis-store.ts            | incomplete  | Remove any, console; add query, tests, helpers           | upstash, redis, ...       | /api/ai-sdk/threads, ...         | debuggingapproach, sequentialthinking, codesmells      |
| vector-store.ts           | incomplete  | Remove console; add query, tests, type safety, logging   | upstash, vector, ...      | /api/ai-sdk/embeddings, ...      | scientificmethod, decisionframework, codesmells        |
| upstash-logger.ts         | incomplete  | Remove any, console; add type-safe parsing, tests        | upstash, logging, ...     | /api/ai-sdk/logs, ...            | metacognitivemonitoring, codesmells                   |
| upstashClients.ts         | incomplete  | Fix Query config: { url, token } is not valid for QueryConfig (see get_errors) | upstash, client, ...      | /api/ai-sdk/*                    | debuggingapproach, metacognitivemonitoring            |
| upstashTypes.ts           | incomplete  | Expand types for RediSearch/query, add granular types    | upstash, types, ...       |                                  | debuggingapproach, metacognitivemonitoring, codesmells |
| memoryStore.ts            | incomplete  | Remove any, console; add query, tests, error handling    | upstash, memory, ...      | /api/ai-sdk/threads, ...         | debuggingapproach, decisionframework, codesmells       |
| stream-processor.ts       | incomplete  | Remove any, console; add query, tests, error handling    | upstash, streaming, ...   | /api/ai-sdk/streams, ...         | sequentialthinking, scientificmethod, codesmells       |
| memory-processor.ts       | incomplete  | Add query for streaming/semantic search, add tests       | upstash, memory, ...      |                                  | debuggingapproach, codesmells                          |
| supabase-adapter.ts       | incomplete  | Fix Query API, add CRUD, error handling, tests           | upstash, supabase, ...    |                                  | debuggingapproach, codesmells                          |
| supabase-adapter-factory.ts| incomplete | Fix TableRow is not generic type errors (see get_errors) | upstash, supabase, ...    |                                  | debuggingapproach, codesmells                          |
| index.ts                  | incomplete  | Check for missing/broken exports from dependencies (see get_errors) | upstash, barrel, ...      | /api/ai-sdk/*                    | debuggingapproach, codesmells                          |

**Legend:** See `upstash.json` for full tag and route lists. All files must:

- Remove all `any` types and direct `console` statements
- Use Zod schemas and upstashLogger for type safety and logging
- Add/expand tests and docs for all features
- Use @upstash/query for advanced search, streaming, and filtering
- Update the knowledge graph and README after every significant change

---

## Features

- **Typed API**: Strongly-typed interfaces for all data models and function signatures.
- **Error Handling**: Custom error classes for each module (`UpstashClientError`, `RedisStoreError`, `VectorStoreError`, `LoggerError`).
- **Efficient Data Structures**: Optimized use of Redis data structures for performance.
- **Vector Similarity Search**: Powerful semantic and hybrid search capabilities.
- **Metadata Support**: Rich metadata storage for threads, messages, and vectors.
- **Redis Streams for Logging**: Scalable and persistent logging.
- **@upstash/query Integration**: Advanced querying, RediSearch, and secondary indexing for flexible, production-grade queries.
- **Environment Variable Configuration**: Easy setup via environment variables.
- **Modular Design**: Clear separation of concerns for maintainability and testability.
- **Supabase Fallback**: Automatic fallback to Supabase/LibSQL for maximum reliability.

---

## Directory Structure (2025-05-15)

```bash
┣ 📜agent-state-store.ts
┣ 📜index.ts
┣ 📜memory-processor.ts
┣ 📜memoryStore.ts
┣ 📜README.md
┣ 📜redis-store.ts
┣ 📜stream-processor.ts
┣ 📜supabase-adapter-factory.ts
┣ 📜supabase-adapter.ts
┣ 📜upstash-logger.ts
┣ 📜upstash.json
┣ 📜upstashClients.ts
┣ 📜upstashTypes.ts
┗ 📜vector-store.ts
```

---

## Setup

To use the Upstash memory and logging implementation, ensure the following environment variables are set:

```env
# Required for all Upstash services
UPSTASH_REDIS_REST_URL=your_redis_rest_url
UPSTASH_REDIS_REST_TOKEN=your_redis_rest_token
UPSTASH_VECTOR_REST_URL=your_vector_rest_url
UPSTASH_VECTOR_REST_TOKEN=your_vector_rest_token

# Optional: For memory factory integration
MEMORY_PROVIDER=upstash

# Optional: For Upstash Logger configuration
UPSTASH_LOGGER_STREAM_NAME=ai_app_logs # Default stream name
UPSTASH_LOGGER_MAX_LENGTH=1000 # Default max log entries
```

---

## 📚 Upstash Command Documentation & LLM Integration

> **Full Upstash Redis, Vector, QStash, and Workflow Command References:**
>
> - [Upstash Redis LLMs Command Reference](https://context7.com/upstash/docs/llms.txt?folders=redis&tokens=84007)
> - [Upstash Vector LLMs Command Reference](https://context7.com/upstash/docs/llms.txt?folders=vector&tokens=40216)
> - [Upstash QStash LLMs Command Reference](https://context7.com/upstash/docs/llms.txt?folders=qstash&tokens=41928)
> - [Upstash Workflow LLMs Command Reference](https://context7.com/upstash/docs/llms.txt?folders=workflow&tokens=45652)
>
> These links provide comprehensive, production-grade documentation for all Upstash Redis and Vector DB commands, including advanced LLM, search, pipelining, hybrid search, QStash, and workflow orchestration. Use these for all backend memory, logging, vector, and workflow operations.

- **Redis:** Use all available commands for memory, logging, and workflow. See [Upstash Redis LLMs Command Reference](https://context7.com/upstash/docs/llms.txt?folders=redis&tokens=84007).
- **Vector:** Use all available commands for vector DB, hybrid search, and embeddings. See [Upstash Vector LLMs Command Reference](https://context7.com/upstash/docs/llms.txt?folders=vector&tokens=40216).
- **QStash:** Use for workflow orchestration, background jobs, and queue management. See [Upstash QStash LLMs Command Reference](https://context7.com/upstash/docs/llms.txt?folders=qstash&tokens=41928).
- **Workflow:** For backend workflow and automation logic, see [Upstash Workflow LLMs Command Reference](https://context7.com/upstash/docs/llms.txt?folders=workflow&tokens=45652).

### Tool Execution Store (Workflow Integration)

- See [`lib/tools/upstash-tool-execution-store.ts`](../tools/upstash-tool-execution-store.ts) for Upstash-based workflow and tool execution logging.
- Integrate QStash and Workflow commands for robust, observable, and scalable backend workflows.

---

## File-by-File Status & Detailed TODO Checklist

### upstashClients.ts

- [x] Type-safe, robust, singleton clients for Redis, Vector, and Query
- [x] Uses Zod schemas for config validation
- [x] upstashLogger for all logging
- [x] Health checks and availability functions
- [ ] **Fix Query config: { url, token } is not valid for QueryConfig (see get_errors)**
- [ ] **Add advanced Query client usage examples in docs**
- [ ] **Document how to use Query for RediSearch and advanced filtering**

### upstashTypes.ts

- [x] Canonical source for types, Zod schemas, and error classes
- [x] No errors
- [ ] **Expand types for advanced RediSearch/query support if needed**
- [ ] **Add more granular types for RediSearch results and query options**

### upstash-logger.ts

- [ ] Replace all `any` types with precise types (see errors)
- [ ] Remove unused types/vars (e.g., RedisClient)
- [ ] Remove all console statements, use upstashLogger only
- [ ] Ensure all log entry parsing is type-safe
- [ ] Add advanced log querying (e.g., by level, time range)
- [ ] Add tests for log streaming and retrieval

### redis-store.ts

- [ ] Remove all `any` types (see errors)
- [ ] Remove unused @ts-expect-error
- [ ] Use @upstash/query for advanced thread/message search (RediSearch, full-text, filters)
- [ ] Add more type-safe helpers for RediSearch results
- [ ] Remove all direct console statements, use upstashLogger
- [ ] Add tests for thread/message search and RediSearch integration

### vector-store.ts

- [x] No type errors
- [ ] Remove all direct console statements, use upstashLogger
- [ ] Use precise types for metadata, results, and errors
- [ ] Add @upstash/query integration for hybrid search, advanced filtering
- [ ] Add more robust error handling and logging
- [ ] Add tests for hybrid and filtered search

### supabase-adapter.ts

- [x] Uses generateEmbedding from ai-integration for real embeddings
- [x] Uses upstashLogger for all logging
- [x] Uses getUpstashQueryClient for advanced queries (but see error below)
- [ ] **Fix: Property 'sql' does not exist on type 'Query' (update to use correct @upstash/query API)**
- [ ] Remove unused imports (uuidv4, Query)
- [ ] Add create/update/delete item support for full Supabase compatibility
- [ ] Add more advanced query support (RediSearch, full-text, filters)
- [ ] Add more robust error handling and type safety
- [ ] Add tests for all CRUD and query operations

### supabase-adapter-factory.ts

- [ ] **Fix TableRow is not generic type errors (see get_errors)**
- [ ] Remove all `any` types (see errors)
- [ ] Remove unused types/vars
- [ ] Add @upstash/query support for advanced table/vector operations
- [ ] Add more robust error handling and type safety
- [ ] Add tests for all factory-generated clients

### stream-processor.ts

- [ ] Remove all `any` types (see errors)
- [ ] Remove all direct console statements, use upstashLogger
- [ ] Remove unused imports/vars
- [ ] Add @upstash/query support for streaming queries
- [ ] Add more robust error handling and type safety
- [ ] Add tests for streaming and batch processing

### memoryStore.ts

- [ ] Remove all `any` types (see errors)
- [ ] Remove all direct console statements, use upstashLogger
- [ ] Add @upstash/query support for advanced memory/thread/message search
- [ ] Add more robust error handling and type safety
- [ ] Add tests for memory operations and advanced search

### memory-processor.ts

- [x] No errors
- [ ] Add @upstash/query support for streaming/semantic search if needed
- [ ] Add tests for memory processing

### agent-state-store.ts

- [ ] Remove all `any` types (see errors)
- [ ] Remove all direct console statements, use upstashLogger
- [ ] Add @upstash/query support for agent state search if needed
- [ ] Add more robust error handling and type safety
- [ ] Add tests for agent state operations

### index.ts (barrel)

- [ ] **Check for missing/broken exports from dependencies (see get_errors)**

---

## Feature Coverage Table

| File                        | Type Safety | Logging | @upstash/query | RediSearch | CRUD | Vector | Streaming | Tests | Supabase Fallback |
|-----------------------------|:-----------:|:-------:|:--------------:|:----------:|:----:|:------:|:---------:|:-----:|:-----------------:|
| upstashClients.ts           |     ⚠️      |   ✅    |      ⚠️        |     ❌     |  ❌  |   ❌   |     ❌    |   ❌  |        ❌         |
| upstashTypes.ts             |     ✅      |   ❌    |      ❌        |     ❌     |  ❌  |   ❌   |     ❌    |   ❌  |        ❌         |
| upstash-logger.ts           |     ⚠️      |   ✅    |      ❌        |     ❌     |  ❌  |   ❌   |     ❌    |   ❌  |        ❌         |
| redis-store.ts              |     ⚠️      |   ⚠️    |      ⚠️        |     ⚠️     |  ✅  |   ❌   |     ❌    |   ❌  |        ❌         |
| vector-store.ts             |     ✅      |   ⚠️    |      ⚠️        |     ⚠️     |  ❌  |   ✅   |     ❌    |   ❌  |        ❌         |
| supabase-adapter.ts         |     ✅      |   ✅    |      ⚠️        |     ⚠️     |  ⚠️  |   ✅   |     ❌    |   ❌  |        ✅         |
| supabase-adapter-factory.ts |     ⚠️      |   ❌    |      ⚠️        |     ⚠️     |  ⚠️  |   ⚠️   |     ❌    |   ❌  |        ✅         |
| stream-processor.ts         |     ⚠️      |   ⚠️    |      ⚠️        |     ❌     |  ❌  |   ❌   |     ✅    |   ❌  |        ❌         |
| memoryStore.ts              |     ⚠️      |   ⚠️    |      ⚠️        |     ❌     |  ✅  |   ⚠️   |     ⚠️    |   ❌  |        ✅         |
| memory-processor.ts         |     ✅      |   ✅    |      ⚠️        |     ❌     |  ❌  |   ⚠️   |     ✅    |   ❌  |        ✅         |
| agent-state-store.ts        |     ⚠️      |   ⚠️    |      ⚠️        |     ❌     |  ✅  |   ❌   |     ❌    |   ❌  |        ✅         |
| index.ts                    |     ⚠️      |   ❌    |      ❌        |     ❌     |  ❌  |   ❌   |     ❌    |   ❌  |        ❌         |

Legend: ✅ = Complete, ⚠️ = Needs work, ❌ = Not present

---

## Implementation Guide & Best Practices

### Why Upstash as Main Memory (with Supabase Fallback)?

- **Performance**: Upstash Redis and VectorDB provide low-latency, serverless, globally distributed memory and vector search.
- **Scalability**: Upstash scales automatically, with no server management.
- **Advanced Querying**: @upstash/query enables secondary indexes, RediSearch, and flexible, typesafe queries.
- **Reliability**: Supabase/LibSQL fallback ensures data durability and compatibility with existing APIs.
- **Observability**: upstashLogger and Redis Streams provide robust, persistent logging.

### How to Implement and Use Each Module

#### upstashClients.ts

- Use singleton pattern for Redis, Vector, and Query clients.
- Validate all configs with Zod schemas.
- Log all client errors and health checks with upstashLogger.
- Example:

  ```ts
  import { getRedisClient, getVectorClient, getUpstashQueryClient } from './upstashClients';
  const redis = getRedisClient();
  const vector = getVectorClient();
  const query = getUpstashQueryClient();
  ```

#### upstashTypes.ts

- Define all types, interfaces, and Zod schemas for memory, vector, and query data.
- Add types for RediSearch and @upstash/query results as needed.

#### upstash-logger.ts

- Use Redis Streams for log storage.
- Replace all `any` types with precise types or Zod schemas.
- Remove all direct console statements; use upstashLogger for all logging.
- Add advanced log querying (by level, time range, etc).

#### redis-store.ts

- Store threads/messages as Redis Hashes and Sorted Sets.
- Use @upstash/query for advanced search (secondary indexes, RediSearch, full-text, filters):

  ```ts
  import { getUpstashQueryClient } from './upstashClients';
  const query = getUpstashQueryClient();
  const threads = query.createCollection<Thread>('threads');
  const threadsByUser = threads.createIndex({ name: 'threads_by_user', terms: ['userId'] });
  const userThreads = await threadsByUser.match({ userId: '123' });
  ```

- Remove all `any` types and direct console statements.

#### vector-store.ts

- Use Upstash Vector for all vector operations.
- Integrate @upstash/query for hybrid/filtered search and secondary indexes.
- Example:

  ```ts
  import { getUpstashQueryClient } from './upstashClients';
  const query = getUpstashQueryClient();
  const vectors = query.createCollection<VectorDocument>('vectors');
  const vectorsByDoc = vectors.createIndex({ name: 'vectors_by_doc', terms: ['document_id'] });
  const docVectors = await vectorsByDoc.match({ document_id: 'doc1' });
  ```

#### supabase-adapter.ts

- Provide Supabase-compatible API using Upstash as backend.
- Use generateEmbedding for vector operations.
- Use getUpstashQueryClient for advanced queries (see above for examples).
- Remove unused imports and fix all type errors.
- Add full CRUD support for items, threads, and vectors.

#### supabase-adapter-factory.ts

- Factory for creating Supabase/Upstash-compatible clients.
- Add @upstash/query support for advanced table/vector operations.
- Remove all `any` types and unused vars.

#### stream-processor.ts

- Use @upstash/query for streaming and batch queries.
- Remove all direct console statements and `any` types.

#### memoryStore.ts

- High-level memory operations (threads, messages, etc).
- Use @upstash/query for advanced search/filtering.
- Remove all `any` types and direct console statements.

#### memory-processor.ts

- Use @upstash/query for streaming/semantic search if needed.
- Add tests for memory processing.

#### agent-state-store.ts

- Use @upstash/query for advanced agent state search.
- Remove all `any` types and direct console statements.

#### index.ts

- Ensure all exports are up-to-date and type-safe.
- Remove/replace all broken exports.

---

## Advanced @upstash/query Usage Examples

### 1. Creating a Collection and Index

```ts
import { Query } from '@upstash/query';
import { Redis } from '@upstash/redis';

type User = { id: string; name: string; organization: string; email: string };
const q = new Query({ redis: Redis.fromEnv({ automaticDeserialization: false }) });
const users = q.createCollection<User>('users');
const usersByOrg = users.createIndex({ name: 'users_by_organization', terms: ['organization'] });

// Add a user
await users.set('user1', { id: 'user1', name: 'Alice', organization: 'Upstash', email: 'alice@upstash.com' });

// Query by organization
const upstashUsers = await usersByOrg.match({ organization: 'Upstash' });
```

### 2. Advanced Filtering and Range Queries

```ts
const deployments = q.createCollection<Deployment>('deployments');
const deploymentsByOrg = deployments.createIndex({ name: 'deployments_by_org', terms: ['organization'] });
const results = await deploymentsByOrg.match({ organization: 'Upstash' });
// Range query example (numeric or lexicographic)
const rangeResults = await deploymentsByOrg.range({ organization: 'Upstash' }, { time: { gte: 1700000000000 } });
```

### 3. Hybrid Search with Vectors and Metadata

```ts
// Use Upstash Vector for similarity search, then filter with @upstash/query
const vectorResults = await vectorClient.query({ vector, topK: 10, includeMetadata: true });
const query = getUpstashQueryClient();
const vectors = query.createCollection<VectorDocument>('vectors');
const vectorsByDoc = vectors.createIndex({ name: 'vectors_by_doc', terms: ['document_id'] });
const docVectors = await vectorsByDoc.match({ document_id: 'doc1' });
```

---

## Upstash SDK Best Practices & Advanced Features (2025)

### @upstash/redis

- **TypeScript-first, REST-based, connectionless:** Designed for serverless, edge, and multi-platform environments.
- **Initialization:** Use `Redis.fromEnv()` for automatic config from environment variables, or pass `{ url, token }` directly.
- **Type Safety:** All commands are strongly typed. You can disable automatic JSON serialization with `automaticDeserialization: false` for raw data.
- **Best Practices:**
  - **Singleton Pattern:** Keep the Redis client in memory for reuse (especially in serverless/edge).
  - **No direct console:** Use a logger for all output.
  - **Pipelining:** Use built-in pipelining for batch operations.
  - **Supported Types:** Strings, hashes, sets, sorted sets, lists, etc. All with type-safe APIs.
- **Advanced:** Supports keyspace notifications, multi-region, and RESTful access for edge/serverless.
- **Common Use Cases:** Caching, session/token storage, real-time analytics, queues, pub/sub, prototyping.

### @upstash/vector

- **TypeScript-first, REST-based, connectionless:** For serverless, edge, and multi-platform.
- **Initialization:** Use `new Index()` with env vars or pass `{ url, token }` directly.
- **Type Safety:** You can specify a metadata type at the index level for all operations (`Index<MyMetaType>`), or per-command.
- **Best Practices:**
  - **Namespaces:** Use `index.namespace("name")` to partition data for multi-tenant or isolated workloads.
  - **Metadata Filtering:** Use SQL-like filter strings in queries (e.g., `genre = 'fantasy' and year > 2000`).
  - **Hybrid Search:** Combine vector similarity with metadata filters for powerful RAG and semantic search.
  - **No direct console:** Use a logger for all output.
- **Advanced:** Supports dense and sparse vectors, multiple similarity functions (cosine, dot, euclidean), and metadata filtering.
- **Example Types:**

  ```ts
  type Metadata = { title: string; genre: "sci-fi" | "fantasy"; year: number };
  const index = new Index<Metadata>();
  ```

- **Common Use Cases:** RAG, semantic search, hybrid search, multi-tenant vector storage.

### @upstash/query

- **TypeScript-first, typesafe secondary indexing and querying for Redis.**
- **Collections & Indexes:** Use `createCollection<T>()` and `createIndex({ name, terms })` for typesafe, indexed queries.
- **Best Practices:**
  - **Always pass types** to collections and indexes for full type safety.
  - **Use secondary indexes** for fast lookups and filtering.
  - **Range queries:** Use `.range()` for numeric/lexicographic queries.
  - **No direct console:** Use a logger for all output.
- **Advanced:** Blazing fast, supports RediSearch-like queries, hybrid search (combine with vector results), and full CRUD.
- **Example Types:**

  ```ts
  type User = { id: string; org: string };
  const users = q.createCollection<User>("users");
  const byOrg = users.createIndex({ name: "by_org", terms: ["org"] });
  ```

- **Common Use Cases:** Secondary indexes, advanced filtering, hybrid search, typesafe queries.

---

## Using This Guide for Future Development & Best Practices

This README is designed to be a living, authoritative reference for all Upstash-based memory, vector, and logging development in this project. To ensure long-term maintainability, reliability, and production-readiness, follow these principles and workflows:

### 1. **Onboarding & Team Knowledge Transfer**

- New contributors should read this document in full before making changes to any Upstash-related code.
- All onboarding sessions should reference the Implementation Guide, Feature Table, and Best Practices sections.
- Encourage team members to update this README with new patterns, lessons learned, and API changes as Upstash evolves.

### 2. **Development Workflow**

- **Start with Types:** Always define and validate types in `upstashTypes.ts` before implementing new features.
- **Singleton Clients:** Use the provided Upstash client factories to avoid connection churn and maximize performance.
- **Type Safety:** Never use `any`—always use Zod schemas and shared types for all data, queries, and results.
- **Logging:** Replace all direct `console` usage with `upstashLogger` for observability and debugging.
- **Advanced Features:** When adding new search, filtering, or hybrid features, consult the @upstash/query and @upstash/vector best practices and examples in this README.
- **Testing:** Add/expand tests for all new features, especially for advanced queries, hybrid search, and error handling.
- **Documentation:** Update this README with new usage patterns, code snippets, and lessons learned after every major change.

### 3. **Troubleshooting & Debugging**

- Use the Feature Coverage Table to quickly identify which modules are missing type safety, logging, or advanced query support.
- Reference the Implementation Guide for step-by-step instructions on how to add or refactor features.
- For issues with Upstash SDKs, check the Best Practices and Advanced Features section for the latest recommendations.
- If you encounter new Upstash features or breaking changes, document them here and update the codebase accordingly.

### 4. **Staying Up to Date**

- Regularly review Upstash, @upstash/redis, @upstash/vector, and @upstash/query documentation for new features and deprecations.
- Schedule periodic code reviews to ensure all modules adhere to the latest best practices outlined here.
- Use this README as the single source of truth for Upstash integration—avoid duplicating guidance elsewhere.

### 5. **Contributing & Continuous Improvement**

- All pull requests that touch Upstash code must reference relevant sections of this README in their description.
- Encourage contributors to add new examples, troubleshooting tips, and advanced usage patterns as they are discovered.
- Use the checklists and tables to track progress and ensure nothing is missed during refactors or feature additions.

### 6. **Production Readiness Checklist**

- [ ] All types are defined and validated with Zod.
- [ ] No `any` types or direct `console` statements remain.
- [ ] All logging uses `upstashLogger`.
- [ ] All advanced queries use @upstash/query or @upstash/vector with type safety.
- [ ] Tests cover all major features and edge cases.
- [ ] This README is up to date and covers all new features and patterns.

---

## Long-Term Onboarding, Evolution, and AI Agent Guidance (2025+)

This section is designed to future-proof your Upstash memory and logging system, ensuring that both human developers and AI coding agents (like Copilot or custom LLM-based agents) can onboard, extend, and maintain this codebase with maximum reliability, context, and best practices. Drawing from the latest 2025 onboarding and AI agent development techniques, this guidance will help you avoid common pitfalls and keep your system at the cutting edge.

### 1. **AI Agent and Human Onboarding: Structured, Context-Rich, and Iterative**

- **Purpose and Scope:** Every new agent or contributor should start by reading this README in full, understanding the rationale for Upstash-first design, and reviewing the Feature Table and Implementation Guide.
- **Knowledge Graphs & Semantic Search:** Use knowledge graphs (or structured docs) to relate types, modules, and workflows. Semantic search (for both humans and AI) should be enabled across this README and codebase to quickly answer "how do I...?" questions.
- **Explicit API and Type Contracts:** All APIs, types, and Zod schemas must be documented and discoverable. This enables both AI and human agents to reason about the system without guesswork.
- **Continuous Learning:** AI agents should be designed to learn from every code review, PR, and user interaction—updating their internal models and this README as new best practices emerge.

### 2. **Development Environment and Tooling**

- **Integrated DevOps:** Use CI/CD pipelines to enforce type safety, linting, and test coverage. Automated checks should block PRs that violate the standards in this README.
- **Automated Documentation Generation:** Use NLP models or AI agents to auto-generate and update docstrings, usage examples, and module-level documentation from code and type signatures.
- **Feedback Loops:** Set up mechanisms for both human and AI contributors to provide feedback on onboarding, documentation, and system behavior. Use this feedback to iteratively improve the onboarding process and documentation.

### 3. **AI Agent Optimization and Continuous Improvement**

- **Transfer Learning and RLHF:** AI agents should leverage transfer learning (using pre-trained models) and reinforcement learning with human feedback (RLHF) to improve code suggestions, error detection, and documentation generation over time.
- **Monitoring and Telemetry:** Continuously monitor agent and system performance (e.g., via Azure Monitor, Upstash logs, or custom dashboards). Use this data to identify bottlenecks, regressions, or opportunities for optimization.
- **Iterative Updates:** Regularly retrain and update AI models, expand agent capabilities, and update this README as new features, patterns, or technologies are adopted.

### 4. **Advanced Testing, Debugging, and Validation**

- **Automated Testing:** All new features must be covered by unit, integration, and load tests. AI agents should be able to auto-generate and optimize test cases based on code changes and usage patterns.
- **User Acceptance Testing (UAT):** Gather feedback from real developers and AI agents to validate that new features and workflows add value and do not introduce regressions.
- **Load and Edge-Case Testing:** Ensure the system can handle high concurrency, large data volumes, and unusual edge cases—especially for memory, vector, and logging operations.

### 5. **Human-AI Collaboration and Future-Proofing**

- **Human-in-the-Loop:** Encourage a collaborative workflow where AI agents augment, not replace, human developers. Use AI for code review, test generation, and documentation, but always validate with human oversight.
- **Customizability and Extensibility:** Design the system so that both AI and human contributors can easily add new memory backends, logging strategies, or advanced query features without breaking existing contracts.
- **Security and Compliance:** Regularly review secrets management, access controls, and compliance requirements. AI agents should be aware of and enforce these constraints.

### 6. **Integration with Modern Dev Workflows**

- **Cloud and Edge Readiness:** Ensure all modules are compatible with serverless, edge, and multi-cloud environments. Use RESTful, stateless patterns and avoid assumptions about runtime or infrastructure.
- **API and Tooling Integration:** Integrate with modern tools (e.g., VS Code, GitHub, Azure, CI/CD) so that both AI and human agents can access, test, and deploy the system efficiently.
- **Automated Change Tracking:** Use bots or scripts to detect when the README or codebase falls out of sync, prompting updates or reviews as needed.

### 7. **Continuous Documentation and Knowledge Sharing**

- **Living Documentation:** Treat this README as a living document. Every major change, new feature, or lesson learned should be reflected here.
- **Onboarding Playbooks:** Maintain onboarding playbooks for both human and AI agents, including step-by-step guides, troubleshooting tips, and escalation paths for complex issues.
- **Community and Feedback:** Foster a culture of open feedback, regular retrospectives, and knowledge sharing—ensuring that both AI and human contributors feel empowered to improve the system.

---

**Final Note:**

By following this extended guidance, you ensure that your Upstash memory, vector, and logging system is not only robust and production-ready today, but also adaptable, scalable, and AI-friendly for the future. Whether you are a new developer, a seasoned maintainer, or an advanced AI coding agent, this README and its workflows will help you onboard quickly, avoid common mistakes, and contribute to a system that is always improving. Treat this document as your north star for quality, reliability, and innovation—update it often, and let it guide every step of your development journey.




================================================================
End of Codebase
================================================================
